{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"LiveHD and Pyrope Documentation for LiveHD and Pyrope","title":"LiveHD and Pyrope"},{"location":"#livehd-and-pyrope","text":"Documentation for LiveHD and Pyrope","title":"LiveHD and Pyrope"},{"location":"livehd/01-install/","text":"Installation This is a high level description of how to build LiveHD. Requirements Although LiveHD should run on most common Linux distributions, it is heavily tested on both Arch and Kali (Debian based). The following programs are assumed to be present when building LiveHD: GCC 8+ or Clang 8+ (C++17 support is required) Bazel python3 The following programs are optional: pandoc (for better viewing of markdown documentation) It is also assumed that bash is used to compile LiveHD. gcc and clang offers better warnings and execution speed dependent of the benchmark. If you're unsure if your copy of gcc or clang is new enough, you can check the version by typing g++ --version or clang++ --version Steps Download LiveHD source git clone https://github.com/masc-ucsc/livehd Install Bazel For Debian-derived distros (including Ubuntu and Kali), follow these instructions. For Arch-derived distros, install the bazel package with sudo pacman -Syu bazel . Build LiveHD LiveHD has several build options, detailed below. All three should result in a working executable, but may differ in speed or output. A binary will be created in livehd/bazel-bin/main/lgshell . bazel build //main:all # fast build, no debug symbols, slow execution (default) bazel build //main:all -c opt # fastest execution speed, no debug symbols, no assertions bazel build //main:all -c dbg # moderate execution speed, debug symbols Install pandoc (optional) sudo pacman -Syu pandoc # (Arch) sudo apt-get install pandoc # (Kali/Debian/Ubuntu) Potential issues If you have multiple gcc versions, you may need to specify the latest. E.g: CXX = g++-8 CC = gcc-8 bazel build //main:all -c opt # fast execution for benchmarking CXX = g++-8 CC = gcc-8 bazel build //main:all -c dbg # debugging/development If you want to run clang specific version: CXX = clang++-10 CC = clang-10 bazel build //main:all -c dbg # debugging/development Make sure that the openJDK installed is compatible with bazel and has the certificates to use tools. E.g in debian: dpkg-reconfigure openjdk-11-jdk /var/lib/dpkg/ca-certificates-java.postinst configure If you fail to build for the first time, you may need to clear the cache under your home directory before rebuilding: rm -rf ~/.cache/bazel Make sure to have enough memory (4+GB at least) Next Steps To start using LiveHD, check out Usage . If you're interested in working on LiveHD, refer to Develop .","title":"Installation"},{"location":"livehd/01-install/#installation","text":"This is a high level description of how to build LiveHD.","title":"Installation"},{"location":"livehd/01-install/#requirements","text":"Although LiveHD should run on most common Linux distributions, it is heavily tested on both Arch and Kali (Debian based). The following programs are assumed to be present when building LiveHD: GCC 8+ or Clang 8+ (C++17 support is required) Bazel python3 The following programs are optional: pandoc (for better viewing of markdown documentation) It is also assumed that bash is used to compile LiveHD. gcc and clang offers better warnings and execution speed dependent of the benchmark. If you're unsure if your copy of gcc or clang is new enough, you can check the version by typing g++ --version or clang++ --version","title":"Requirements"},{"location":"livehd/01-install/#steps","text":"Download LiveHD source git clone https://github.com/masc-ucsc/livehd Install Bazel For Debian-derived distros (including Ubuntu and Kali), follow these instructions. For Arch-derived distros, install the bazel package with sudo pacman -Syu bazel . Build LiveHD LiveHD has several build options, detailed below. All three should result in a working executable, but may differ in speed or output. A binary will be created in livehd/bazel-bin/main/lgshell . bazel build //main:all # fast build, no debug symbols, slow execution (default) bazel build //main:all -c opt # fastest execution speed, no debug symbols, no assertions bazel build //main:all -c dbg # moderate execution speed, debug symbols Install pandoc (optional) sudo pacman -Syu pandoc # (Arch) sudo apt-get install pandoc # (Kali/Debian/Ubuntu)","title":"Steps"},{"location":"livehd/01-install/#potential-issues","text":"If you have multiple gcc versions, you may need to specify the latest. E.g: CXX = g++-8 CC = gcc-8 bazel build //main:all -c opt # fast execution for benchmarking CXX = g++-8 CC = gcc-8 bazel build //main:all -c dbg # debugging/development If you want to run clang specific version: CXX = clang++-10 CC = clang-10 bazel build //main:all -c dbg # debugging/development Make sure that the openJDK installed is compatible with bazel and has the certificates to use tools. E.g in debian: dpkg-reconfigure openjdk-11-jdk /var/lib/dpkg/ca-certificates-java.postinst configure If you fail to build for the first time, you may need to clear the cache under your home directory before rebuilding: rm -rf ~/.cache/bazel Make sure to have enough memory (4+GB at least)","title":"Potential issues"},{"location":"livehd/01-install/#next-steps","text":"To start using LiveHD, check out Usage . If you're interested in working on LiveHD, refer to Develop .","title":"Next Steps"},{"location":"livehd/01-usage/","text":"Getting started This is a high level description of how to use LiveHD. Sample usage Below are some sample usages of the LiveHD shell (lgshell). A bash prompt is indicated by $ , an lgshell prompt is indicated by livehd> , and a Yosys prompt is indicated by a yosys> . Lgshell supports color output and autocompletion using the tab key. General concepts When Verilog file(s) are imported into lgshell through the inou.yosys.tolg command (see below for examples), the Verilog modules get converted to an internal representation and are stored in livehd/lgdb . If a problem occurs while importing Verilog files (due to a syntax error, use of un-synthesizable Verilog, or something else), the corresponding error from Yosys will be printed. Once a hierarchy has been created, other lgshell commands can read, modify, or export this hierarchy freely. The command lgraph.match can be used to specify a (sub)hierarchy to operate over, which can then be moved from pass to pass using the pipe ( |> ) operator. Starting and exiting the shell $ ./bazel-bin/main/lgshell livehd> help ... livehd> help pass.sample livehd> exit Reading and writing Verilog files with of LiveHD To read a single-module Verilog file with Yosys and create an LGraph: $ ./bazel-bin/main/lgshell livehd> inou.yosys.tolg files:./inou/yosys/tests/simple_add.v livehd> exit $ ls lgdb To read a Verilog file with more than one module: $ ./bazel-bin/main/lgshell livehd> inou.yosys.tolg files:./inou/yosys/tests/hierarchy.v top:<top module name> livehd> exit $ ls lgdb Print information about an existing LGraph: $ ./bazel-bin/main/lgshell livehd> inou.yosys.tolg files:./inou/yosys/tests/trivial.v livehd> lgraph.match |> lgraph.stats To dump an LGraph (and submodules) to Verilog: $ ./bazel-bin/main/lgshell livehd> lgraph.open name:simple_add |> inou.yosys.fromlg odir:lgdb livehd> exit $ ls lgdb/*.v lgraph.match picks up any LGraphs matching the regex passed (or everything if no regex is provided) and treats every single one as the top of the hierarchy, whereas lgraph.open name:<root module> will just open the root module as the top of the hierarchy. Running a custom pass $ ./bazel-bin/main/lgshell livehd> inou.yosys.tolg files:./inou/yosys/tests/trivial.v livehd> lgraph.match |> <pass name> Generating json file from an LGraph $ ./bazel-bin/main/lgshell livehd> inou.yosys.tolg files:./inou/yosys/tests/trivial.v |> inou.json.fromlg output:trivial.json livehd> exit $ less trivial.json RocketChip example pass Load RocketChip (a RISC-V core) to the DB for the first time $ ./bazel-bin/main/lgshell livehd> inou.yosys.tolg files:lgdb/parse/file_freechips.rocketchip.system.DefaultConfig.v livehd> lgraph.open name:RocketTile |> pass.sample.wirecount Perform a pass over RocketTile (the top level module in RocketChip) $ ./bazel-bin/main/lgshell livehd> lgraph.open name:RocketTile |> pass.sample.wirecount Other example projects are located in the projects folder. Keep in mind that the BoomConfig verilog file contains almost 500,000 lines of code! Perform a pass over BoomTile $ ./bazel-bin/main/lgshell livehd> inou.yosys.tolg files:projects/boom/AsyncResetReg.v,projects/boom/SimDTM.v,projects/boom/boom.system.TestHarness.BoomConfig.v livehd> lgraph.match |> lgraph.stats Low level directed build To compile an individual pass: $ bazel build -c dbg //pass/sample:pass_sample $ bazel build -c dbg //inou/yosys:all To build a direct Yosys executable that has LiveHD embedded: $ bazel build -c dbg //inou/yosys:all $./bazel-bin/inou/yosys/yosys2","title":"Getting started"},{"location":"livehd/01-usage/#getting-started","text":"This is a high level description of how to use LiveHD.","title":"Getting started"},{"location":"livehd/01-usage/#sample-usage","text":"Below are some sample usages of the LiveHD shell (lgshell). A bash prompt is indicated by $ , an lgshell prompt is indicated by livehd> , and a Yosys prompt is indicated by a yosys> . Lgshell supports color output and autocompletion using the tab key.","title":"Sample usage"},{"location":"livehd/01-usage/#general-concepts","text":"When Verilog file(s) are imported into lgshell through the inou.yosys.tolg command (see below for examples), the Verilog modules get converted to an internal representation and are stored in livehd/lgdb . If a problem occurs while importing Verilog files (due to a syntax error, use of un-synthesizable Verilog, or something else), the corresponding error from Yosys will be printed. Once a hierarchy has been created, other lgshell commands can read, modify, or export this hierarchy freely. The command lgraph.match can be used to specify a (sub)hierarchy to operate over, which can then be moved from pass to pass using the pipe ( |> ) operator.","title":"General concepts"},{"location":"livehd/01-usage/#starting-and-exiting-the-shell","text":"$ ./bazel-bin/main/lgshell livehd> help ... livehd> help pass.sample livehd> exit","title":"Starting and exiting the shell"},{"location":"livehd/01-usage/#reading-and-writing-verilog-files-with-of-livehd","text":"To read a single-module Verilog file with Yosys and create an LGraph: $ ./bazel-bin/main/lgshell livehd> inou.yosys.tolg files:./inou/yosys/tests/simple_add.v livehd> exit $ ls lgdb To read a Verilog file with more than one module: $ ./bazel-bin/main/lgshell livehd> inou.yosys.tolg files:./inou/yosys/tests/hierarchy.v top:<top module name> livehd> exit $ ls lgdb Print information about an existing LGraph: $ ./bazel-bin/main/lgshell livehd> inou.yosys.tolg files:./inou/yosys/tests/trivial.v livehd> lgraph.match |> lgraph.stats To dump an LGraph (and submodules) to Verilog: $ ./bazel-bin/main/lgshell livehd> lgraph.open name:simple_add |> inou.yosys.fromlg odir:lgdb livehd> exit $ ls lgdb/*.v lgraph.match picks up any LGraphs matching the regex passed (or everything if no regex is provided) and treats every single one as the top of the hierarchy, whereas lgraph.open name:<root module> will just open the root module as the top of the hierarchy.","title":"Reading and writing Verilog files with of LiveHD"},{"location":"livehd/01-usage/#running-a-custom-pass","text":"$ ./bazel-bin/main/lgshell livehd> inou.yosys.tolg files:./inou/yosys/tests/trivial.v livehd> lgraph.match |> <pass name>","title":"Running a custom pass"},{"location":"livehd/01-usage/#generating-json-file-from-an-lgraph","text":"$ ./bazel-bin/main/lgshell livehd> inou.yosys.tolg files:./inou/yosys/tests/trivial.v |> inou.json.fromlg output:trivial.json livehd> exit $ less trivial.json","title":"Generating json file from an LGraph"},{"location":"livehd/01-usage/#rocketchip-example-pass","text":"Load RocketChip (a RISC-V core) to the DB for the first time $ ./bazel-bin/main/lgshell livehd> inou.yosys.tolg files:lgdb/parse/file_freechips.rocketchip.system.DefaultConfig.v livehd> lgraph.open name:RocketTile |> pass.sample.wirecount Perform a pass over RocketTile (the top level module in RocketChip) $ ./bazel-bin/main/lgshell livehd> lgraph.open name:RocketTile |> pass.sample.wirecount Other example projects are located in the projects folder. Keep in mind that the BoomConfig verilog file contains almost 500,000 lines of code! Perform a pass over BoomTile $ ./bazel-bin/main/lgshell livehd> inou.yosys.tolg files:projects/boom/AsyncResetReg.v,projects/boom/SimDTM.v,projects/boom/boom.system.TestHarness.BoomConfig.v livehd> lgraph.match |> lgraph.stats","title":"RocketChip example pass"},{"location":"livehd/01-usage/#low-level-directed-build","text":"To compile an individual pass: $ bazel build -c dbg //pass/sample:pass_sample $ bazel build -c dbg //inou/yosys:all To build a direct Yosys executable that has LiveHD embedded: $ bazel build -c dbg //inou/yosys:all $./bazel-bin/inou/yosys/yosys2","title":"Low level directed build"},{"location":"livehd/02-lgraph/","text":"LGraph Warning This document is not updated to the latest changes LGraph is the graph-based data structure used inside LiveHD. Together with LNAST, it is one of the key data structures. The LGraph can be built directly with passes like Yosys, or through LNAST to LGraph translations. The LNAST builds a gated-SSA which is translated to LGraph. Understanding the LGraph is needed if you want to build a LiveHD pass. LGraph API A single LGraph represents a single netlist module. LGraph is composed of nodes, node pins, edges and tables of attributes. An LGraph node is affiliated with a node type and each type defines different amounts of input and output node pins. For example, a node can have 3 input ports and 2 output pins. Each of the input/output pins can have many edges to other graph nodes. Every node pin has an affiliated node pid. In the code, every node_pin has a Port_ID . A pair of driver pin and sink pin constitutes an edge. In the following API example, an edge is connected from a driver pin (pid1) to a sink pin (pid3). The bitwidth of the driver pin determines the edge bitwidth. Node, Node_pin, and Edge Construction create node new_node = lg -> create_node () //note: type and/or bits still need to be assigned later create node with node type assigned new_node = lg -> create_node ( Node_type_Op ) //note: recommended way if you know the target node type create a constant node new_node = lg -> create_node_const ( value ) //note: recommended way to create a const node setup default driver pin for pin_0 of a node driver_pin = new_node . setup_driver_pin (); //note: when you know the node type only has one output pin setup default sink pin for pin_0 of a node sink_pin = new_node . setup_sink_pin () //note: when you know the node type only has one input pin setup driver pin for pin_x of a node driver_pin = new_node . setup_driver_pin ( pid ) //note: when you know the pid, same as sink_pin get the pid value of a node_pin object node_pin . get_pid () add an edge between driver_pin and sink_pin driver_pin . connect ( sink_pin ); get the driver node of an edge driver_node = edge . driver . get_node () use node as the index/key for a container absl :: flat_hash_map < Node :: Compact , int > my_map ; my_map [ node1 . get_compact ()] = 77 ; my_map [ node2 . get_compact ()] = 42 ; ... use node_pin as the index/key for a container absl :: flat_hash_map < Node_pin :: Compact , int > my_map ; my_map [ node_pin1 . get_compact ()] = 14 ; my_map [ node_pin2 . get_compact ()] = 58 ; ... get the node_pin back from a Node_pin::Compact Node_pin dpin ( lg , some_dpin . get_compact ()) get the node back from a Node::Compact Node node ( lg , some_node . get_compact ()) create a LGraph input(output) with the name new_node_pin = lg -> add_graph_input ( std :: string_view ) debug information of a node node . debug_name () debug information of a node_pin node_pin . debug_name () iterate output edges and get node/pin information from it for ( auto & out : node . out_edges ()) { auto dpin = out . driver ; auto dpin_pid = dpin . get_pid (); auto dnode_name = dpin . get_node (). debug_name (); auto snode_name = out . sink . get_node (). debug_name (); auto spin_pid = out . sink . get_pid (); auto dpin_name = dpin . has_name () ? dpin . get_name () : \"\" ; auto dbits = dpin . get_bits (); fmt :: print ( \" {}->{}[label= \\\" {}b :{} :{} :{} \\\" ]; \\n \" , dnode_name , snode_name , dbits , dpin_pid , spin_pid , dpin_name ); } Non-Hierarchical Traversal Iterators LGraph allows forward and backward traversals in the nodes (bidirectional graph). The reason is that some algorithms need a forward and some a backward traversal, being bidirectional would help. Whenever possible, the fast iterator should be used. for ( const auto & node : lg -> fast ()) {...} // unordered but very fast traversal for ( const auto & node : lg -> forward ()) {...} // propagates forward from each input/constant for ( const auto & node : lg -> backward ()) {...} // propagates backward from each output The LGraph iterator such as for(auto node: g->forward()) do not visit graph input and outputs. // simple way using lambda lg->each_graph_input([&](const Node_pin &pin){ //your operation with graph_input node_pin; }); Hierarchical Traversal Iterators LGraph supports hierarchical traversal. Each sub-module of a hierarchical design will be transformed into a new LGraph and represented as a sub-graph node in the parent module. If the hierarchical traversal is used, every time the iterator encounters a sub-graph node, it will load the sub-graph persistent tables to the memory and traverse the subgraph recursively, ignoring the sub-graph input/outputs. This cross-module traversal treats the hierarchical netlist just like a flattened design. In this way, all integrated third-party tools could automatically achieve global design optimization or analysis by leveraging the LGraph hierarchical traversal feature. for ( const auto & node : lg -> forward_hier ()) {...} Edge Iterators To iterate over the input edges of node, simply call: for ( const auto & inp_edge : node . inp_edges ()) {...} And for output edges: for ( const auto & out_edge : node . out_edges ()) {...} LGraph Attribute Design Design attribute stands for the characteristic given to a LGraph node or node pin. For instance, the characteristic of a node name and node physical placement. Despite a single LGraph stands for a particular module, it could be instantiated multiple times. In this case, same module could have different attribute at different hierarchy of the netlist. A good design of attribute structure should be able to represent both non-hierarchical and hierarchical characteristic. Non-Hierarchical Attribute Non-hierarchical LGraph attributes include pin name, node name and line of source code. Such properties should be the same across different LGraph instantia- tions. Two instantiations of the same LGraph module will have the exact same user-defined node name on every node. For example, instantiations of a subgraph-2 in both top and subgraph-1 would maintain the same non-hierarchical attribute table. node . set_name ( std :: string_view name ); Hierarchical Attribute LGraph also support hierarchical attribute. It is achieved by using a tree data structure to record the design hierarchy. In LGraph, every graph has a unique id (lg_id), every instantiation of a graph would form some nodes in the tree and every tree node is indexed by a unique hierarchical id (hid). We are able to identify a unique instantiation of a graph and generate its own hierarchical attribute table. An example of hierarchical attribute is wire-delay. node_pin . set_delay ( float delay ); LGraph Node Type Semantics For each LGraph node, there is a specific semantic. This section explains the operation to perform for each node. It includes a precise way to compute the maximum and minimum value for the output. In LGraph, the cells operate like having unlimited precision with signed numbers. Most HDLs focus on unsigned, but LiveHD handles the superset (sign and unlimited precision). The precision is reduced only explicitly with few operations like and-gate with masks or Shifts. In LGraph, an unsigned value is a value that can not be negative. The document also explains corner cases in relationship to Verilog and how to convert to/from Verilog semantics. These are corner cases to deal with sign and precision. Each HDL may have different semantics, the Verilog is to showcase the specifics. In general the nodes have a single output with the exception of complex nodes like subgraphs or memories. Ntypes with single output, have 'Y' as output. The inputs are single characters 'A', 'B'... For most inputs, there can be many drivers. E.g: a single Sum cell can do Y=3+20+a0+a3 where A_{0} = 3 , A_{1} = 20 , A_{2} = a0 , and A_{3} = a3 . If an input can not have multiple drivers, a lower case name is used ('a', 'b'...). E.g: the right shift cell is Y=a>>b because only one driver can connect to 'a' and 'b'. The section includes description on how to compute the maximum ( max ) and minimum ( min ) allowed result range. This is used by the bitwidth inference pass. To ease the explanation, a sign value means that the result may be negative ( a.sign == a.min<0 ). known is true if the result sign is known ( a.known == a.max<0 or a.min>=0 ), either positive or negative ( neg == a.max<0 ). The cells explanation also requires the to compute the bit mask ( a.mask == (1<<a.bits)-1 ). For any value ( a ), the number of bits required ( bits ) is a.bits = log2(absmax(a.max,a.min))+a.sign?1:0 . Sum_op Addition and substraction node is a single node that performs 2-complement additions and substractions with unlimited precision. digraph Sum { rankdir=LR; size=\"1,0.5\" node [shape = circle]; Sum; node [shape = point ]; q0 node [shape = point ]; q1 node [shape = point ]; q q0 -> Sum [ label =\"A\" ]; q1 -> Sum [ label =\"B\" ]; Sum -> q [ label = \"Y\" ]; } If the inputs do not have the same size, they are extended (sign or unsigned) to all have the same length. Forward Propagation \\(Y = \\sum_{i=0}^{\\infty} A_{i} - \\sum_{i=0}^{\\infty} B_{i}\\) \\(Y.max = \\sum_{i=0}^{\\infty} A_{i}.max - \\sum_{i=0}^{\\infty} B_{i}.min\\) \\(Y.min = \\sum_{i=0}^{\\infty} A_{i}.min - \\sum_{i=0}^{\\infty} B_{i}.max\\) Backward Propagation Backward propagation is possible when all the inputs but one are known. If all the inputs have known size. The algorithm can check and look for the inputs that have more precision than needed and reduce the max/min backwards. For example, if and all the inputs but one A ( \\(A_{0}\\) ) are known: \\(A_{0}.max = Y.max - \\sum{i=1}^{\\infty} A_{i}.min + \\sum_{i=0}^{\\infty} B_{i}.max\\) \\(A_{0}.min = Y.min - \\sum{i=1}^{\\infty} A_{i}.max + \\sum_{i=0}^{\\infty} B_{i}.min\\) If and all the inputs but one B ( \\(B_{0}\\) ) are known: \\(B_{0}.max = \\sum{i=0}^{\\infty} A_{i}.max - \\sum_{i=1}^{\\infty} B_{i}.min - Y.min\\) \\(B_{0}.min = \\sum{i=0}^{\\infty} A_{i}.min - \\sum_{i=1}^{\\infty} B_{i}.max - Y.max\\) Verilog Considerations In Verilog, the addition is unsigned if any of the inputs is unsigned. If any input is unsigned. all the inputs will be \"unsigned extended\" to match the largest value. This is different from Sum_Op semantics were each input is signed or unsigned extended independent of the other inputs. To match the semantics, when mixing signed and unsigned, all the potentially negative inputs must be converted to unsign with the Ntype_op::Tposs. logic signed [ 3 : 0 ] a = - 1 logic signed [ 4 : 0 ] c ; assign c = a + 1 'b1 ; The previous Verilog example extends everything to 5 bits (c) UNSIGNED extended because one of the inputs is unsigned (1b1 is unsigned in verilog, and 2sb1 is signed +1). LGraph semantics are different, everything is signed. c = 5 b01111 + 5 b0001 // this is the Verilog semantics by matching size c == - 16 ( !! ) Since the operation is commutative. A Sum(a,b) can have these options: | size | A_sign | B_sign | Operation | | a==b | S | S | EQ(a,b) | | a==b | S | U | EQ(a,b) | | a==b | U | S | EQ(a,b) | | a==b | U | U | EQ(a,b) | | a< b | S | S | LT(a,b) | | a< b | S | U | LT(a,Tposs(b)) | | a< b | U | S | LT(Tposs(a),b) | | a< b | U | U | LT(Tposs(a),Tposs(b)) | The Verilog addition/substraction output can have more bits than the inputs. This is the same as in LGraph Sum. Nevertheless, Verilog requires to specify the bits for all the input/outputs. This means that whenever Verilog drops precision an AND gate must be added. In the following examples only the 'g' and 'h' variables needed. wire [ 7 : 0 ] a ; wire [ 7 : 0 ] b ; wire [ 6 : 0 ] c ; wire [ 8 : 0 ] f = a + b ; // f = Sum(a,b) // a same size as b wire [ 8 : 0 ] f = a + c ; // f = Sum(a,Tposs(c)) wire [ 7 : 0 ] g = a + b ; // g = And(Sum(a,b),0x7F) wire [ 6 : 0 ] h = a + b ; // h = And(Sum(a,b),0x3F) Peephole Optimizations Y = x-0+0+... becomes Y = x+... Y = x-x+... becomes Y = ... Y = x+x+... becomes Y = (x<<1)+... Y = (x<<n)+(y<<m) where m>n becomes Y = (x+y<<(m-n)<<n Y = (~x)+1+... becomes Y = ...-x Y = a + (b<<n) becomes Y = {(a>>n)+b, a&n.mask} Y = a - (b<<n) becomes Y = {(a>>n)-b, a&n.mask} If every x,y... lower bit is zero Y=x+y+... becomes Y=((x>>1)+(y>>1)+..)<<1 Ntype_op::Mult Multiply operator. There is no Prod_Op that combines multiplication and division because unlike in Sum_Op, in integer operations the order matters (unlimited precision decimals may combine) ( a*(b/c) != (a*b)/c ). digraph Mult { rankdir=LR; size=\"1,0.5\" node [shape = circle]; Mult; node [shape = point ]; q0 node [shape = point ]; q q0 -> Mult [ label =\"A\" ]; Mult -> q [ label = \"Y\" ]; } Forward Propagation \\(Y = \\prod_{i=0}^{\\infty} A_{i}\\) \\(Tmax = \\prod_{i=0}^{\\infty} \\text{maxabs}(A_{i}.max, A_{i}.min)\\) \\(Tmin = \\prod_{i=0}^{\\infty} \\text{minabs}(A_{i}.max, A_{i}.min)\\) \\(neg = \\prod_{i=0}^{\\infty} A_{i}.sign\\) \\(known = \\forall_{i=0}^{\\infty} A_{i}.known\\) \\(Y.max = \\begin{cases} -Tmin & neg \\land known \\\\ Tmax & \\text{otherwise} \\end{cases}\\) \\(Y.min = \\begin{cases} Tmin & \\overline{neg} \\land known \\\\ -Tmax & \\text{otherwise} \\end{cases}\\) When the result sign is not known, the max/min is conservatively computed. Backward Propagation If only one input is missing, it is possible to infer the max/min from the output and the other inputs. As usual, if all the inputs and outputs are known, it is possible to backward propagate to further constraint the inputs. \\(Tmax = \\frac{\\prod_{i=1}^{\\infty} \\text{maxabs}(A_{i}.max, A_{i}.min)}{Y.min}\\) \\(Tmin = \\frac{\\prod_{i=1}^{\\infty} \\text{minabs}(A_{i}.max, A_{i}.min)}{Y.max}\\) \\(neg = Y.sign \\times \\prod_{i=1}^{\\infty} A_{i}.sign\\) \\(known = Y.known \\land \\forall_{i=1}^{\\infty} A_{i}.known\\) \\(A_{0}.max = \\begin{cases} -Tmin & neg \\land known \\\\ Tmax & \\text{otherwise} \\end{cases}\\) \\(A_{0}.min = \\begin{cases} Tmin & \\overline{neg} \\land known \\\\ -Tmax & \\text{otherwise} \\end{cases}\\) Verilog Considerations Unlike the Sum_Op, the Verilog 2 LiveHD translation does not need to extend the inputs to have matching sizes. Multiplying/dividing signed and unsigned numbers has the same result. The bit representation is the same if the result was signed or unsigned. LiveHD mult node result (Y) number of bits can be more efficient than in Verilog. E.g: if the max value of A0 is 3 (2 bits) and A1 is 5 (3bits). If the result is unsigned, the maximum result is 15 (4 bits). In Verilog, the result will always be 5 bits. If the Verilog result was to an unsigned variable. Either all the inputs were unsigned, or there should pass to an Ntype_op::Tposs to force the MSB as positive. This extra bit will be simplified but it will notify LGraph that the output is to be treated as unsigned. Peephole Optimizations Y = a*1*... becomes Y=a*... Y = a*0*... becomes Y=0 Y = power2a*... becomes Y=(...)<<log2(power2a) Y = (power2a+power2b)*... becomes tmp=... ; Y = (tmp+tmp<<power2b)<<(power2a-power2b) when power2a>power2b Y = (power2a-power2b)*... becomes tmp=... ; Y = (tmp-tmp<<power2b)<<(power2a-power2b) when power2a>power2b Div_op Division operator. The division operation is quite similar to the inverse of the multiplication, but a key difference is that only one driver is allowed for each input ('a' vs 'A'). digraph Div { rankdir=LR; size=\"1,0.5\" node [shape = circle]; Div; node [shape = point ]; q0 node [shape = point ]; q1 node [shape = point ]; q q0 -> Div [ label =\"a\" ]; q1 -> Div [ label =\"b\" ]; Div -> q [ label = \"Y\" ]; } Forward Propagation \\(Y = \\frac{a}{b}\\) \\(Tmax = \\frac{\\text{maxabs}(a.max,a.min)}{\\text{minabs}(b.max,b.min)}\\) \\(Tmin = \\frac{\\text{minabs}(a.max,a.min)}{\\text{maxabs}(b.max,b.min)}\\) \\(known = a.known \\land \\b.known\\) \\(neg = a.sign \\times b.sign\\) \\(Y.max = \\begin{cases} -Tmin & neg \\land known \\\\ Tmax & \\text{otherwise} \\end{cases}\\) \\(Y.min = \\begin{cases} Tmin & \\overline{neg} \\land known \\\\ -Tmax & \\text{otherwise} \\end{cases}\\) Backward Propagation The backward propagation from the division can extracted from the forward propagation. It is a simpler case of multiplication backward propagation. Verilog Considerations The same considerations as in the multiplication should be applied. Peephole Optimizations Y = a/1 becomes Y=a Y = 0/b becomes Y=0 Y = a/power2b becomes Y=a>>log2(power2b) if Y.known and !Y.neg Y = a/power2b becomes Y=1+~(a>>log2(power2b)) if Y.known and Y.neg Y = (x*c)/a if c.bits>a.bits becomes Y = x * (c/a) which should be a smaller division. If b is a constant and Y.known and !Y.neg . From the hackers delight, we know that the division can be changed for a multiplication Y=(a*(((1<<(a.bits+2)))/b+1))>>(a.bits+2) If a sign is not known . Then `Y = Y.neg? (~Y_unsigned+1):Y_unsigned` Modulo There is no mod cell (Ntype_op::Mod) in LGraph. The reason is that a modulo different from a power of 2 is very rare in hardware. If the language supports modulo operations, they must be translated to division/multiplication. y = a mod b It is the same as: y = a-b*(a/b) If b is a power of 2, the division optimization will transform the modulo operation to: y = a - (a>>n)<<n The add optimization should reduce it to: y = a & n.mask Not_op Bitwise Not operator digraph Not { rankdir=LR; size=\"1,0.5\" node [shape = circle]; Not; node [shape = point ]; q0 node [shape = point ]; q q0 -> Not [ label =\"a\" ]; Not -> q [ label = \"Y\" ]; } Forward Propagation \\(Y = \\text{bitwise-not}(\\text{a})\\) \\(Y.max = \\text{max}(~a.max,~a.min)\\) \\(Y.min = \\text{min}(~a.max,~a.min)\\) Backward Propagation \\(a.max = \\text{max}(~Y.max,~Y.min)\\) \\(a.min = \\text{min}(~Y.max,~Y.min)\\) Verilog Considerations Same semantics as verilog Peephole Optimizations No optimizations by itself, it has a single input. Other operations like Sum_Op can optimize when combined with Not_Op. And And is a typical AND gate with multiple inputs. All the inputs connect to pin 'A' because input order does not matter. The result is always a signed number. digraph And { rankdir=LR; size=\"1,0.5\" node [shape = circle]; And; node [shape = point ]; q0 node [shape = point ]; q q0 -> And [ label =\"A\" ]; And -> q [ label = \"Y\" ]; } Forward Propagation \\(Y = \\forall_{i=0}^{\\infty} Y \\& A_{i}\\) \\(m = \\forall_{i=0}^{\\infty} min(m,A_{i}.bits)\\) \\(Y.max = (1\\ll m)-1\\) \\(Y.min = -Y.max-1\\) Backward Propagation The And cell has a significant backpropagation impact. Even if some inputs had more bits, after the And cell the upper bits are dropped. This allows the back propagation to indicate that those bits are useless. $a.max = Y.max $ $a.min = -Y.max-1 $ Other Considerations Peephole Optimizations Ntype_op::Tposs Every value is signed but some times a value must be treated as unsigned. The Tposs operator stands for To Positive Signed. It does nothing if the input is signed and positive, but behaves like concatenating a zero bit to the most significant bit of the input value. The result is an always positive value. digraph Unsigned { rankdir=LR; size=\"1,0.5\" node [shape = circle]; Unsigned; node [shape = point ]; q0 node [shape = point ]; q q0 -> Unsigned [ label =\"a\" ]; Unsigned -> q [ label = \"Y\" ]; } Forward Propagation \\(Y = \\begin{cases} a & a \\get 0 \\\\ a.mask+a+1 & otherwise \\end{cases}\\) \\(Y.max = \\begin{cases} a.max & a.min \\get 0 \\\\ a.mask & otherwise \\end{cases}\\) \\(Y.min = 0\\) Backward Propagation $a.max = Y.max $ $a.min = -Y.max-1 $ Other Considerations It is important to notice that Ntype_op::Tposs is different from a absolute calculation. It is like a concatenating a zero to convert the signed values. Peephole Optimizations Y = Tposs(a) becomes Y= a when a.min>=0 Y = And(Tposs(a),a.mask) becomes Y= a Y = And(Tposs(a),b) can become Y= Tposs(And(a,b)) Y = Tposs(const) becomes Y=const when const>=0 Comparators LT, GT, EQ There are only 3 comparators. Other typically found like LE, GE, and NE can be created by simply negating one of the LGraph comparators. GT = ~LE , LT = ~GE , and NE = ~EQ . Forward Propagation Y = A LT B Y = A0 LT B and A1 LT B Y = A0 LT B0 and A1 LT B0 and A0 LT B1 and A1 LT B1 Backward Propagation Peephole Optimizations Other Considerations Verilog treats all the inputs as unsigned if any of them is unsigned. LGraph treats all the inputs as signed all the time. SHL_op Shift Left performs the typical shift left when there is a single amount ( a<<amt ). The allow supports multiple left shift amounts. In this case the shift left is used to build one hot encoding mask. ( 1<<(1,2) == (1<<1)|(1<<2) ) The result for when there are not amounts ( a<<() ) is -1 . Notice that this is not ZERO but -1. The -1 means that all the bits are set. The reason is that when there are no offsets in the onehot encoding, the default functionality is to select all the bit masks, and hence -1. SRA_op Logical or sign extension shift right. Verilog Considerations Verilog has 2 types of shift >> and >>> . The first is unsigned right shift, the 2nd is arithmetic right shift. LGraph only has arithmetic right shift (ShiftRigt_op). The verilog translation should make the value unsigned ( ShiftRigt(Join(0,a),b) ) before calling the shift operation. Conversely, for a >>> if the input is Verilog unsigned ( ShiftRigt(a,b) ) Mux_op Forward Propagation \\(Y = P_{(1+P_{0}}\\) \\(Y.max = (1\\ll m)-1\\) \\(Y.max = \\forall_{i=0}^{\\infty} P_{i}.max\\) \\(Y.max = \\forall_{i=0}^{\\infty} P_{i}.min\\) Backward Propagation Peephole Optimizations Other Considerations LUT_op And_op reduce AND a =u= -1 // unsigned equal Or_op reduce OR a != 0 Xor_op reduce xor is a chain of XORs. Const_op SFlop_op AFlop_op FFlop_op Latch_op Memory_op Memory is the basic block to represent SRAM-like structures. Any large storage will benefit from using memory arrays instead of flops, which are slower to simulate. These memories are highly configurable. digraph Memory { rankdir=LR; size=\"2,1\" node [shape = circle]; Memory; node [shape = point ]; q0 node [shape = point ]; q1 node [shape = point ]; q2 node [shape = point ]; q3 node [shape = point ]; q4 node [shape = point ]; q5 node [shape = point ]; q6 node [shape = point ]; q7 node [shape = point ]; q8 node [shape = point ]; q9 node [shape = point ]; q10 node [shape = point ]; q q0 -> Memory [ label =\"a (addr)\" ]; q1 -> Memory [ label =\"b (bits)\" ]; q2 -> Memory [ label =\"c (clock)\" ]; q3 -> Memory [ label =\"d (data in)\" ]; q4 -> Memory [ label =\"e (enable)\" ]; q5 -> Memory [ label =\"f (fwd)\" ]; q6 -> Memory [ label =\"l (latency)\" ]; q7 -> Memory [ label =\"m (wmask)\" ]; q8 -> Memory [ label =\"p (posedge)\" ]; q9 -> Memory [ label =\"s (size)\" ]; q10 -> Memory [ label =\"w (wmode)\" ]; Memory -> q [ label =\"Q (data out)\" ]; } s ( size ) is for the array size in number of entries b ( bits ) is the number of bits per entry f ( fwd ) points to a 0/1 constant driver pin to indicate if writes forward value ( 0b0 for write-only ports). Effectively, it means zero cycles read latency when enabled. fwd is more than just setting latency=0 . Even with latency zero, the write delay affects until the result is visible. With fwd enabled, the write latency does not matter to observe the results. This requires a costly forwarding logic. c , d , e , q ... are the memory configuration, data, address ports Ports ( a , c ... p , w ) are arrays/vectors to support multiported memories. If a single instance exists in a port, the same is used across all the ports. E.g: if clock ( c ) is populated: mem1.c = clk1 // clk for all the memory ports mem2.c[0] = clk1 // clock for memory port 0 mem2.c[1] = clk2 // clock for memory port 1 mem2.c[2] = clk2 // clock for memory port 2 Each memory port (rd, wr, or rd/wr) has the following ports: a ( addr ) points to the driver pin for the address. The address bits should match the array size ( ceil(log2(s)) ) c ( clock ) points to the clock driver pin d ( data_in ) points to the write data driver pin (read result is in q port). e ( enable ) points to the driver pin for read/write enable. l ( latency ) points to an integer constant driver pin (2 bits always). For writes latency from 1 to 3 , for reads latency from 0 to 3 w ( wmask ) Points to the write mask (1 == write, 0==no write). The mask bust be a big as the number of bits per entry ( b ). The wmask pin can be disconnected which means no write mask (a write will write all the bits). p ( posedge ) points to a 1/0 constant driver pin m ( mode ) points to the driver pin or switching between read (0) and write mode (1) (single bit) Q ( data_out ) is a driver pin with the data read from the memory All the entries but the wmask must be populated. If the wmask is not set, a full write size is expected. Read-only ports do not have data and wmask fields if the write use the low ports (0,1...). By placing the read-only ports to the high numbers, we can avoid populating the wmask ( m ) and data out ( q ) ports. If the read ports use low port numbers those fields must be populated to allow the correct matching between write port ( a[n] ) and write result ( q[n] ). All the ports must be populated with the correct size. This is important because some modules access the field by bit position. If it is not used, it will point to a zero constant with the correct number of bits. The exception to this is wmask which, if b indicates 8 bits per entry, will be equivalent to 0xFF . Setting wmask to 0b1 will mean a 1 bit zero, and the memory will be incorrectly operated. The memory usually has power of two sizes. If the size is not a power of 2, the address is rounded up. Writes to the invalid addresses will generated random memory updates. Reads should read random data. Forward Propagation Backward Propagation Other Considerations Peephole Optimizations SubGraph_op And_Op: bitwise AND with 2 outputs single bit reduction (RED) or bitwise Y = VAL&..&VAL ; RED= &Y Forward Propagation \\(Y = \\left\\{\\begin{matrix} VAL>>OFF & SZ==0 \\\\ (VAL>>OFF) \\& (1<<SZ)-1) & otherwise \\end{matrix}\\right.\\) \\(Y.max = \\left\\{\\begin{matrix} VAL.max>>OFF & SZ==0 \\\\ (VAL.max>>OFF) \\& (1<<SZ)-1) & otherwise \\end{matrix}\\right.\\) \\(Y.min = 0\\) \\(Y.sign = 0\\) Backward Propagation The sign can not be backward propagated because Pick_Op removes the sign no matter the input sign. Generate PDF pandoc --pdf-engine=xelatex --toc -N GitHub-use.md lgraph.md --mathjax --filter pandoc-graphviz.py -o ~/tmp/pp.pdf https://github.com/Wandmalfarbe/pandoc-latex-template https://pianomanfrazier.com/post/write-a-book-with-markdown/ To be continued ... LGraph Optimization Not all the nodes have the same complexity overhead. When performing peephole optimization is possible to trade one set of nodes for others. In general, we have this set of overheads: 0 overhead: not, get_mask, set_mask, sext, and SHL/SRA with constant shift amounts. The rational is that those are just \"wiring\" cells to connect or extract wires across. The NOT gate is not really zero, but it could be easily mixed with sorrounding cells. 1 overhead: And, Or, Xor, LUT, Mux 3 overhead: LT, GT, EQ, Ror 4 overhead: Less than 4 bit output Sum, and SHL/SRA with non-compile time shift amount. This can be costly an require hardware like barrel shifters. 5 overhead: large Sum, SHL/SRA. 6 Overhead: Mult/Div If a overhead level can be elininated having a small number of different cells with a smaller overhead level,the translation makes sense. Notice the \"small number of cells\", after all everything can be translated to nand gates. A 3x factor is somewhat reasonable. This means that a 5-level overhead is fine to be replaced for 3 4-level (or 3 3-level) but not for 4 4-level overhead. Zero overhead cells are not included in the list of cells in the replacement. This is a heuristic. Once works, it is a nice target to use AI to decide when/if a transformation is worth.","title":"LGraph"},{"location":"livehd/02-lgraph/#lgraph","text":"Warning This document is not updated to the latest changes LGraph is the graph-based data structure used inside LiveHD. Together with LNAST, it is one of the key data structures. The LGraph can be built directly with passes like Yosys, or through LNAST to LGraph translations. The LNAST builds a gated-SSA which is translated to LGraph. Understanding the LGraph is needed if you want to build a LiveHD pass.","title":"LGraph"},{"location":"livehd/02-lgraph/#lgraph-api","text":"A single LGraph represents a single netlist module. LGraph is composed of nodes, node pins, edges and tables of attributes. An LGraph node is affiliated with a node type and each type defines different amounts of input and output node pins. For example, a node can have 3 input ports and 2 output pins. Each of the input/output pins can have many edges to other graph nodes. Every node pin has an affiliated node pid. In the code, every node_pin has a Port_ID . A pair of driver pin and sink pin constitutes an edge. In the following API example, an edge is connected from a driver pin (pid1) to a sink pin (pid3). The bitwidth of the driver pin determines the edge bitwidth.","title":"LGraph API"},{"location":"livehd/02-lgraph/#node-node_pin-and-edge-construction","text":"create node new_node = lg -> create_node () //note: type and/or bits still need to be assigned later create node with node type assigned new_node = lg -> create_node ( Node_type_Op ) //note: recommended way if you know the target node type create a constant node new_node = lg -> create_node_const ( value ) //note: recommended way to create a const node setup default driver pin for pin_0 of a node driver_pin = new_node . setup_driver_pin (); //note: when you know the node type only has one output pin setup default sink pin for pin_0 of a node sink_pin = new_node . setup_sink_pin () //note: when you know the node type only has one input pin setup driver pin for pin_x of a node driver_pin = new_node . setup_driver_pin ( pid ) //note: when you know the pid, same as sink_pin get the pid value of a node_pin object node_pin . get_pid () add an edge between driver_pin and sink_pin driver_pin . connect ( sink_pin ); get the driver node of an edge driver_node = edge . driver . get_node () use node as the index/key for a container absl :: flat_hash_map < Node :: Compact , int > my_map ; my_map [ node1 . get_compact ()] = 77 ; my_map [ node2 . get_compact ()] = 42 ; ... use node_pin as the index/key for a container absl :: flat_hash_map < Node_pin :: Compact , int > my_map ; my_map [ node_pin1 . get_compact ()] = 14 ; my_map [ node_pin2 . get_compact ()] = 58 ; ... get the node_pin back from a Node_pin::Compact Node_pin dpin ( lg , some_dpin . get_compact ()) get the node back from a Node::Compact Node node ( lg , some_node . get_compact ()) create a LGraph input(output) with the name new_node_pin = lg -> add_graph_input ( std :: string_view ) debug information of a node node . debug_name () debug information of a node_pin node_pin . debug_name () iterate output edges and get node/pin information from it for ( auto & out : node . out_edges ()) { auto dpin = out . driver ; auto dpin_pid = dpin . get_pid (); auto dnode_name = dpin . get_node (). debug_name (); auto snode_name = out . sink . get_node (). debug_name (); auto spin_pid = out . sink . get_pid (); auto dpin_name = dpin . has_name () ? dpin . get_name () : \"\" ; auto dbits = dpin . get_bits (); fmt :: print ( \" {}->{}[label= \\\" {}b :{} :{} :{} \\\" ]; \\n \" , dnode_name , snode_name , dbits , dpin_pid , spin_pid , dpin_name ); }","title":"Node, Node_pin, and Edge Construction"},{"location":"livehd/02-lgraph/#non-hierarchical-traversal-iterators","text":"LGraph allows forward and backward traversals in the nodes (bidirectional graph). The reason is that some algorithms need a forward and some a backward traversal, being bidirectional would help. Whenever possible, the fast iterator should be used. for ( const auto & node : lg -> fast ()) {...} // unordered but very fast traversal for ( const auto & node : lg -> forward ()) {...} // propagates forward from each input/constant for ( const auto & node : lg -> backward ()) {...} // propagates backward from each output The LGraph iterator such as for(auto node: g->forward()) do not visit graph input and outputs. // simple way using lambda lg->each_graph_input([&](const Node_pin &pin){ //your operation with graph_input node_pin; });","title":"Non-Hierarchical Traversal Iterators"},{"location":"livehd/02-lgraph/#hierarchical-traversal-iterators","text":"LGraph supports hierarchical traversal. Each sub-module of a hierarchical design will be transformed into a new LGraph and represented as a sub-graph node in the parent module. If the hierarchical traversal is used, every time the iterator encounters a sub-graph node, it will load the sub-graph persistent tables to the memory and traverse the subgraph recursively, ignoring the sub-graph input/outputs. This cross-module traversal treats the hierarchical netlist just like a flattened design. In this way, all integrated third-party tools could automatically achieve global design optimization or analysis by leveraging the LGraph hierarchical traversal feature. for ( const auto & node : lg -> forward_hier ()) {...}","title":"Hierarchical Traversal Iterators"},{"location":"livehd/02-lgraph/#edge-iterators","text":"To iterate over the input edges of node, simply call: for ( const auto & inp_edge : node . inp_edges ()) {...} And for output edges: for ( const auto & out_edge : node . out_edges ()) {...}","title":"Edge Iterators"},{"location":"livehd/02-lgraph/#lgraph-attribute-design","text":"Design attribute stands for the characteristic given to a LGraph node or node pin. For instance, the characteristic of a node name and node physical placement. Despite a single LGraph stands for a particular module, it could be instantiated multiple times. In this case, same module could have different attribute at different hierarchy of the netlist. A good design of attribute structure should be able to represent both non-hierarchical and hierarchical characteristic.","title":"LGraph Attribute Design"},{"location":"livehd/02-lgraph/#non-hierarchical-attribute","text":"Non-hierarchical LGraph attributes include pin name, node name and line of source code. Such properties should be the same across different LGraph instantia- tions. Two instantiations of the same LGraph module will have the exact same user-defined node name on every node. For example, instantiations of a subgraph-2 in both top and subgraph-1 would maintain the same non-hierarchical attribute table. node . set_name ( std :: string_view name );","title":"Non-Hierarchical Attribute"},{"location":"livehd/02-lgraph/#hierarchical-attribute","text":"LGraph also support hierarchical attribute. It is achieved by using a tree data structure to record the design hierarchy. In LGraph, every graph has a unique id (lg_id), every instantiation of a graph would form some nodes in the tree and every tree node is indexed by a unique hierarchical id (hid). We are able to identify a unique instantiation of a graph and generate its own hierarchical attribute table. An example of hierarchical attribute is wire-delay. node_pin . set_delay ( float delay );","title":"Hierarchical Attribute"},{"location":"livehd/02-lgraph/#lgraph-node-type-semantics","text":"For each LGraph node, there is a specific semantic. This section explains the operation to perform for each node. It includes a precise way to compute the maximum and minimum value for the output. In LGraph, the cells operate like having unlimited precision with signed numbers. Most HDLs focus on unsigned, but LiveHD handles the superset (sign and unlimited precision). The precision is reduced only explicitly with few operations like and-gate with masks or Shifts. In LGraph, an unsigned value is a value that can not be negative. The document also explains corner cases in relationship to Verilog and how to convert to/from Verilog semantics. These are corner cases to deal with sign and precision. Each HDL may have different semantics, the Verilog is to showcase the specifics. In general the nodes have a single output with the exception of complex nodes like subgraphs or memories. Ntypes with single output, have 'Y' as output. The inputs are single characters 'A', 'B'... For most inputs, there can be many drivers. E.g: a single Sum cell can do Y=3+20+a0+a3 where A_{0} = 3 , A_{1} = 20 , A_{2} = a0 , and A_{3} = a3 . If an input can not have multiple drivers, a lower case name is used ('a', 'b'...). E.g: the right shift cell is Y=a>>b because only one driver can connect to 'a' and 'b'. The section includes description on how to compute the maximum ( max ) and minimum ( min ) allowed result range. This is used by the bitwidth inference pass. To ease the explanation, a sign value means that the result may be negative ( a.sign == a.min<0 ). known is true if the result sign is known ( a.known == a.max<0 or a.min>=0 ), either positive or negative ( neg == a.max<0 ). The cells explanation also requires the to compute the bit mask ( a.mask == (1<<a.bits)-1 ). For any value ( a ), the number of bits required ( bits ) is a.bits = log2(absmax(a.max,a.min))+a.sign?1:0 .","title":"LGraph Node Type Semantics"},{"location":"livehd/02-lgraph/#sum_op","text":"Addition and substraction node is a single node that performs 2-complement additions and substractions with unlimited precision. digraph Sum { rankdir=LR; size=\"1,0.5\" node [shape = circle]; Sum; node [shape = point ]; q0 node [shape = point ]; q1 node [shape = point ]; q q0 -> Sum [ label =\"A\" ]; q1 -> Sum [ label =\"B\" ]; Sum -> q [ label = \"Y\" ]; } If the inputs do not have the same size, they are extended (sign or unsigned) to all have the same length.","title":"Sum_op"},{"location":"livehd/02-lgraph/#forward-propagation","text":"\\(Y = \\sum_{i=0}^{\\infty} A_{i} - \\sum_{i=0}^{\\infty} B_{i}\\) \\(Y.max = \\sum_{i=0}^{\\infty} A_{i}.max - \\sum_{i=0}^{\\infty} B_{i}.min\\) \\(Y.min = \\sum_{i=0}^{\\infty} A_{i}.min - \\sum_{i=0}^{\\infty} B_{i}.max\\)","title":"Forward Propagation"},{"location":"livehd/02-lgraph/#backward-propagation","text":"Backward propagation is possible when all the inputs but one are known. If all the inputs have known size. The algorithm can check and look for the inputs that have more precision than needed and reduce the max/min backwards. For example, if and all the inputs but one A ( \\(A_{0}\\) ) are known: \\(A_{0}.max = Y.max - \\sum{i=1}^{\\infty} A_{i}.min + \\sum_{i=0}^{\\infty} B_{i}.max\\) \\(A_{0}.min = Y.min - \\sum{i=1}^{\\infty} A_{i}.max + \\sum_{i=0}^{\\infty} B_{i}.min\\) If and all the inputs but one B ( \\(B_{0}\\) ) are known: \\(B_{0}.max = \\sum{i=0}^{\\infty} A_{i}.max - \\sum_{i=1}^{\\infty} B_{i}.min - Y.min\\) \\(B_{0}.min = \\sum{i=0}^{\\infty} A_{i}.min - \\sum_{i=1}^{\\infty} B_{i}.max - Y.max\\)","title":"Backward Propagation"},{"location":"livehd/02-lgraph/#verilog-considerations","text":"In Verilog, the addition is unsigned if any of the inputs is unsigned. If any input is unsigned. all the inputs will be \"unsigned extended\" to match the largest value. This is different from Sum_Op semantics were each input is signed or unsigned extended independent of the other inputs. To match the semantics, when mixing signed and unsigned, all the potentially negative inputs must be converted to unsign with the Ntype_op::Tposs. logic signed [ 3 : 0 ] a = - 1 logic signed [ 4 : 0 ] c ; assign c = a + 1 'b1 ; The previous Verilog example extends everything to 5 bits (c) UNSIGNED extended because one of the inputs is unsigned (1b1 is unsigned in verilog, and 2sb1 is signed +1). LGraph semantics are different, everything is signed. c = 5 b01111 + 5 b0001 // this is the Verilog semantics by matching size c == - 16 ( !! ) Since the operation is commutative. A Sum(a,b) can have these options:","title":"Verilog Considerations"},{"location":"livehd/02-lgraph/#size-a_sign-b_sign-operation","text":"| a==b | S | S | EQ(a,b) | | a==b | S | U | EQ(a,b) | | a==b | U | S | EQ(a,b) | | a==b | U | U | EQ(a,b) | | a< b | S | S | LT(a,b) | | a< b | S | U | LT(a,Tposs(b)) | | a< b | U | S | LT(Tposs(a),b) | | a< b | U | U | LT(Tposs(a),Tposs(b)) | The Verilog addition/substraction output can have more bits than the inputs. This is the same as in LGraph Sum. Nevertheless, Verilog requires to specify the bits for all the input/outputs. This means that whenever Verilog drops precision an AND gate must be added. In the following examples only the 'g' and 'h' variables needed. wire [ 7 : 0 ] a ; wire [ 7 : 0 ] b ; wire [ 6 : 0 ] c ; wire [ 8 : 0 ] f = a + b ; // f = Sum(a,b) // a same size as b wire [ 8 : 0 ] f = a + c ; // f = Sum(a,Tposs(c)) wire [ 7 : 0 ] g = a + b ; // g = And(Sum(a,b),0x7F) wire [ 6 : 0 ] h = a + b ; // h = And(Sum(a,b),0x3F)","title":"| size | A_sign | B_sign | Operation |"},{"location":"livehd/02-lgraph/#peephole-optimizations","text":"Y = x-0+0+... becomes Y = x+... Y = x-x+... becomes Y = ... Y = x+x+... becomes Y = (x<<1)+... Y = (x<<n)+(y<<m) where m>n becomes Y = (x+y<<(m-n)<<n Y = (~x)+1+... becomes Y = ...-x Y = a + (b<<n) becomes Y = {(a>>n)+b, a&n.mask} Y = a - (b<<n) becomes Y = {(a>>n)-b, a&n.mask} If every x,y... lower bit is zero Y=x+y+... becomes Y=((x>>1)+(y>>1)+..)<<1","title":"Peephole Optimizations"},{"location":"livehd/02-lgraph/#ntype_opmult","text":"Multiply operator. There is no Prod_Op that combines multiplication and division because unlike in Sum_Op, in integer operations the order matters (unlimited precision decimals may combine) ( a*(b/c) != (a*b)/c ). digraph Mult { rankdir=LR; size=\"1,0.5\" node [shape = circle]; Mult; node [shape = point ]; q0 node [shape = point ]; q q0 -> Mult [ label =\"A\" ]; Mult -> q [ label = \"Y\" ]; }","title":"Ntype_op::Mult"},{"location":"livehd/02-lgraph/#forward-propagation_1","text":"\\(Y = \\prod_{i=0}^{\\infty} A_{i}\\) \\(Tmax = \\prod_{i=0}^{\\infty} \\text{maxabs}(A_{i}.max, A_{i}.min)\\) \\(Tmin = \\prod_{i=0}^{\\infty} \\text{minabs}(A_{i}.max, A_{i}.min)\\) \\(neg = \\prod_{i=0}^{\\infty} A_{i}.sign\\) \\(known = \\forall_{i=0}^{\\infty} A_{i}.known\\) \\(Y.max = \\begin{cases} -Tmin & neg \\land known \\\\ Tmax & \\text{otherwise} \\end{cases}\\) \\(Y.min = \\begin{cases} Tmin & \\overline{neg} \\land known \\\\ -Tmax & \\text{otherwise} \\end{cases}\\) When the result sign is not known, the max/min is conservatively computed.","title":"Forward Propagation"},{"location":"livehd/02-lgraph/#backward-propagation_1","text":"If only one input is missing, it is possible to infer the max/min from the output and the other inputs. As usual, if all the inputs and outputs are known, it is possible to backward propagate to further constraint the inputs. \\(Tmax = \\frac{\\prod_{i=1}^{\\infty} \\text{maxabs}(A_{i}.max, A_{i}.min)}{Y.min}\\) \\(Tmin = \\frac{\\prod_{i=1}^{\\infty} \\text{minabs}(A_{i}.max, A_{i}.min)}{Y.max}\\) \\(neg = Y.sign \\times \\prod_{i=1}^{\\infty} A_{i}.sign\\) \\(known = Y.known \\land \\forall_{i=1}^{\\infty} A_{i}.known\\) \\(A_{0}.max = \\begin{cases} -Tmin & neg \\land known \\\\ Tmax & \\text{otherwise} \\end{cases}\\) \\(A_{0}.min = \\begin{cases} Tmin & \\overline{neg} \\land known \\\\ -Tmax & \\text{otherwise} \\end{cases}\\)","title":"Backward Propagation"},{"location":"livehd/02-lgraph/#verilog-considerations_1","text":"Unlike the Sum_Op, the Verilog 2 LiveHD translation does not need to extend the inputs to have matching sizes. Multiplying/dividing signed and unsigned numbers has the same result. The bit representation is the same if the result was signed or unsigned. LiveHD mult node result (Y) number of bits can be more efficient than in Verilog. E.g: if the max value of A0 is 3 (2 bits) and A1 is 5 (3bits). If the result is unsigned, the maximum result is 15 (4 bits). In Verilog, the result will always be 5 bits. If the Verilog result was to an unsigned variable. Either all the inputs were unsigned, or there should pass to an Ntype_op::Tposs to force the MSB as positive. This extra bit will be simplified but it will notify LGraph that the output is to be treated as unsigned.","title":"Verilog Considerations"},{"location":"livehd/02-lgraph/#peephole-optimizations_1","text":"Y = a*1*... becomes Y=a*... Y = a*0*... becomes Y=0 Y = power2a*... becomes Y=(...)<<log2(power2a) Y = (power2a+power2b)*... becomes tmp=... ; Y = (tmp+tmp<<power2b)<<(power2a-power2b) when power2a>power2b Y = (power2a-power2b)*... becomes tmp=... ; Y = (tmp-tmp<<power2b)<<(power2a-power2b) when power2a>power2b","title":"Peephole Optimizations"},{"location":"livehd/02-lgraph/#div_op","text":"Division operator. The division operation is quite similar to the inverse of the multiplication, but a key difference is that only one driver is allowed for each input ('a' vs 'A'). digraph Div { rankdir=LR; size=\"1,0.5\" node [shape = circle]; Div; node [shape = point ]; q0 node [shape = point ]; q1 node [shape = point ]; q q0 -> Div [ label =\"a\" ]; q1 -> Div [ label =\"b\" ]; Div -> q [ label = \"Y\" ]; }","title":"Div_op"},{"location":"livehd/02-lgraph/#forward-propagation_2","text":"\\(Y = \\frac{a}{b}\\) \\(Tmax = \\frac{\\text{maxabs}(a.max,a.min)}{\\text{minabs}(b.max,b.min)}\\) \\(Tmin = \\frac{\\text{minabs}(a.max,a.min)}{\\text{maxabs}(b.max,b.min)}\\) \\(known = a.known \\land \\b.known\\) \\(neg = a.sign \\times b.sign\\) \\(Y.max = \\begin{cases} -Tmin & neg \\land known \\\\ Tmax & \\text{otherwise} \\end{cases}\\) \\(Y.min = \\begin{cases} Tmin & \\overline{neg} \\land known \\\\ -Tmax & \\text{otherwise} \\end{cases}\\)","title":"Forward Propagation"},{"location":"livehd/02-lgraph/#backward-propagation_2","text":"The backward propagation from the division can extracted from the forward propagation. It is a simpler case of multiplication backward propagation.","title":"Backward Propagation"},{"location":"livehd/02-lgraph/#verilog-considerations_2","text":"The same considerations as in the multiplication should be applied.","title":"Verilog Considerations"},{"location":"livehd/02-lgraph/#peephole-optimizations_2","text":"Y = a/1 becomes Y=a Y = 0/b becomes Y=0 Y = a/power2b becomes Y=a>>log2(power2b) if Y.known and !Y.neg Y = a/power2b becomes Y=1+~(a>>log2(power2b)) if Y.known and Y.neg Y = (x*c)/a if c.bits>a.bits becomes Y = x * (c/a) which should be a smaller division. If b is a constant and Y.known and !Y.neg . From the hackers delight, we know that the division can be changed for a multiplication Y=(a*(((1<<(a.bits+2)))/b+1))>>(a.bits+2) If a sign is not known . Then `Y = Y.neg? (~Y_unsigned+1):Y_unsigned`","title":"Peephole Optimizations"},{"location":"livehd/02-lgraph/#modulo","text":"There is no mod cell (Ntype_op::Mod) in LGraph. The reason is that a modulo different from a power of 2 is very rare in hardware. If the language supports modulo operations, they must be translated to division/multiplication. y = a mod b It is the same as: y = a-b*(a/b) If b is a power of 2, the division optimization will transform the modulo operation to: y = a - (a>>n)<<n The add optimization should reduce it to: y = a & n.mask","title":"Modulo"},{"location":"livehd/02-lgraph/#not_op","text":"Bitwise Not operator digraph Not { rankdir=LR; size=\"1,0.5\" node [shape = circle]; Not; node [shape = point ]; q0 node [shape = point ]; q q0 -> Not [ label =\"a\" ]; Not -> q [ label = \"Y\" ]; }","title":"Not_op"},{"location":"livehd/02-lgraph/#forward-propagation_3","text":"\\(Y = \\text{bitwise-not}(\\text{a})\\) \\(Y.max = \\text{max}(~a.max,~a.min)\\) \\(Y.min = \\text{min}(~a.max,~a.min)\\)","title":"Forward Propagation"},{"location":"livehd/02-lgraph/#backward-propagation_3","text":"\\(a.max = \\text{max}(~Y.max,~Y.min)\\) \\(a.min = \\text{min}(~Y.max,~Y.min)\\)","title":"Backward Propagation"},{"location":"livehd/02-lgraph/#verilog-considerations_3","text":"Same semantics as verilog","title":"Verilog Considerations"},{"location":"livehd/02-lgraph/#peephole-optimizations_3","text":"No optimizations by itself, it has a single input. Other operations like Sum_Op can optimize when combined with Not_Op.","title":"Peephole Optimizations"},{"location":"livehd/02-lgraph/#and","text":"And is a typical AND gate with multiple inputs. All the inputs connect to pin 'A' because input order does not matter. The result is always a signed number. digraph And { rankdir=LR; size=\"1,0.5\" node [shape = circle]; And; node [shape = point ]; q0 node [shape = point ]; q q0 -> And [ label =\"A\" ]; And -> q [ label = \"Y\" ]; }","title":"And"},{"location":"livehd/02-lgraph/#forward-propagation_4","text":"\\(Y = \\forall_{i=0}^{\\infty} Y \\& A_{i}\\) \\(m = \\forall_{i=0}^{\\infty} min(m,A_{i}.bits)\\) \\(Y.max = (1\\ll m)-1\\) \\(Y.min = -Y.max-1\\)","title":"Forward Propagation"},{"location":"livehd/02-lgraph/#backward-propagation_4","text":"The And cell has a significant backpropagation impact. Even if some inputs had more bits, after the And cell the upper bits are dropped. This allows the back propagation to indicate that those bits are useless. $a.max = Y.max $ $a.min = -Y.max-1 $","title":"Backward Propagation"},{"location":"livehd/02-lgraph/#other-considerations","text":"","title":"Other Considerations"},{"location":"livehd/02-lgraph/#peephole-optimizations_4","text":"","title":"Peephole Optimizations"},{"location":"livehd/02-lgraph/#ntype_optposs","text":"Every value is signed but some times a value must be treated as unsigned. The Tposs operator stands for To Positive Signed. It does nothing if the input is signed and positive, but behaves like concatenating a zero bit to the most significant bit of the input value. The result is an always positive value. digraph Unsigned { rankdir=LR; size=\"1,0.5\" node [shape = circle]; Unsigned; node [shape = point ]; q0 node [shape = point ]; q q0 -> Unsigned [ label =\"a\" ]; Unsigned -> q [ label = \"Y\" ]; }","title":"Ntype_op::Tposs"},{"location":"livehd/02-lgraph/#forward-propagation_5","text":"\\(Y = \\begin{cases} a & a \\get 0 \\\\ a.mask+a+1 & otherwise \\end{cases}\\) \\(Y.max = \\begin{cases} a.max & a.min \\get 0 \\\\ a.mask & otherwise \\end{cases}\\) \\(Y.min = 0\\)","title":"Forward Propagation"},{"location":"livehd/02-lgraph/#backward-propagation_5","text":"$a.max = Y.max $ $a.min = -Y.max-1 $","title":"Backward Propagation"},{"location":"livehd/02-lgraph/#other-considerations_1","text":"It is important to notice that Ntype_op::Tposs is different from a absolute calculation. It is like a concatenating a zero to convert the signed values.","title":"Other Considerations"},{"location":"livehd/02-lgraph/#peephole-optimizations_5","text":"Y = Tposs(a) becomes Y= a when a.min>=0 Y = And(Tposs(a),a.mask) becomes Y= a Y = And(Tposs(a),b) can become Y= Tposs(And(a,b)) Y = Tposs(const) becomes Y=const when const>=0","title":"Peephole Optimizations"},{"location":"livehd/02-lgraph/#comparators","text":"LT, GT, EQ There are only 3 comparators. Other typically found like LE, GE, and NE can be created by simply negating one of the LGraph comparators. GT = ~LE , LT = ~GE , and NE = ~EQ .","title":"Comparators"},{"location":"livehd/02-lgraph/#forward-propagation_6","text":"Y = A LT B Y = A0 LT B and A1 LT B Y = A0 LT B0 and A1 LT B0 and A0 LT B1 and A1 LT B1","title":"Forward Propagation"},{"location":"livehd/02-lgraph/#backward-propagation_6","text":"","title":"Backward Propagation"},{"location":"livehd/02-lgraph/#peephole-optimizations_6","text":"","title":"Peephole Optimizations"},{"location":"livehd/02-lgraph/#other-considerations_2","text":"Verilog treats all the inputs as unsigned if any of them is unsigned. LGraph treats all the inputs as signed all the time.","title":"Other Considerations"},{"location":"livehd/02-lgraph/#shl_op","text":"Shift Left performs the typical shift left when there is a single amount ( a<<amt ). The allow supports multiple left shift amounts. In this case the shift left is used to build one hot encoding mask. ( 1<<(1,2) == (1<<1)|(1<<2) ) The result for when there are not amounts ( a<<() ) is -1 . Notice that this is not ZERO but -1. The -1 means that all the bits are set. The reason is that when there are no offsets in the onehot encoding, the default functionality is to select all the bit masks, and hence -1.","title":"SHL_op"},{"location":"livehd/02-lgraph/#sra_op","text":"Logical or sign extension shift right.","title":"SRA_op"},{"location":"livehd/02-lgraph/#verilog-considerations_4","text":"Verilog has 2 types of shift >> and >>> . The first is unsigned right shift, the 2nd is arithmetic right shift. LGraph only has arithmetic right shift (ShiftRigt_op). The verilog translation should make the value unsigned ( ShiftRigt(Join(0,a),b) ) before calling the shift operation. Conversely, for a >>> if the input is Verilog unsigned ( ShiftRigt(a,b) )","title":"Verilog Considerations"},{"location":"livehd/02-lgraph/#mux_op","text":"","title":"Mux_op"},{"location":"livehd/02-lgraph/#forward-propagation_7","text":"\\(Y = P_{(1+P_{0}}\\) \\(Y.max = (1\\ll m)-1\\) \\(Y.max = \\forall_{i=0}^{\\infty} P_{i}.max\\) \\(Y.max = \\forall_{i=0}^{\\infty} P_{i}.min\\)","title":"Forward Propagation"},{"location":"livehd/02-lgraph/#backward-propagation_7","text":"","title":"Backward Propagation"},{"location":"livehd/02-lgraph/#peephole-optimizations_7","text":"","title":"Peephole Optimizations"},{"location":"livehd/02-lgraph/#other-considerations_3","text":"","title":"Other Considerations"},{"location":"livehd/02-lgraph/#lut_op","text":"","title":"LUT_op"},{"location":"livehd/02-lgraph/#and_op","text":"reduce AND a =u= -1 // unsigned equal","title":"And_op"},{"location":"livehd/02-lgraph/#or_op","text":"reduce OR a != 0","title":"Or_op"},{"location":"livehd/02-lgraph/#xor_op","text":"reduce xor is a chain of XORs.","title":"Xor_op"},{"location":"livehd/02-lgraph/#const_op","text":"","title":"Const_op"},{"location":"livehd/02-lgraph/#sflop_op","text":"","title":"SFlop_op"},{"location":"livehd/02-lgraph/#aflop_op","text":"","title":"AFlop_op"},{"location":"livehd/02-lgraph/#fflop_op","text":"","title":"FFlop_op"},{"location":"livehd/02-lgraph/#latch_op","text":"","title":"Latch_op"},{"location":"livehd/02-lgraph/#memory_op","text":"Memory is the basic block to represent SRAM-like structures. Any large storage will benefit from using memory arrays instead of flops, which are slower to simulate. These memories are highly configurable. digraph Memory { rankdir=LR; size=\"2,1\" node [shape = circle]; Memory; node [shape = point ]; q0 node [shape = point ]; q1 node [shape = point ]; q2 node [shape = point ]; q3 node [shape = point ]; q4 node [shape = point ]; q5 node [shape = point ]; q6 node [shape = point ]; q7 node [shape = point ]; q8 node [shape = point ]; q9 node [shape = point ]; q10 node [shape = point ]; q q0 -> Memory [ label =\"a (addr)\" ]; q1 -> Memory [ label =\"b (bits)\" ]; q2 -> Memory [ label =\"c (clock)\" ]; q3 -> Memory [ label =\"d (data in)\" ]; q4 -> Memory [ label =\"e (enable)\" ]; q5 -> Memory [ label =\"f (fwd)\" ]; q6 -> Memory [ label =\"l (latency)\" ]; q7 -> Memory [ label =\"m (wmask)\" ]; q8 -> Memory [ label =\"p (posedge)\" ]; q9 -> Memory [ label =\"s (size)\" ]; q10 -> Memory [ label =\"w (wmode)\" ]; Memory -> q [ label =\"Q (data out)\" ]; } s ( size ) is for the array size in number of entries b ( bits ) is the number of bits per entry f ( fwd ) points to a 0/1 constant driver pin to indicate if writes forward value ( 0b0 for write-only ports). Effectively, it means zero cycles read latency when enabled. fwd is more than just setting latency=0 . Even with latency zero, the write delay affects until the result is visible. With fwd enabled, the write latency does not matter to observe the results. This requires a costly forwarding logic. c , d , e , q ... are the memory configuration, data, address ports Ports ( a , c ... p , w ) are arrays/vectors to support multiported memories. If a single instance exists in a port, the same is used across all the ports. E.g: if clock ( c ) is populated: mem1.c = clk1 // clk for all the memory ports mem2.c[0] = clk1 // clock for memory port 0 mem2.c[1] = clk2 // clock for memory port 1 mem2.c[2] = clk2 // clock for memory port 2 Each memory port (rd, wr, or rd/wr) has the following ports: a ( addr ) points to the driver pin for the address. The address bits should match the array size ( ceil(log2(s)) ) c ( clock ) points to the clock driver pin d ( data_in ) points to the write data driver pin (read result is in q port). e ( enable ) points to the driver pin for read/write enable. l ( latency ) points to an integer constant driver pin (2 bits always). For writes latency from 1 to 3 , for reads latency from 0 to 3 w ( wmask ) Points to the write mask (1 == write, 0==no write). The mask bust be a big as the number of bits per entry ( b ). The wmask pin can be disconnected which means no write mask (a write will write all the bits). p ( posedge ) points to a 1/0 constant driver pin m ( mode ) points to the driver pin or switching between read (0) and write mode (1) (single bit) Q ( data_out ) is a driver pin with the data read from the memory All the entries but the wmask must be populated. If the wmask is not set, a full write size is expected. Read-only ports do not have data and wmask fields if the write use the low ports (0,1...). By placing the read-only ports to the high numbers, we can avoid populating the wmask ( m ) and data out ( q ) ports. If the read ports use low port numbers those fields must be populated to allow the correct matching between write port ( a[n] ) and write result ( q[n] ). All the ports must be populated with the correct size. This is important because some modules access the field by bit position. If it is not used, it will point to a zero constant with the correct number of bits. The exception to this is wmask which, if b indicates 8 bits per entry, will be equivalent to 0xFF . Setting wmask to 0b1 will mean a 1 bit zero, and the memory will be incorrectly operated. The memory usually has power of two sizes. If the size is not a power of 2, the address is rounded up. Writes to the invalid addresses will generated random memory updates. Reads should read random data.","title":"Memory_op"},{"location":"livehd/02-lgraph/#forward-propagation_8","text":"","title":"Forward Propagation"},{"location":"livehd/02-lgraph/#backward-propagation_8","text":"","title":"Backward Propagation"},{"location":"livehd/02-lgraph/#other-considerations_4","text":"","title":"Other Considerations"},{"location":"livehd/02-lgraph/#peephole-optimizations_8","text":"","title":"Peephole Optimizations"},{"location":"livehd/02-lgraph/#subgraph_op","text":"And_Op: bitwise AND with 2 outputs single bit reduction (RED) or bitwise Y = VAL&..&VAL ; RED= &Y","title":"SubGraph_op"},{"location":"livehd/02-lgraph/#forward-propagation_9","text":"\\(Y = \\left\\{\\begin{matrix} VAL>>OFF & SZ==0 \\\\ (VAL>>OFF) \\& (1<<SZ)-1) & otherwise \\end{matrix}\\right.\\) \\(Y.max = \\left\\{\\begin{matrix} VAL.max>>OFF & SZ==0 \\\\ (VAL.max>>OFF) \\& (1<<SZ)-1) & otherwise \\end{matrix}\\right.\\) \\(Y.min = 0\\) \\(Y.sign = 0\\)","title":"Forward Propagation"},{"location":"livehd/02-lgraph/#backward-propagation_9","text":"The sign can not be backward propagated because Pick_Op removes the sign no matter the input sign.","title":"Backward Propagation"},{"location":"livehd/02-lgraph/#generate-pdf","text":"pandoc --pdf-engine=xelatex --toc -N GitHub-use.md lgraph.md --mathjax --filter pandoc-graphviz.py -o ~/tmp/pp.pdf https://github.com/Wandmalfarbe/pandoc-latex-template https://pianomanfrazier.com/post/write-a-book-with-markdown/","title":"Generate PDF"},{"location":"livehd/02-lgraph/#to-be-continued","text":"","title":"To be continued ..."},{"location":"livehd/02-lgraph/#lgraph-optimization","text":"Not all the nodes have the same complexity overhead. When performing peephole optimization is possible to trade one set of nodes for others. In general, we have this set of overheads: 0 overhead: not, get_mask, set_mask, sext, and SHL/SRA with constant shift amounts. The rational is that those are just \"wiring\" cells to connect or extract wires across. The NOT gate is not really zero, but it could be easily mixed with sorrounding cells. 1 overhead: And, Or, Xor, LUT, Mux 3 overhead: LT, GT, EQ, Ror 4 overhead: Less than 4 bit output Sum, and SHL/SRA with non-compile time shift amount. This can be costly an require hardware like barrel shifters. 5 overhead: large Sum, SHL/SRA. 6 Overhead: Mult/Div If a overhead level can be elininated having a small number of different cells with a smaller overhead level,the translation makes sense. Notice the \"small number of cells\", after all everything can be translated to nand gates. A 3x factor is somewhat reasonable. This means that a 5-level overhead is fine to be replaced for 3 4-level (or 3 3-level) but not for 4 4-level overhead. Zero overhead cells are not included in the list of cells in the replacement. This is a heuristic. Once works, it is a nice target to use AI to decide when/if a transformation is worth.","title":"LGraph Optimization"},{"location":"livehd/03-lnast/","text":"LNAST Warning This document is not updated to the latest changes LNAST stands for Language-Neutral Abstract Syntax Tree, which is constituted of Lnast_nodes and indexed by a tree structure. LiveHD has two main data structures: LNAST and LGraph. The LNAST is the higher level representation with a tree structure. The LGraph is the lower level representation with a graph structure. Each node in LGraph has a LNAST equivalent node, but LNAST is more high level and several nodes in LNAST may not have a one-to-one mapping to LGraph. Each Lnast_node should has a specific node type and contain the following information from source code tokens (a) line number (b) pos_start, pos_end (c) string_view (optional) Function Overloadings of Node Data Construction Every node construction method has four function overloadings. For example, to construct a Lnast_node with a type of reference, we could use one of the following functions: // C++ auto node_ref = Lnast_node :: create_ref ( \"foo\" ); auto node_ref = Lnast_node :: create_ref ( \"foo\" , line_num ); auto node_ref = Lnast_node :: create_ref ( \"foo\" , line_num , pos1 , pos2 ); auto node_ref = Lnast_node :: create_ref ( token ); In case (1), you only knows the variable name is \"foo\". In case (2), you know the variable name and the corresponding line number. In case (3), you know the variable name, the line number, and the charactrer position. In case (4), you are building LNAST from your HDL AST and you already have the Token. The toke should have line number, positions, and string_view information. Another Example If you don't care the string_view to be stored in the lnast node, just leave it empty for set \"foo\" for it. This is true for many of the operator node, for example, to build a node with type of assign. // C++ auto node_assign = Lnast_node :: create_assign (); auto node_assign = Lnast_node :: create_assign ( line_num ); auto node_assign = Lnast_node :: create_assign ( line_num , pos1 , pos2 ); auto node_assign = Lnast_node :: create_assign ( token ); // The token is not necessary to have a string_view Module Input, Output, and Register Declaration In LNAST, all input/output/register are defined in the node type reference with differenct prefix of string_view, \"$\" stands for input, \"%\" stands for output, and \"#\" stands for register. Input // Pyrope foo = $a // Verilog input a ; // C++ auto node_input = Lnast_node :: create_ref ( \"$a\" , line_num , pos1 , pos2 ); Output // Pyrope %out // Verilog output out ; // C++ auto node_output = Lnast_node :: create_ref ( \"%out\" , line_num , pos1 , pos2 ); Register // Pyrope reg_foo // Verilog reg reg_foo ; // C++ auto node_reg = Lnast_node :: create_ref ( \"#reg_foo\" , line_num , pos1 , pos2 ); Assign Statement LNAST has 3 types of assignments. \"=\", \"as\", and \":=\". The \"lhs = rhs\" assignment (assign), copies the rhs value to the lhs and makes sure that there is no bit drop. The lhs has to have equal or more bits than the rhs. The \"lhs as rhs\" assignment (as) is the same as the \"=\" assignment but it fixes the value. The lhs variable becomes a \"C++ const\" after the assignment. The value assigned can not change again. the \"lhs := rhs\" assignment (dp_assign) is like the \"=\" assignment but there is no check for overflow. If the rhs has more bits than the lhs, the upper bits will be dropped. Assign Trivial Constant // Pyrope val = 1023u10bits // Verilog assign val = 10 `d1023 // val has 10 bits // CFG 1 0 0 SEQ0 2 1 0 0 10 = val 0d1023u10 // C++ auto node_stmts = Lnast_node :: create_stmts ( \"foo\" , line_num , pos1 , pos2 ); auto node_assign = Lnast_node :: create_assign ( \"foo\" , line_num , pos1 , pos2 ); auto node_target = Lnast_node :: create_ref ( \"val\" , line_num , pos1 , pos2 ); auto node_const = Lnast_node :: create_const ( \"0d1023u10\" , line_num , pos1 , pos2 ); auto idx_stmts = lnast -> add_child ( idx_root , node_stmts ); auto idx_assign = lnast -> add_child ( idx_stmts , node_assign ); auto idx_target = lnast -> add_child ( idx_assign , node_target ); auto idx_const = lnast -> add_child ( idx_assign , node_const ); An assign node sets the right hand side value to the reference pointed by the left hand side of the expression. The left hand side is always a reference. The right hand side is a reference or a constant. Assign Simple Expression // Pyrope total := (x - 1) + 3 + 2 // Verilog assign total = ( x - 1 ) + 3 + 2 // CFG 1 0 0 SEQ0 2 1 0 0 21 - ___a x 0d1 3 1 1 0 21 + ___b ___a 0d3 0d2 4 1 3 0 21 = total ___b // C++ // preparing lnast_node data // Note: as mentioned in the introduction, if you have the HDL-AST in hand, using // Token directly instead of explicit string, line_num, pos ... etc. auto node_stmts = Lnast_node :: create_stmts ( \"foo\" , line_num , pos1 , pos2 ); node node_minus = Lnast_node :: create_minus ( \"foo\" , line_num , pos1 , pos2 ); node node_lhs1 = Lnast_node :: create_ref ( \"___a\" , line_num , pos1 , pos2 ); node node_op1 = Lnast_node :: create_ref ( \"x\" , line_num , pos1 , pos2 ); node node_op2 = Lnast_node :: create_const ( \"0d1\" , line_num , pos1 , pos2 ); node node_plus = Lnast_node :: create_plus ( \"bar\" , line_num , pos1 , pos2 ); node node_lhs2 = Lnast_node :: create_ref ( \"___b\" , line_num , pos1 , pos2 ); node node_op3 = Lnast_node :: create_ref ( \"___a\" , line_num , pos1 , pos2 ); node node_op4 = Lnast_node :: create_const ( \"0d3\" , line_num , pos1 , pos2 ); node node_op5 = Lnast_node :: create_const ( \"0d2\" , line_num , pos1 , pos2 ); auto node_dpa = Lnast_node :: create_dp_assign ( \"foo2\" , line_num , pos1 , pos2 ); auto node_lhs3 = Lnast_node :: create_ref ( \"total\" , line_num , pos1 , pos2 ); auto node_op6 = Lnast_node :: create_ref ( \"___b\" , line_num , pos1 , pos2 ); // construct the LNAST tree auto idx_stmts = lnast -> add_child ( idx_root , node_stmts ); auto idx_minus = lnast -> add_child ( idx_stmts , node_minus ); auto idx_lhs1 = lnast -> add_child ( idx_minus , node_lhs1 ); auto idx_op1 = lnast -> add_child ( idx_minus , node_op1 ); auto idx_op2 = lnast -> add_child ( idx_minus , node_op2 ); auto idx_plus = lnast -> add_child ( idx_stmts , node_plus ); auto idx_lhs2 = lnast -> add_child ( idx_plus , node_lhs2 ); auto idx_op3 = lnast -> add_child ( idx_plus , node_op3 ); auto idx_op4 = lnast -> add_child ( idx_plus , node_op4 ); auto idx_op5 = lnast -> add_child ( idx_plus , node_op5 ); auto idx_assign = lnast -> add_child ( idx_stmts , node_dpa ); auto idx_lhs3 = lnast -> add_child ( idx_assign , node_lhs3 ); auto idx_op6 = lnast -> add_child ( idx_assign , node_op6 ); statements that have operations must breakdown the operations per type, and then assign the temporal value to the assign node. Unary Operation Statement Unary operator is embedded as the prefix of the variable string_view Binary Not Operation // Pyrope %out = ~$inp // Verilog input inp ; output wire out ; assign out = ~ inp ; 1 0 0 SEQ0 2 1 1 0 10 ~ %out $inp //C++ auto idx_not = lnast -> add_child ( idx_not , Lnast_node :: create_not ( token1 )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token2 )); // string_view = %out auto idx_op = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token3 )); // string_view = $inp Logical Not Operation The not operation can be applied over logical values. Compares the input against zero to be true. The binary not just toggles each bit. // Pyrope %out = !$inp // Verilog input inp ; output wire out ; assign out = ! inp ; 1 0 0 SEQ0 2 1 1 0 10 ! %out $inp //C++ auto idx_not = lnast -> add_child ( idx_logical_not , Lnast_node :: create_logical_not ( token1 )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token2 )); // string_view = %out auto idx_op = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token3 )); // string_view = $inp N-ary Operation Statement N-ary operation computes n rhs operands and assign the result to the lhs. The n-ary operator group includes Operator Syntax And & Or | Xor ^ Logical And and Logical Or or Plus + Minus - Multiply * Division / Equals to == Less than < Less than or Equals to <= Greater than > Greater than or Equals to >= Tuple concatenation ++ We take the \"And Operator\" for explaination. And Operation // Pyrope out = a & b & c // Verilog assign out = a & b & c // CFG 1 0 0 SEQ0 2 1 0 0 21 & ___a a b c 3 1 3 0 21 = out ___a // C++ auto idx_stmts = lnast -> add_child ( idx_root , Lnast_node :: create_stmts ( token0 )); auto idx_and = lnast -> add_child ( idx_stmts , Lnast_node :: create_and ( token1 )); // string_view = ___a auto idx_lhs1 = lnast -> add_child ( idx_and , Lnast_node :: create_ref ( token2 )); // string_view = a auto idx_op1 = lnast -> add_child ( idx_and , Lnast_node :: create_ref ( token3 )); // string_view = b auto idx_op2 = lnast -> add_child ( idx_and , Lnast_node :: create_ref ( token4 )); // string_view = c auto idx_assign = lnast -> add_child ( idx_stmts , Lnast_node :: create_assign ( token5 )); auto idx_lhs2 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token6 )); // string_view = out auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token7 )); // string_view = ___a If Statement Simple Case if a > 3 { b = a + 1 } // CFG 1 0 0 SEQ0 2 1 0 0 24 if ___a 3 2 0 SEQ1 4 3 0 0 24 > ___a a 0d3 6 2 0 SEQ2 7 6 0 0 24 + ___b a 0d1 8 6 1 0 24 = a ___b assign b2 = ( a > 3 ) ? a + 1 : b ; //C++ auto idx_stmts0 = lnast -> add_child ( idx_root , Lnast_node :: create_stmts ( token_0 )); auto idx_if = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_if ( token_1 )); auto idx_cstmts = lnast -> add_child ( idx_if , Lnast_node :: create_cstmts ( token_2 )); auto idx_gt = lnast -> add_child ( idx_cstmts , Lnast_node :: create_gt ( token_3 )); auto idx_lhs = lnast -> add_child ( idx_gt , Lnast_node :: create_ref ( token_4 )); //string_view = \"___a\" auto idx_op1 = lnast -> add_child ( idx_gt , Lnast_node :: create_ref ( token_5 )); //string_view = \"a\" auto idx_op2 = lnast -> add_child ( idx_gt , Lnast_node :: create_const ( token_6 )); //string_view = \"0d3\" auto idx_cond1 = lnast -> add_child ( idx_if , Lnast_node :: create_cond ( token_7 )); //string_view = \"___a\" auto idx_stmts1 = lnast -> add_child ( idx_if , Lnast_node :: create_stmts ( token_8 )); auto idx_plus = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_plus ( token_9 )); auto idx_lhs = lnast -> add_child ( idx_plus , Lnast_node :: create_ref ( token_a )); //string_view = \"___b\" auto idx_op3 = lnast -> add_child ( idx_plus , Lnast_node :: create_ref ( token_b )); //string_view = \"a\" auto idx_op4 = lnast -> add_child ( idx_plus , Lnast_node :: create_const ( token_c )); //string_view = \"0d1\" auto idx_assign = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_assign ( token_d )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_e )); //string_view = \"a\" auto idx_op5 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_f )); //string_view = \"___b\" An if-subtree consisted of conditional-statements sub-trees, boolean condition nodes, and statements sub-trees in the following order: cstmts1 -> condition1 -> stmts1 -> cstmts2 -> condition2 -> stmts2 ...-> stmtsN, If there is a final \"else\" chunk, it won't come with a corresponding conditionial statements sub-tree and conditional node, see the figure for the detail. Full Case // Pyrope if a > 10 { b = 3 } elif a < 1 { b = 2 } else { b = 1 } // Verilog assign b = ( a > 10 ) ? 3 : ( a < 1 ) ? 2 : 1 ; // CFG 1 0 0 SEQ0 2 1 0 0 62 if ___a 3 2 0 SEQ1 4 3 0 0 62 > ___a a 0d10 6 2 0 SEQ2 7 6 0 0 62 = b 0d3 9 2 2 0 62 elif ___b 10 2 0 SEQ3 11 10 0 0 62 < ___b a 0d1 13 2 0 SEQ4 14 13 0 0 62 = b 0d2 16 2 0 SEQ5 17 16 0 0 62 = b 0d1 //C++ auto idx_stmts0 = lnast -> add_child ( idx_root , Lnast_node :: create_stmts ( token_0 )); auto idx_if = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_if ( token_1 )); auto idx_cstmts1 = lnast -> add_child ( idx_if , Lnast_node :: create_cstmts ( token_2 )); auto idx_gt = lnast -> add_child ( idx_cstmts , Lnast_node :: create_gt ( token_3 )); auto idx_lhs = lnast -> add_child ( idx_gt , Lnast_node :: create_ref ( token_4 )); //string_view = \"___a\" auto idx_op1 = lnast -> add_child ( idx_gt , Lnast_node :: create_ref ( token_5 )); //string_view = \"a\" auto idx_op2 = lnast -> add_child ( idx_gt , Lnast_node :: create_const ( token_6 )); //string_view = \"0d10\" auto idx_cond1 = lnast -> add_child ( idx_if , Lnast_node :: create_cond ( token_7 )); //string_view = \"___a\" auto idx_stmts1 = lnast -> add_child ( idx_if , Lnast_node :: create_stmts ( token_8 )); auto idx_assign = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_assign ( token_9 )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_a )); //string_view = \"b\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token_b )); //string_view = \"0d3\" auto idx_cstmts2 = lnast -> add_child ( idx_if , Lnast_node :: create_cstmts ( token_c )); auto idx_lt = lnast -> add_child ( idx_cstmts , Lnast_node :: create_lt ( token_d )); auto idx_lhs = lnast -> add_child ( idx_lt , Lnast_node :: create_ref ( token_e )); //string_view = \"___b\" auto idx_op2 = lnast -> add_child ( idx_lt , Lnast_node :: create_ref ( token_f )); //string_view = \"a\" auto idx_op3 = lnast -> add_child ( idx_lt , Lnast_node :: create_const ( token_g )); //string_view = \"0d1\" auto idx_cond2 = lnast -> add_child ( idx_if , Lnast_node :: create_cond ( token_h )); //string_view = \"___b\" auto idx_stmts2 = lnast -> add_child ( idx_if , Lnast_node :: create_stmts ( token_i )); auto idx_assign = lnast -> add_child ( idx_stmts2 , Lnast_node :: create_assign ( token_j )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_k )); //string_view = \"b\" auto idx_op4 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token_l )); //string_view = \"0d2\" auto idx_stmts3 = lnast -> add_child ( idx_if , Lnast_node :: create_stmts ( token_m )); auto idx_assign = lnast -> add_child ( idx_stmts3 , Lnast_node :: create_assign ( token_n )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_o )); //string_view = \"b\" auto idx_op5 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token_p )); //string_view = \"0d3\" Tuple Statement The tuple LNAST node first entry always points to a \"ref\" node. This is the destination of the tuple. The following entries point to LNAST nodes that can be \"assign\", \"as\", \"ref\", or \"const\". // Pyrope tup = (foo = 1, bar = cat + 2) // Verilog typede packed { logic foo ; logic [ 4 : 0 ] bar ; } tup_t ; tup_t tup ; always_comb begin tup . foo = 1 ; tup . bar = cat + 2 ; end // CFG // FIXME: SH: wait Akash to change tuple expression scope 1 0 x SEQ0 4 1 x 0 33 + ___d cat 0d2 2 1 x TUP0 ___a 3 2 x 0 33 = foo 0d1 5 2 x 0 33 = bar ___d 7 1 x 0 33 = tup ___a //C++ auto idx_plus = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_plus ( token_1 )); auto idx_lhs = lnast -> add_child ( idx_plus , Lnast_node :: create_ref ( token_2 )); //string_view = \"___d\" auto idx_op1 = lnast -> add_child ( idx_plus , Lnast_node :: create_ref ( token_3 )); //string_view = \"cat\" auto idx_op2 = lnast -> add_child ( idx_plus , Lnast_node :: create_const ( token_4 )); //string_view = \"0d2\" auto idx_tup = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_tuple ( token_5 )); auto idx_tname = lnast -> add_child ( idx_tup , Lnast_node :: create_ref ( token_6 )); //string_view = \"tup\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_7 )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_8 )); //string_view = \"foo\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token_9 )); //string_view = \"0d1\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_a )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_b )); //string_view = \"bar\" auto idx_op4 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_c )); //string_view = \"___d\" Tuple Concatenation Statement // Pyrope tup = (foo = 1, bar = cat + 2) tup = tup ++ (4, dog) // Verilog // CFG 1 0 x SEQ0 4 1 x 0 33 + ___d cat 0d2 2 1 x TUP0 tup 3 2 x 0 33 = foo 0d1 5 2 x 0 33 = bar ___d 7 1 x TUP1 ___f 8 7 x 35 54 = null 0d4 9 7 x 35 54 = null dog 10 1 x 35 54 ++ ___e tup ___f 11 1 x 35 54 = tup ___e //C++ auto idx_plus = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_plus ( token_1 )); auto idx_lhs = lnast -> add_child ( idx_plus , Lnast_node :: create_ref ( token_2 )); //string_view = \"___d\" auto idx_op1 = lnast -> add_child ( idx_plus , Lnast_node :: create_ref ( token_3 )); //string_view = \"cat\" auto idx_op2 = lnast -> add_child ( idx_plus , Lnast_node :: create_const ( token_4 )); //string_view = \"0d2\" auto idx_tup = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_tuple ( token_5 )); auto idx_tname = lnast -> add_child ( idx_tup , Lnast_node :: create_ref ( token_6 )); //string_view = \"tup\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_7 )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_8 )); //string_view = \"foo\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token_9 )); //string_view = \"0d1\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_a )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_b )); //string_view = \"bar\" auto idx_op4 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_c )); //string_view = \"___d\" auto idx_tup2 = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_tuple ( token_g )) auto idx_tname = lnast -> add_child ( idx_tup2 , Lnast_node :: create_ref ( token_h )); //string_view = \"___f\", for intermediate temp tuple auto idx_op7 = lnast -> add_child ( idx_tup2 , Lnast_node :: create_const ( token_j )); //string_view = \"0d4\" auto idx_op8 = lnast -> add_child ( idx_tup2 , Lnast_node :: create_reg ( token_m )); //string_view = \"dog\" auto idx_tconcat = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_tuple_concat ( token_p )); auto idx_lhs = lnast -> add_child ( idx_tconcat , Lnast_node :: create_ref ( token_q )); //string_view = \"___e\" auto idx_op9 = lnast -> add_child ( idx_tconcat , Lnast_node :: create_ref ( token_r )); //string_view = \"tup\" auto idx_opa = lnast -> add_child ( idx_tconcat , Lnast_node :: create_ref ( token_s )); //string_view = \"___f\" auto idx_assign = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_assign ( token_t )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_u )); //string_view = \"tup\" auto idx_opb = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_v )); //string_view = \"___e\" For Loop Statement // Pyrope for i in (0..3) { tuple_foo[i] = tuple_bar[3-i] } // Verilog // CFG // FIXME: SH: still need to check with new CFG from Akash 1 0 x SEQ0 2 1 0 TUP0 ___b 3 2 0 0 51 .. ___c 0d0 0d3 5 1 2 0 51 for i ___b 7 5 0 SEQ1 8 7 0 0 51 [] ___d tuple_foo i 9 7 1 0 51 - ___g 0d3 i 10 7 2 0 51 [] ___f tuple_bar ___g 11 7 3 0 51 . () ___e ___f 12 7 4 0 51 = ___d ___e //C++ auto idx_tup = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_tuple ( token_1 )); auto idx_tname = lnast -> add_child ( idx_tup , Lnast_node :: create_ref ( token_2 )); //string_view = \"___b\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_3 )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_4 )); //string_view = \"__range_begin\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token_5 )); //string_view = \"0d0\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_6 )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_7 )); //string_view = \"__range_end\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token_8 )); //string_view = \"0d3\" auto idx_for = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_for ( token_9 )); auto idx_stmts1 = lnast -> add_child ( idx_for , Lnast_node :: create_stmts ( token_a )); auto idx_itr = lnast -> add_child ( idx_for , Lnast_node :: create_ref ( token_b )); //string_view = \"i\" auto idx_itr_range = lnast -> add_child ( idx_for , Lnast_node :: create_ref ( token_c )); //string_view = \"___b\" auto idx_select = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_select ( token_d )); auto idx_lhs = lnast -> add_child ( idx_select , Lnast_node :: create_ref ( token_e )); //string_view = \"___d\" auto idx_op4 = lnast -> add_child ( idx_select , Lnast_node :: create_ref ( token_f )); //string_view = \"tup_foo\" auto idx_op5 = lnast -> add_child ( idx_select , Lnast_node :: create_ref ( token_g )); //string_view = \"i\" auto idx_minus = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_minus ( token_h )); auto idx_lhs = lnast -> add_child ( idx_minus , Lnast_node :: create_ref ( token_i )); //string_view = \"___g\" auto idx_op6 = lnast -> add_child ( idx_minus , Lnast_node :: create_cond ( token_j )); //string_view = \"0d3\" auto idx_op7 = lnast -> add_child ( idx_minus , Lnast_node :: create_ref ( token_k )); //string_view = \"i\" auto idx_select = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_select ( token_l )); auto idx_lhs = lnast -> add_child ( idx_select , Lnast_node :: create_ref ( token_m )); //string_view = \"___f\" auto idx_op8 = lnast -> add_child ( idx_select , Lnast_node :: create_ref ( token_n )); //string_view = \"tup_bar\" auto idx_op9 = lnast -> add_child ( idx_select , Lnast_node :: create_ref ( token_o )); //string_view = \"___g\" auto idx_assign = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_assign ( token_p )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_q )); //string_view = \"___d\" auto idx_opa = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_r )); //string_view = \"___f\" While Loop Statement // Pyrope for i in (0..3) { tup_foo[i] = tup_bar[3-i] } // Verilog // CFG 1 0 0 SEQ0 2 1 0 0 58 > ___a i 0d0 3 1 1 0 58 while ___a 5 3 0 SEQ1 6 5 0 0 58 [] ___b tup_foo i 7 5 1 0 58 - ___e 0d3 i 8 5 2 0 58 [] ___d tup_bar ___e 9 5 4 0 58 = ___b ___d 10 5 5 0 58 - ___f i 0d1 11 5 6 0 58 = i ___f //C++ auto idx_while = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_while ( token_0 )); auto idx_cond = lnast -> add_child ( idx_while , Lnast_node :: create_cond ( token_1 )); //string_view = \"___a\" auto idx_stmts1 = lnast -> add_child ( idx_while , Lnast_node :: create_stmts ( token_2 )); auto idx_exp1 = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_select ( token_3 )); //string_view = \"___b\" . . . Function Definition Statement Basic Function Definition A function could be viewed as a module, the arguments of a function represent the module IO with the io-prefix, $ for input or % for output. In LNAST, a function definition statement is composed as the following node sequence: function_name -> condition -> statements(function body) -> io_1 -> io_2 -> io_N ... // Pyrope func_xor = :($a, $b, %out):{ %out = $a ^ $b } // Verilog module func_xor ( input a , input b , outpout wire out ); assign out = a ^ b ; endmodule // CFG 1 0 0 SEQ0 2 1 0 0 47 :: { ___a null $a $b %out 4 2 0 SEQ1 5 4 0 0 47 ^ ___b $a $b 6 4 1 0 47 = %out ___b 7 1 1 0 47 = func_xor \\_ __a //C++ auto idx_stmts0 = lnast -> add_child ( idx_root , Lnast_node :: create_stmts ( token_0 )); auto idx_func = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_func_def ( token_1 )); auto idx_fname = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_2 )); //string_view = \"func_xor\" auto idx_cond = lnast -> add_child ( idx_func , Lnast_node :: create_cond ( token_3 )); //string_view = \"true\" auto idx_stmts1 = lnast -> add_child ( idx_func , Lnast_node :: create_stmts ( token_4 )); auto idx_io1 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_5 )); //string_view = \"$a\" auto idx_io2 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_6 )); //string_view = \"$b\" auto idx_io3 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_7 )); //string_view = \"$out\" auto idx_xor = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_xor ( token_7 )); auto idx_lhs = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_8 )); //string_view = \"___b\" auto idx_op1 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_9 )); //string_view = \"$a\" auto idx_op2 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_a )); //string_view = \"$b\" auto idx_assign = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_assign ( token_b )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_c )); //string_view = \"%out\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_d )); //string_view = \"___b\" Conditional Function Definition If the HDL support the conditional function definition, for example, Pyrope, we have to assign the appropriate condition variable to the condition node. In the example of the following Pyrope code, the func_xor function will only be declared when its intput $valid is true. For normal case, we assign \"true\" string_view to this condition node. See figure for better understanding. // Pyrope func_xor = :($a, $b, $valid, %out) when $valid:{ %out = $a ^ $b } // Verilog module func_xor ( input a , input b , outpout wire out ); assign out = a ^ b ; endmodule // CFG 1 0 0 SEQ0 2 1 0 0 47 :: { ___a $valid $a $b $valid %out 4 2 0 SEQ1 5 4 0 0 47 ^ ___b $a $b 6 4 1 0 47 = %out ___b 7 1 1 0 47 = func_xor \\_ __a //C++ auto idx_stmts0 = lnast -> add_child ( idx_root , Lnast_node :: create_stmts ( token_0 )); auto idx_func = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_func_def ( token_1 )); auto idx_fname = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_2 )); //string_view = \"func_xor\" auto idx_cond = lnast -> add_child ( idx_func , Lnast_node :: create_cond ( token_3 )); //string_view = \"$valid\" auto idx_stmts1 = lnast -> add_child ( idx_func , Lnast_node :: create_stmts ( token_4 )); auto idx_io1 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_5 )); //string_view = \"$a\" auto idx_io2 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_6 )); //string_view = \"$b\" auto idx_io3 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_7 )); //string_view = \"$out\" auto idx_xor = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_xor ( token_7 )); auto idx_lhs = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_8 )); //string_view = \"___b\" auto idx_op1 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_9 )); //string_view = \"$a\" auto idx_op2 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_a )); //string_view = \"$b\" auto idx_assign = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_assign ( token_b )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_c )); //string_view = \"%out\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_d )); //string_view = \"___b\" auto idx_assign = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_assign ( token_e )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_f )); //string_view = \"func_xor\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_g )); //string_view = \"\\___a\" Function Call Implicit Function Argument Assignment // Pyrope func_xor = :($a, $b, %out):{ %out = $a ^ $b } my_xor = func_xor($foo, $bar) %out = my_xor.out // Verilog module func_xor ( input a , input b , outpout wire out ); assign out = a ^ b ; endmodule module top ( input foo , input bar , output wire out ); func_xor my_xor (. a ( foo ), . b ( bar ), . out ( out )) endmodule // CFG 1 0 0 SEQ0 2 1 0 0 47 :: { ___a null $a $b %out 4 2 0 SEQ1 5 4 0 0 47 ^ ___b $a $b 6 4 1 0 47 = %out ___b 7 1 1 0 47 = func_xor \\_ __a 8 1 0 TUP0 ___d 9 8 2 49 = null $foo 10 8 3 49 = null $bar 11 1 4 49 78 . () my_xor func_xor ___d 13 1 6 79 96 . ___f my_xor out 15 1 8 79 96 = %out ___f //C++ auto idx_stmts0 = lnast -> add_child ( idx_root , Lnast_node :: create_stmts ( token_0 )); auto idx_func = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_func_def ( token_1 )); auto idx_fname = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_2 )); //string_view = \"func_xor\" auto idx_cond = lnast -> add_child ( idx_func , Lnast_node :: create_cond ( token_3 )); //string_view = \"true\" auto idx_stmts1 = lnast -> add_child ( idx_func , Lnast_node :: create_stmts ( token_4 )); auto idx_io1 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_5 )); //string_view = \"$a\" auto idx_io2 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_6 )); //string_view = \"$b\" auto idx_io3 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_7 )); //string_view = \"$out\" auto idx_xor = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_xor ( token_8 )); auto idx_lhs = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_9 )); //string_view = \"___b\" auto idx_op1 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_a )); //string_view = \"$a\" auto idx_op2 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_b )); //string_view = \"$b\" auto idx_assign = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_assign ( token_c )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_d )); //string_view = \"%out\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_e )); //string_view = \"___b\" auto idx_assign = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_assign ( token_f )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_g )); //string_view = \"func_xor\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_h )); //string_view = \"\\___a\" auto idx_tup = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_tuple ( token_i )); auto idx_tname = lnast -> add_child ( idx_tup , Lnast_node :: create_ref ( token_j )); //string_view = \"___d\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_k )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_l )); //string_view = \"null\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_m )); //string_view = \"$foo\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_n )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_o )); //string_view = \"null\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_p )); //string_view = \"$bar\" auto idx_fcall = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_func_call ( token_q )); auto idx_lhs = lnast -> add_child ( idx_fcall , Lnast_node :: create_ref ( token_r )); //string_view = \"my_xor\" auto idx_target = lnast -> add_child ( idx_fcall , Lnast_node :: create_ref ( token_s )); //string_view = \"func_xor\" auto idx_arg = lnast -> add_child ( idx_fcall , Lnast_node :: create_ref ( token_t )); //string_view = \"___d\" auto idx_dot = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_dot ( token_u )); auto idx_lhs = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token_v )); //string_view = \"___f\" auto idx_op1 = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token_w )); //string_view = \"my_xor\" auto idx_op2 = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token_x )); //string_view = \"out\" auto idx_assign = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_assign ( token_y )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_z )); //string_view = \"%out\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_aa )); //string_view = \"___f\" Explicit Function Argument Assignment // Pyrope func_xor = :($a, $b, %out):{ %out = $a ^ $b } my_xor = func_xor(a = $foo, b = $bar) %out = my_xor.out // Verilog module func_xor ( input a , input b , outpout wire out ); assign out = a ^ b ; endmodule module top ( input foo , input bar , output wire out ); func_xor my_xor (. a ( foo ), . b ( bar ), . out ( out )) endmodule // CFG 1 0 0 SEQ0 2 1 0 0 47 :: { ___a null $a $b %out 4 2 0 SEQ1 5 4 0 0 47 ^ ___b $a $b 6 4 1 0 47 = %out ___b 7 1 1 0 47 = func_xor \\_ __a 8 1 0 TUP0 ___d 10 8 3 49 86 = a $foo 12 8 5 49 86 = b $bar 13 1 6 49 86 . () ___c func_xor ___d 14 1 7 49 86 = my_xor ___c 15 1 8 87 104 . ___j my_xor out 17 1 10 87 104 = %out ___j //C++ auto idx_stmts0 = lnast -> add_child ( idx_root , Lnast_node :: create_stmts ( token_0 )); auto idx_func = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_func_def ( token_1 )); auto idx_fname = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_2 )); //string_view = \"func_xor\" auto idx_cond = lnast -> add_child ( idx_func , Lnast_node :: create_cond ( token_3 )); //string_view = \"true\" auto idx_stmts1 = lnast -> add_child ( idx_func , Lnast_node :: create_stmts ( token_4 )); auto idx_io1 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_5 )); //string_view = \"$a\" auto idx_io2 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_6 )); //string_view = \"$b\" auto idx_io3 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_7 )); //string_view = \"$out\" auto idx_xor = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_xor ( token_8 )); auto idx_lhs = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_9 )); //string_view = \"___b\" auto idx_op1 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_a )); //string_view = \"$a\" auto idx_op2 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_b )); //string_view = \"$b\" auto idx_assign = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_assign ( token_c )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_d )); //string_view = \"%out\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_e )); //string_view = \"___b\" auto idx_assign = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_assign ( token_f )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_g )); //string_view = \"func_xor\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_h )); //string_view = \"\\___a\" auto idx_tup = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_tuple ( token_i )); auto idx_tname = lnast -> add_child ( idx_tup , Lnast_node :: create_ref ( token_j )); //string_view = \"___d\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_k )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_l )); //string_view = \"a\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_m )); //string_view = \"$foo\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_n )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_o )); //string_view = \"b\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_p )); //string_view = \"$bar\" auto idx_fcall = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_func_call ( token_q )); auto idx_lhs = lnast -> add_child ( idx_fcall , Lnast_node :: create_ref ( token_r )); //string_view = \"my_xor\" auto idx_target = lnast -> add_child ( idx_fcall , Lnast_node :: create_ref ( token_s )); //string_view = \"func_xor\" auto idx_arg = lnast -> add_child ( idx_fcall , Lnast_node :: create_ref ( token_t )); //string_view = \"___d\" auto idx_dot = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_dot ( token_u )); auto idx_lhs = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token_v )); //string_view = \"___j\" auto idx_op1 = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token_w )); //string_view = \"my_xor\" auto idx_op2 = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token_x )); //string_view = \"out\" auto idx_assign = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_assign ( token_y )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_z )); //string_view = \"%out\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_aa )); //string_view = \"___j\" // Pyrope val = 1023u10bits Attribute statement There are two ways to set an attribute to a variable or tuple, using \".\" dot operator directly or using as (__attr = foo). An classical attribute setting is bitwidth assignment. // Pyrope foo.__bits = 3 foo = 7 bar as (__bits = 10) bar = 123 // Verilog wire [ 2 : 0 ] foo ; wire [ 9 : 0 ] bar ; assign foo = 7 ; assign bar = 123 ; // CFG 1 0 0 SEQ0 2 1 0 0 14 . ___a foo __bits 3 1 1 0 14 = ___a 0d3 4 1 2 15 22 = foo 0d7 5 1 0 TUP0 ___b 6 5 3 24 44 = __bits 0d10 7 1 4 24 44 as bar ___b 8 1 5 45 54 = bar 0d123 // C++ auto idx_dot = lnast -> add_child ( idx_stmts , Lnast_node :: create_dot ( token1 )); auto idx_lhs1 = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token2 )); // string_view = ___a auto idx_op1 = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token3 )); // string_view = foo auto idx_op2 = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token4 )); // string_view = __bits auto idx_assign = lnast -> add_child ( idx_stmts , Lnast_node :: create_assign ( token5 )); auto idx_lhs2 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token6 )); // string_view = ___a auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token7 )); // string_view = 0d3 auto idx_assign = lnast -> add_child ( idx_stmts , Lnast_node :: create_assign ( token8 )); auto idx_lhs2 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token9 )); // string_view = foo auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( tokena )); // string_view = 0d7 auto idx_tup = lnast -> add_child ( idx_stmts , Lnast_node :: create_tuple ( tokenb )); auto idx_tname = lnast -> add_child ( idx_tup , Lnast_node :: create_ref ( tokenc )); // string_view = ___b auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( tokend )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( tokene )); //string_view = \"__bits\" auto idx_op4 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( tokenf )); //string_view = \"0d10\" auto idx_as = lnast -> add_child ( idx_stmts , Lnast_node :: create_as ( tokeng )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( tokenh )); //string_view = \"bar\" auto idx_op5 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( tokeni )); //string_view = \"___b\" auto idx_assign = lnast -> add_child ( idx_stmts , Lnast_node :: create_assign ( tokenj )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( tokenk )); //string_view = \"bar\" auto idx_op6 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( tokenk )); //string_view = \"0d123\" String management LNAST has to handle lots of strings. Each LNAST node has several strings, for example, the simple \"ref\" node has 2 strings: the variable name and the contents. The LNAST interface does not allocate strings when passed as arguments. The reason is that it accepts std::string_view as argument. The LNAST internals assume that someone else handles the string allocations. A code like this will result in incorrect behaviour: // WARNING: INCORRECT CODE std::string str{\"foo\"}; str += \"bar\"; auto Lnast_node::create_ref(str); The reason is that str is allocated at the stack, and after the function returns LNAST will have a pointer to incorrect memory region. The solution is that for newly created strings, the \"add_string\" API must be called. // CORRECT CODE to handle strings in LNAST std::string str{\"foo\"}; str += \"bar\"; auto Lnast_node::create_ref(lnast->add_string(str)); The add_string allocates a string inside lnast. When the lnast is de-allocated the string is garbage collected. LNAST is optimized to operate with scanner parsers. When LNAST is built, it is possible to pass a memory region mmaped with all the strings used by the scanner. In this case, the LNAST can get ownership of a large memory region with all the strings used by the scanner. // LNAST mmap support std::pair<std::string_view, int> own; // own.first points to the mmap region that lnast will munmap at the end // own.second points to the file descriptor associated to the mmap that must be closed lnast = std::make_unique<Lnast>(\"top_name\", own);","title":"LNAST"},{"location":"livehd/03-lnast/#lnast","text":"Warning This document is not updated to the latest changes LNAST stands for Language-Neutral Abstract Syntax Tree, which is constituted of Lnast_nodes and indexed by a tree structure. LiveHD has two main data structures: LNAST and LGraph. The LNAST is the higher level representation with a tree structure. The LGraph is the lower level representation with a graph structure. Each node in LGraph has a LNAST equivalent node, but LNAST is more high level and several nodes in LNAST may not have a one-to-one mapping to LGraph. Each Lnast_node should has a specific node type and contain the following information from source code tokens (a) line number (b) pos_start, pos_end (c) string_view (optional)","title":"LNAST"},{"location":"livehd/03-lnast/#function-overloadings-of-node-data-construction","text":"Every node construction method has four function overloadings. For example, to construct a Lnast_node with a type of reference, we could use one of the following functions: // C++ auto node_ref = Lnast_node :: create_ref ( \"foo\" ); auto node_ref = Lnast_node :: create_ref ( \"foo\" , line_num ); auto node_ref = Lnast_node :: create_ref ( \"foo\" , line_num , pos1 , pos2 ); auto node_ref = Lnast_node :: create_ref ( token ); In case (1), you only knows the variable name is \"foo\". In case (2), you know the variable name and the corresponding line number. In case (3), you know the variable name, the line number, and the charactrer position. In case (4), you are building LNAST from your HDL AST and you already have the Token. The toke should have line number, positions, and string_view information.","title":"Function Overloadings of Node Data Construction"},{"location":"livehd/03-lnast/#another-example","text":"If you don't care the string_view to be stored in the lnast node, just leave it empty for set \"foo\" for it. This is true for many of the operator node, for example, to build a node with type of assign. // C++ auto node_assign = Lnast_node :: create_assign (); auto node_assign = Lnast_node :: create_assign ( line_num ); auto node_assign = Lnast_node :: create_assign ( line_num , pos1 , pos2 ); auto node_assign = Lnast_node :: create_assign ( token ); // The token is not necessary to have a string_view","title":"Another Example"},{"location":"livehd/03-lnast/#module-input-output-and-register-declaration","text":"In LNAST, all input/output/register are defined in the node type reference with differenct prefix of string_view, \"$\" stands for input, \"%\" stands for output, and \"#\" stands for register.","title":"Module Input, Output, and Register Declaration"},{"location":"livehd/03-lnast/#input","text":"// Pyrope foo = $a // Verilog input a ; // C++ auto node_input = Lnast_node :: create_ref ( \"$a\" , line_num , pos1 , pos2 );","title":"Input"},{"location":"livehd/03-lnast/#output","text":"// Pyrope %out // Verilog output out ; // C++ auto node_output = Lnast_node :: create_ref ( \"%out\" , line_num , pos1 , pos2 );","title":"Output"},{"location":"livehd/03-lnast/#register","text":"// Pyrope reg_foo // Verilog reg reg_foo ; // C++ auto node_reg = Lnast_node :: create_ref ( \"#reg_foo\" , line_num , pos1 , pos2 );","title":"Register"},{"location":"livehd/03-lnast/#assign-statement","text":"LNAST has 3 types of assignments. \"=\", \"as\", and \":=\". The \"lhs = rhs\" assignment (assign), copies the rhs value to the lhs and makes sure that there is no bit drop. The lhs has to have equal or more bits than the rhs. The \"lhs as rhs\" assignment (as) is the same as the \"=\" assignment but it fixes the value. The lhs variable becomes a \"C++ const\" after the assignment. The value assigned can not change again. the \"lhs := rhs\" assignment (dp_assign) is like the \"=\" assignment but there is no check for overflow. If the rhs has more bits than the lhs, the upper bits will be dropped.","title":"Assign Statement"},{"location":"livehd/03-lnast/#assign-trivial-constant","text":"// Pyrope val = 1023u10bits // Verilog assign val = 10 `d1023 // val has 10 bits // CFG 1 0 0 SEQ0 2 1 0 0 10 = val 0d1023u10 // C++ auto node_stmts = Lnast_node :: create_stmts ( \"foo\" , line_num , pos1 , pos2 ); auto node_assign = Lnast_node :: create_assign ( \"foo\" , line_num , pos1 , pos2 ); auto node_target = Lnast_node :: create_ref ( \"val\" , line_num , pos1 , pos2 ); auto node_const = Lnast_node :: create_const ( \"0d1023u10\" , line_num , pos1 , pos2 ); auto idx_stmts = lnast -> add_child ( idx_root , node_stmts ); auto idx_assign = lnast -> add_child ( idx_stmts , node_assign ); auto idx_target = lnast -> add_child ( idx_assign , node_target ); auto idx_const = lnast -> add_child ( idx_assign , node_const ); An assign node sets the right hand side value to the reference pointed by the left hand side of the expression. The left hand side is always a reference. The right hand side is a reference or a constant.","title":"Assign Trivial Constant"},{"location":"livehd/03-lnast/#assign-simple-expression","text":"// Pyrope total := (x - 1) + 3 + 2 // Verilog assign total = ( x - 1 ) + 3 + 2 // CFG 1 0 0 SEQ0 2 1 0 0 21 - ___a x 0d1 3 1 1 0 21 + ___b ___a 0d3 0d2 4 1 3 0 21 = total ___b // C++ // preparing lnast_node data // Note: as mentioned in the introduction, if you have the HDL-AST in hand, using // Token directly instead of explicit string, line_num, pos ... etc. auto node_stmts = Lnast_node :: create_stmts ( \"foo\" , line_num , pos1 , pos2 ); node node_minus = Lnast_node :: create_minus ( \"foo\" , line_num , pos1 , pos2 ); node node_lhs1 = Lnast_node :: create_ref ( \"___a\" , line_num , pos1 , pos2 ); node node_op1 = Lnast_node :: create_ref ( \"x\" , line_num , pos1 , pos2 ); node node_op2 = Lnast_node :: create_const ( \"0d1\" , line_num , pos1 , pos2 ); node node_plus = Lnast_node :: create_plus ( \"bar\" , line_num , pos1 , pos2 ); node node_lhs2 = Lnast_node :: create_ref ( \"___b\" , line_num , pos1 , pos2 ); node node_op3 = Lnast_node :: create_ref ( \"___a\" , line_num , pos1 , pos2 ); node node_op4 = Lnast_node :: create_const ( \"0d3\" , line_num , pos1 , pos2 ); node node_op5 = Lnast_node :: create_const ( \"0d2\" , line_num , pos1 , pos2 ); auto node_dpa = Lnast_node :: create_dp_assign ( \"foo2\" , line_num , pos1 , pos2 ); auto node_lhs3 = Lnast_node :: create_ref ( \"total\" , line_num , pos1 , pos2 ); auto node_op6 = Lnast_node :: create_ref ( \"___b\" , line_num , pos1 , pos2 ); // construct the LNAST tree auto idx_stmts = lnast -> add_child ( idx_root , node_stmts ); auto idx_minus = lnast -> add_child ( idx_stmts , node_minus ); auto idx_lhs1 = lnast -> add_child ( idx_minus , node_lhs1 ); auto idx_op1 = lnast -> add_child ( idx_minus , node_op1 ); auto idx_op2 = lnast -> add_child ( idx_minus , node_op2 ); auto idx_plus = lnast -> add_child ( idx_stmts , node_plus ); auto idx_lhs2 = lnast -> add_child ( idx_plus , node_lhs2 ); auto idx_op3 = lnast -> add_child ( idx_plus , node_op3 ); auto idx_op4 = lnast -> add_child ( idx_plus , node_op4 ); auto idx_op5 = lnast -> add_child ( idx_plus , node_op5 ); auto idx_assign = lnast -> add_child ( idx_stmts , node_dpa ); auto idx_lhs3 = lnast -> add_child ( idx_assign , node_lhs3 ); auto idx_op6 = lnast -> add_child ( idx_assign , node_op6 ); statements that have operations must breakdown the operations per type, and then assign the temporal value to the assign node.","title":"Assign Simple Expression"},{"location":"livehd/03-lnast/#unary-operation-statement","text":"Unary operator is embedded as the prefix of the variable string_view","title":"Unary Operation Statement"},{"location":"livehd/03-lnast/#binary-not-operation","text":"// Pyrope %out = ~$inp // Verilog input inp ; output wire out ; assign out = ~ inp ; 1 0 0 SEQ0 2 1 1 0 10 ~ %out $inp //C++ auto idx_not = lnast -> add_child ( idx_not , Lnast_node :: create_not ( token1 )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token2 )); // string_view = %out auto idx_op = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token3 )); // string_view = $inp","title":"Binary Not Operation"},{"location":"livehd/03-lnast/#logical-not-operation","text":"The not operation can be applied over logical values. Compares the input against zero to be true. The binary not just toggles each bit. // Pyrope %out = !$inp // Verilog input inp ; output wire out ; assign out = ! inp ; 1 0 0 SEQ0 2 1 1 0 10 ! %out $inp //C++ auto idx_not = lnast -> add_child ( idx_logical_not , Lnast_node :: create_logical_not ( token1 )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token2 )); // string_view = %out auto idx_op = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token3 )); // string_view = $inp","title":"Logical Not Operation"},{"location":"livehd/03-lnast/#n-ary-operation-statement","text":"N-ary operation computes n rhs operands and assign the result to the lhs. The n-ary operator group includes Operator Syntax And & Or | Xor ^ Logical And and Logical Or or Plus + Minus - Multiply * Division / Equals to == Less than < Less than or Equals to <= Greater than > Greater than or Equals to >= Tuple concatenation ++ We take the \"And Operator\" for explaination.","title":"N-ary Operation Statement"},{"location":"livehd/03-lnast/#and-operation","text":"// Pyrope out = a & b & c // Verilog assign out = a & b & c // CFG 1 0 0 SEQ0 2 1 0 0 21 & ___a a b c 3 1 3 0 21 = out ___a // C++ auto idx_stmts = lnast -> add_child ( idx_root , Lnast_node :: create_stmts ( token0 )); auto idx_and = lnast -> add_child ( idx_stmts , Lnast_node :: create_and ( token1 )); // string_view = ___a auto idx_lhs1 = lnast -> add_child ( idx_and , Lnast_node :: create_ref ( token2 )); // string_view = a auto idx_op1 = lnast -> add_child ( idx_and , Lnast_node :: create_ref ( token3 )); // string_view = b auto idx_op2 = lnast -> add_child ( idx_and , Lnast_node :: create_ref ( token4 )); // string_view = c auto idx_assign = lnast -> add_child ( idx_stmts , Lnast_node :: create_assign ( token5 )); auto idx_lhs2 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token6 )); // string_view = out auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token7 )); // string_view = ___a","title":"And Operation"},{"location":"livehd/03-lnast/#if-statement","text":"","title":"If Statement"},{"location":"livehd/03-lnast/#simple-case","text":"if a > 3 { b = a + 1 } // CFG 1 0 0 SEQ0 2 1 0 0 24 if ___a 3 2 0 SEQ1 4 3 0 0 24 > ___a a 0d3 6 2 0 SEQ2 7 6 0 0 24 + ___b a 0d1 8 6 1 0 24 = a ___b assign b2 = ( a > 3 ) ? a + 1 : b ; //C++ auto idx_stmts0 = lnast -> add_child ( idx_root , Lnast_node :: create_stmts ( token_0 )); auto idx_if = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_if ( token_1 )); auto idx_cstmts = lnast -> add_child ( idx_if , Lnast_node :: create_cstmts ( token_2 )); auto idx_gt = lnast -> add_child ( idx_cstmts , Lnast_node :: create_gt ( token_3 )); auto idx_lhs = lnast -> add_child ( idx_gt , Lnast_node :: create_ref ( token_4 )); //string_view = \"___a\" auto idx_op1 = lnast -> add_child ( idx_gt , Lnast_node :: create_ref ( token_5 )); //string_view = \"a\" auto idx_op2 = lnast -> add_child ( idx_gt , Lnast_node :: create_const ( token_6 )); //string_view = \"0d3\" auto idx_cond1 = lnast -> add_child ( idx_if , Lnast_node :: create_cond ( token_7 )); //string_view = \"___a\" auto idx_stmts1 = lnast -> add_child ( idx_if , Lnast_node :: create_stmts ( token_8 )); auto idx_plus = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_plus ( token_9 )); auto idx_lhs = lnast -> add_child ( idx_plus , Lnast_node :: create_ref ( token_a )); //string_view = \"___b\" auto idx_op3 = lnast -> add_child ( idx_plus , Lnast_node :: create_ref ( token_b )); //string_view = \"a\" auto idx_op4 = lnast -> add_child ( idx_plus , Lnast_node :: create_const ( token_c )); //string_view = \"0d1\" auto idx_assign = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_assign ( token_d )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_e )); //string_view = \"a\" auto idx_op5 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_f )); //string_view = \"___b\" An if-subtree consisted of conditional-statements sub-trees, boolean condition nodes, and statements sub-trees in the following order: cstmts1 -> condition1 -> stmts1 -> cstmts2 -> condition2 -> stmts2 ...-> stmtsN, If there is a final \"else\" chunk, it won't come with a corresponding conditionial statements sub-tree and conditional node, see the figure for the detail.","title":"Simple Case"},{"location":"livehd/03-lnast/#full-case","text":"// Pyrope if a > 10 { b = 3 } elif a < 1 { b = 2 } else { b = 1 } // Verilog assign b = ( a > 10 ) ? 3 : ( a < 1 ) ? 2 : 1 ; // CFG 1 0 0 SEQ0 2 1 0 0 62 if ___a 3 2 0 SEQ1 4 3 0 0 62 > ___a a 0d10 6 2 0 SEQ2 7 6 0 0 62 = b 0d3 9 2 2 0 62 elif ___b 10 2 0 SEQ3 11 10 0 0 62 < ___b a 0d1 13 2 0 SEQ4 14 13 0 0 62 = b 0d2 16 2 0 SEQ5 17 16 0 0 62 = b 0d1 //C++ auto idx_stmts0 = lnast -> add_child ( idx_root , Lnast_node :: create_stmts ( token_0 )); auto idx_if = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_if ( token_1 )); auto idx_cstmts1 = lnast -> add_child ( idx_if , Lnast_node :: create_cstmts ( token_2 )); auto idx_gt = lnast -> add_child ( idx_cstmts , Lnast_node :: create_gt ( token_3 )); auto idx_lhs = lnast -> add_child ( idx_gt , Lnast_node :: create_ref ( token_4 )); //string_view = \"___a\" auto idx_op1 = lnast -> add_child ( idx_gt , Lnast_node :: create_ref ( token_5 )); //string_view = \"a\" auto idx_op2 = lnast -> add_child ( idx_gt , Lnast_node :: create_const ( token_6 )); //string_view = \"0d10\" auto idx_cond1 = lnast -> add_child ( idx_if , Lnast_node :: create_cond ( token_7 )); //string_view = \"___a\" auto idx_stmts1 = lnast -> add_child ( idx_if , Lnast_node :: create_stmts ( token_8 )); auto idx_assign = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_assign ( token_9 )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_a )); //string_view = \"b\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token_b )); //string_view = \"0d3\" auto idx_cstmts2 = lnast -> add_child ( idx_if , Lnast_node :: create_cstmts ( token_c )); auto idx_lt = lnast -> add_child ( idx_cstmts , Lnast_node :: create_lt ( token_d )); auto idx_lhs = lnast -> add_child ( idx_lt , Lnast_node :: create_ref ( token_e )); //string_view = \"___b\" auto idx_op2 = lnast -> add_child ( idx_lt , Lnast_node :: create_ref ( token_f )); //string_view = \"a\" auto idx_op3 = lnast -> add_child ( idx_lt , Lnast_node :: create_const ( token_g )); //string_view = \"0d1\" auto idx_cond2 = lnast -> add_child ( idx_if , Lnast_node :: create_cond ( token_h )); //string_view = \"___b\" auto idx_stmts2 = lnast -> add_child ( idx_if , Lnast_node :: create_stmts ( token_i )); auto idx_assign = lnast -> add_child ( idx_stmts2 , Lnast_node :: create_assign ( token_j )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_k )); //string_view = \"b\" auto idx_op4 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token_l )); //string_view = \"0d2\" auto idx_stmts3 = lnast -> add_child ( idx_if , Lnast_node :: create_stmts ( token_m )); auto idx_assign = lnast -> add_child ( idx_stmts3 , Lnast_node :: create_assign ( token_n )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_o )); //string_view = \"b\" auto idx_op5 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token_p )); //string_view = \"0d3\"","title":"Full Case"},{"location":"livehd/03-lnast/#tuple-statement","text":"The tuple LNAST node first entry always points to a \"ref\" node. This is the destination of the tuple. The following entries point to LNAST nodes that can be \"assign\", \"as\", \"ref\", or \"const\". // Pyrope tup = (foo = 1, bar = cat + 2) // Verilog typede packed { logic foo ; logic [ 4 : 0 ] bar ; } tup_t ; tup_t tup ; always_comb begin tup . foo = 1 ; tup . bar = cat + 2 ; end // CFG // FIXME: SH: wait Akash to change tuple expression scope 1 0 x SEQ0 4 1 x 0 33 + ___d cat 0d2 2 1 x TUP0 ___a 3 2 x 0 33 = foo 0d1 5 2 x 0 33 = bar ___d 7 1 x 0 33 = tup ___a //C++ auto idx_plus = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_plus ( token_1 )); auto idx_lhs = lnast -> add_child ( idx_plus , Lnast_node :: create_ref ( token_2 )); //string_view = \"___d\" auto idx_op1 = lnast -> add_child ( idx_plus , Lnast_node :: create_ref ( token_3 )); //string_view = \"cat\" auto idx_op2 = lnast -> add_child ( idx_plus , Lnast_node :: create_const ( token_4 )); //string_view = \"0d2\" auto idx_tup = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_tuple ( token_5 )); auto idx_tname = lnast -> add_child ( idx_tup , Lnast_node :: create_ref ( token_6 )); //string_view = \"tup\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_7 )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_8 )); //string_view = \"foo\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token_9 )); //string_view = \"0d1\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_a )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_b )); //string_view = \"bar\" auto idx_op4 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_c )); //string_view = \"___d\"","title":"Tuple Statement"},{"location":"livehd/03-lnast/#tuple-concatenation-statement","text":"// Pyrope tup = (foo = 1, bar = cat + 2) tup = tup ++ (4, dog) // Verilog // CFG 1 0 x SEQ0 4 1 x 0 33 + ___d cat 0d2 2 1 x TUP0 tup 3 2 x 0 33 = foo 0d1 5 2 x 0 33 = bar ___d 7 1 x TUP1 ___f 8 7 x 35 54 = null 0d4 9 7 x 35 54 = null dog 10 1 x 35 54 ++ ___e tup ___f 11 1 x 35 54 = tup ___e //C++ auto idx_plus = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_plus ( token_1 )); auto idx_lhs = lnast -> add_child ( idx_plus , Lnast_node :: create_ref ( token_2 )); //string_view = \"___d\" auto idx_op1 = lnast -> add_child ( idx_plus , Lnast_node :: create_ref ( token_3 )); //string_view = \"cat\" auto idx_op2 = lnast -> add_child ( idx_plus , Lnast_node :: create_const ( token_4 )); //string_view = \"0d2\" auto idx_tup = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_tuple ( token_5 )); auto idx_tname = lnast -> add_child ( idx_tup , Lnast_node :: create_ref ( token_6 )); //string_view = \"tup\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_7 )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_8 )); //string_view = \"foo\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token_9 )); //string_view = \"0d1\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_a )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_b )); //string_view = \"bar\" auto idx_op4 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_c )); //string_view = \"___d\" auto idx_tup2 = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_tuple ( token_g )) auto idx_tname = lnast -> add_child ( idx_tup2 , Lnast_node :: create_ref ( token_h )); //string_view = \"___f\", for intermediate temp tuple auto idx_op7 = lnast -> add_child ( idx_tup2 , Lnast_node :: create_const ( token_j )); //string_view = \"0d4\" auto idx_op8 = lnast -> add_child ( idx_tup2 , Lnast_node :: create_reg ( token_m )); //string_view = \"dog\" auto idx_tconcat = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_tuple_concat ( token_p )); auto idx_lhs = lnast -> add_child ( idx_tconcat , Lnast_node :: create_ref ( token_q )); //string_view = \"___e\" auto idx_op9 = lnast -> add_child ( idx_tconcat , Lnast_node :: create_ref ( token_r )); //string_view = \"tup\" auto idx_opa = lnast -> add_child ( idx_tconcat , Lnast_node :: create_ref ( token_s )); //string_view = \"___f\" auto idx_assign = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_assign ( token_t )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_u )); //string_view = \"tup\" auto idx_opb = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_v )); //string_view = \"___e\"","title":"Tuple Concatenation Statement"},{"location":"livehd/03-lnast/#for-loop-statement","text":"// Pyrope for i in (0..3) { tuple_foo[i] = tuple_bar[3-i] } // Verilog // CFG // FIXME: SH: still need to check with new CFG from Akash 1 0 x SEQ0 2 1 0 TUP0 ___b 3 2 0 0 51 .. ___c 0d0 0d3 5 1 2 0 51 for i ___b 7 5 0 SEQ1 8 7 0 0 51 [] ___d tuple_foo i 9 7 1 0 51 - ___g 0d3 i 10 7 2 0 51 [] ___f tuple_bar ___g 11 7 3 0 51 . () ___e ___f 12 7 4 0 51 = ___d ___e //C++ auto idx_tup = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_tuple ( token_1 )); auto idx_tname = lnast -> add_child ( idx_tup , Lnast_node :: create_ref ( token_2 )); //string_view = \"___b\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_3 )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_4 )); //string_view = \"__range_begin\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token_5 )); //string_view = \"0d0\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_6 )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_7 )); //string_view = \"__range_end\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token_8 )); //string_view = \"0d3\" auto idx_for = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_for ( token_9 )); auto idx_stmts1 = lnast -> add_child ( idx_for , Lnast_node :: create_stmts ( token_a )); auto idx_itr = lnast -> add_child ( idx_for , Lnast_node :: create_ref ( token_b )); //string_view = \"i\" auto idx_itr_range = lnast -> add_child ( idx_for , Lnast_node :: create_ref ( token_c )); //string_view = \"___b\" auto idx_select = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_select ( token_d )); auto idx_lhs = lnast -> add_child ( idx_select , Lnast_node :: create_ref ( token_e )); //string_view = \"___d\" auto idx_op4 = lnast -> add_child ( idx_select , Lnast_node :: create_ref ( token_f )); //string_view = \"tup_foo\" auto idx_op5 = lnast -> add_child ( idx_select , Lnast_node :: create_ref ( token_g )); //string_view = \"i\" auto idx_minus = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_minus ( token_h )); auto idx_lhs = lnast -> add_child ( idx_minus , Lnast_node :: create_ref ( token_i )); //string_view = \"___g\" auto idx_op6 = lnast -> add_child ( idx_minus , Lnast_node :: create_cond ( token_j )); //string_view = \"0d3\" auto idx_op7 = lnast -> add_child ( idx_minus , Lnast_node :: create_ref ( token_k )); //string_view = \"i\" auto idx_select = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_select ( token_l )); auto idx_lhs = lnast -> add_child ( idx_select , Lnast_node :: create_ref ( token_m )); //string_view = \"___f\" auto idx_op8 = lnast -> add_child ( idx_select , Lnast_node :: create_ref ( token_n )); //string_view = \"tup_bar\" auto idx_op9 = lnast -> add_child ( idx_select , Lnast_node :: create_ref ( token_o )); //string_view = \"___g\" auto idx_assign = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_assign ( token_p )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_q )); //string_view = \"___d\" auto idx_opa = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_r )); //string_view = \"___f\"","title":"For Loop Statement"},{"location":"livehd/03-lnast/#while-loop-statement","text":"// Pyrope for i in (0..3) { tup_foo[i] = tup_bar[3-i] } // Verilog // CFG 1 0 0 SEQ0 2 1 0 0 58 > ___a i 0d0 3 1 1 0 58 while ___a 5 3 0 SEQ1 6 5 0 0 58 [] ___b tup_foo i 7 5 1 0 58 - ___e 0d3 i 8 5 2 0 58 [] ___d tup_bar ___e 9 5 4 0 58 = ___b ___d 10 5 5 0 58 - ___f i 0d1 11 5 6 0 58 = i ___f //C++ auto idx_while = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_while ( token_0 )); auto idx_cond = lnast -> add_child ( idx_while , Lnast_node :: create_cond ( token_1 )); //string_view = \"___a\" auto idx_stmts1 = lnast -> add_child ( idx_while , Lnast_node :: create_stmts ( token_2 )); auto idx_exp1 = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_select ( token_3 )); //string_view = \"___b\" . . .","title":"While Loop Statement"},{"location":"livehd/03-lnast/#function-definition-statement","text":"","title":"Function Definition Statement"},{"location":"livehd/03-lnast/#basic-function-definition","text":"A function could be viewed as a module, the arguments of a function represent the module IO with the io-prefix, $ for input or % for output. In LNAST, a function definition statement is composed as the following node sequence: function_name -> condition -> statements(function body) -> io_1 -> io_2 -> io_N ... // Pyrope func_xor = :($a, $b, %out):{ %out = $a ^ $b } // Verilog module func_xor ( input a , input b , outpout wire out ); assign out = a ^ b ; endmodule // CFG 1 0 0 SEQ0 2 1 0 0 47 :: { ___a null $a $b %out 4 2 0 SEQ1 5 4 0 0 47 ^ ___b $a $b 6 4 1 0 47 = %out ___b 7 1 1 0 47 = func_xor \\_ __a //C++ auto idx_stmts0 = lnast -> add_child ( idx_root , Lnast_node :: create_stmts ( token_0 )); auto idx_func = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_func_def ( token_1 )); auto idx_fname = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_2 )); //string_view = \"func_xor\" auto idx_cond = lnast -> add_child ( idx_func , Lnast_node :: create_cond ( token_3 )); //string_view = \"true\" auto idx_stmts1 = lnast -> add_child ( idx_func , Lnast_node :: create_stmts ( token_4 )); auto idx_io1 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_5 )); //string_view = \"$a\" auto idx_io2 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_6 )); //string_view = \"$b\" auto idx_io3 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_7 )); //string_view = \"$out\" auto idx_xor = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_xor ( token_7 )); auto idx_lhs = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_8 )); //string_view = \"___b\" auto idx_op1 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_9 )); //string_view = \"$a\" auto idx_op2 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_a )); //string_view = \"$b\" auto idx_assign = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_assign ( token_b )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_c )); //string_view = \"%out\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_d )); //string_view = \"___b\"","title":"Basic Function Definition"},{"location":"livehd/03-lnast/#conditional-function-definition","text":"If the HDL support the conditional function definition, for example, Pyrope, we have to assign the appropriate condition variable to the condition node. In the example of the following Pyrope code, the func_xor function will only be declared when its intput $valid is true. For normal case, we assign \"true\" string_view to this condition node. See figure for better understanding. // Pyrope func_xor = :($a, $b, $valid, %out) when $valid:{ %out = $a ^ $b } // Verilog module func_xor ( input a , input b , outpout wire out ); assign out = a ^ b ; endmodule // CFG 1 0 0 SEQ0 2 1 0 0 47 :: { ___a $valid $a $b $valid %out 4 2 0 SEQ1 5 4 0 0 47 ^ ___b $a $b 6 4 1 0 47 = %out ___b 7 1 1 0 47 = func_xor \\_ __a //C++ auto idx_stmts0 = lnast -> add_child ( idx_root , Lnast_node :: create_stmts ( token_0 )); auto idx_func = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_func_def ( token_1 )); auto idx_fname = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_2 )); //string_view = \"func_xor\" auto idx_cond = lnast -> add_child ( idx_func , Lnast_node :: create_cond ( token_3 )); //string_view = \"$valid\" auto idx_stmts1 = lnast -> add_child ( idx_func , Lnast_node :: create_stmts ( token_4 )); auto idx_io1 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_5 )); //string_view = \"$a\" auto idx_io2 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_6 )); //string_view = \"$b\" auto idx_io3 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_7 )); //string_view = \"$out\" auto idx_xor = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_xor ( token_7 )); auto idx_lhs = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_8 )); //string_view = \"___b\" auto idx_op1 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_9 )); //string_view = \"$a\" auto idx_op2 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_a )); //string_view = \"$b\" auto idx_assign = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_assign ( token_b )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_c )); //string_view = \"%out\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_d )); //string_view = \"___b\" auto idx_assign = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_assign ( token_e )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_f )); //string_view = \"func_xor\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_g )); //string_view = \"\\___a\"","title":"Conditional Function Definition"},{"location":"livehd/03-lnast/#function-call","text":"","title":"Function Call"},{"location":"livehd/03-lnast/#implicit-function-argument-assignment","text":"// Pyrope func_xor = :($a, $b, %out):{ %out = $a ^ $b } my_xor = func_xor($foo, $bar) %out = my_xor.out // Verilog module func_xor ( input a , input b , outpout wire out ); assign out = a ^ b ; endmodule module top ( input foo , input bar , output wire out ); func_xor my_xor (. a ( foo ), . b ( bar ), . out ( out )) endmodule // CFG 1 0 0 SEQ0 2 1 0 0 47 :: { ___a null $a $b %out 4 2 0 SEQ1 5 4 0 0 47 ^ ___b $a $b 6 4 1 0 47 = %out ___b 7 1 1 0 47 = func_xor \\_ __a 8 1 0 TUP0 ___d 9 8 2 49 = null $foo 10 8 3 49 = null $bar 11 1 4 49 78 . () my_xor func_xor ___d 13 1 6 79 96 . ___f my_xor out 15 1 8 79 96 = %out ___f //C++ auto idx_stmts0 = lnast -> add_child ( idx_root , Lnast_node :: create_stmts ( token_0 )); auto idx_func = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_func_def ( token_1 )); auto idx_fname = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_2 )); //string_view = \"func_xor\" auto idx_cond = lnast -> add_child ( idx_func , Lnast_node :: create_cond ( token_3 )); //string_view = \"true\" auto idx_stmts1 = lnast -> add_child ( idx_func , Lnast_node :: create_stmts ( token_4 )); auto idx_io1 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_5 )); //string_view = \"$a\" auto idx_io2 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_6 )); //string_view = \"$b\" auto idx_io3 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_7 )); //string_view = \"$out\" auto idx_xor = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_xor ( token_8 )); auto idx_lhs = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_9 )); //string_view = \"___b\" auto idx_op1 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_a )); //string_view = \"$a\" auto idx_op2 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_b )); //string_view = \"$b\" auto idx_assign = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_assign ( token_c )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_d )); //string_view = \"%out\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_e )); //string_view = \"___b\" auto idx_assign = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_assign ( token_f )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_g )); //string_view = \"func_xor\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_h )); //string_view = \"\\___a\" auto idx_tup = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_tuple ( token_i )); auto idx_tname = lnast -> add_child ( idx_tup , Lnast_node :: create_ref ( token_j )); //string_view = \"___d\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_k )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_l )); //string_view = \"null\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_m )); //string_view = \"$foo\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_n )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_o )); //string_view = \"null\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_p )); //string_view = \"$bar\" auto idx_fcall = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_func_call ( token_q )); auto idx_lhs = lnast -> add_child ( idx_fcall , Lnast_node :: create_ref ( token_r )); //string_view = \"my_xor\" auto idx_target = lnast -> add_child ( idx_fcall , Lnast_node :: create_ref ( token_s )); //string_view = \"func_xor\" auto idx_arg = lnast -> add_child ( idx_fcall , Lnast_node :: create_ref ( token_t )); //string_view = \"___d\" auto idx_dot = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_dot ( token_u )); auto idx_lhs = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token_v )); //string_view = \"___f\" auto idx_op1 = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token_w )); //string_view = \"my_xor\" auto idx_op2 = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token_x )); //string_view = \"out\" auto idx_assign = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_assign ( token_y )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_z )); //string_view = \"%out\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_aa )); //string_view = \"___f\"","title":"Implicit Function Argument Assignment"},{"location":"livehd/03-lnast/#explicit-function-argument-assignment","text":"// Pyrope func_xor = :($a, $b, %out):{ %out = $a ^ $b } my_xor = func_xor(a = $foo, b = $bar) %out = my_xor.out // Verilog module func_xor ( input a , input b , outpout wire out ); assign out = a ^ b ; endmodule module top ( input foo , input bar , output wire out ); func_xor my_xor (. a ( foo ), . b ( bar ), . out ( out )) endmodule // CFG 1 0 0 SEQ0 2 1 0 0 47 :: { ___a null $a $b %out 4 2 0 SEQ1 5 4 0 0 47 ^ ___b $a $b 6 4 1 0 47 = %out ___b 7 1 1 0 47 = func_xor \\_ __a 8 1 0 TUP0 ___d 10 8 3 49 86 = a $foo 12 8 5 49 86 = b $bar 13 1 6 49 86 . () ___c func_xor ___d 14 1 7 49 86 = my_xor ___c 15 1 8 87 104 . ___j my_xor out 17 1 10 87 104 = %out ___j //C++ auto idx_stmts0 = lnast -> add_child ( idx_root , Lnast_node :: create_stmts ( token_0 )); auto idx_func = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_func_def ( token_1 )); auto idx_fname = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_2 )); //string_view = \"func_xor\" auto idx_cond = lnast -> add_child ( idx_func , Lnast_node :: create_cond ( token_3 )); //string_view = \"true\" auto idx_stmts1 = lnast -> add_child ( idx_func , Lnast_node :: create_stmts ( token_4 )); auto idx_io1 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_5 )); //string_view = \"$a\" auto idx_io2 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_6 )); //string_view = \"$b\" auto idx_io3 = lnast -> add_child ( idx_func , Lnast_node :: create_ref ( token_7 )); //string_view = \"$out\" auto idx_xor = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_xor ( token_8 )); auto idx_lhs = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_9 )); //string_view = \"___b\" auto idx_op1 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_a )); //string_view = \"$a\" auto idx_op2 = lnast -> add_child ( idx_xor , Lnast_node :: create_ref ( token_b )); //string_view = \"$b\" auto idx_assign = lnast -> add_child ( idx_stmts1 , Lnast_node :: create_assign ( token_c )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_d )); //string_view = \"%out\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_e )); //string_view = \"___b\" auto idx_assign = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_assign ( token_f )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_g )); //string_view = \"func_xor\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_h )); //string_view = \"\\___a\" auto idx_tup = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_tuple ( token_i )); auto idx_tname = lnast -> add_child ( idx_tup , Lnast_node :: create_ref ( token_j )); //string_view = \"___d\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_k )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_l )); //string_view = \"a\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_m )); //string_view = \"$foo\" auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( token_n )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_o )); //string_view = \"b\" auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_p )); //string_view = \"$bar\" auto idx_fcall = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_func_call ( token_q )); auto idx_lhs = lnast -> add_child ( idx_fcall , Lnast_node :: create_ref ( token_r )); //string_view = \"my_xor\" auto idx_target = lnast -> add_child ( idx_fcall , Lnast_node :: create_ref ( token_s )); //string_view = \"func_xor\" auto idx_arg = lnast -> add_child ( idx_fcall , Lnast_node :: create_ref ( token_t )); //string_view = \"___d\" auto idx_dot = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_dot ( token_u )); auto idx_lhs = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token_v )); //string_view = \"___j\" auto idx_op1 = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token_w )); //string_view = \"my_xor\" auto idx_op2 = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token_x )); //string_view = \"out\" auto idx_assign = lnast -> add_child ( idx_stmts0 , Lnast_node :: create_assign ( token_y )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_z )); //string_view = \"%out\" auto idx_op1 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token_aa )); //string_view = \"___j\" // Pyrope val = 1023u10bits","title":"Explicit Function Argument Assignment"},{"location":"livehd/03-lnast/#attribute-statement","text":"There are two ways to set an attribute to a variable or tuple, using \".\" dot operator directly or using as (__attr = foo). An classical attribute setting is bitwidth assignment. // Pyrope foo.__bits = 3 foo = 7 bar as (__bits = 10) bar = 123 // Verilog wire [ 2 : 0 ] foo ; wire [ 9 : 0 ] bar ; assign foo = 7 ; assign bar = 123 ; // CFG 1 0 0 SEQ0 2 1 0 0 14 . ___a foo __bits 3 1 1 0 14 = ___a 0d3 4 1 2 15 22 = foo 0d7 5 1 0 TUP0 ___b 6 5 3 24 44 = __bits 0d10 7 1 4 24 44 as bar ___b 8 1 5 45 54 = bar 0d123 // C++ auto idx_dot = lnast -> add_child ( idx_stmts , Lnast_node :: create_dot ( token1 )); auto idx_lhs1 = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token2 )); // string_view = ___a auto idx_op1 = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token3 )); // string_view = foo auto idx_op2 = lnast -> add_child ( idx_dot , Lnast_node :: create_ref ( token4 )); // string_view = __bits auto idx_assign = lnast -> add_child ( idx_stmts , Lnast_node :: create_assign ( token5 )); auto idx_lhs2 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token6 )); // string_view = ___a auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( token7 )); // string_view = 0d3 auto idx_assign = lnast -> add_child ( idx_stmts , Lnast_node :: create_assign ( token8 )); auto idx_lhs2 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( token9 )); // string_view = foo auto idx_op3 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( tokena )); // string_view = 0d7 auto idx_tup = lnast -> add_child ( idx_stmts , Lnast_node :: create_tuple ( tokenb )); auto idx_tname = lnast -> add_child ( idx_tup , Lnast_node :: create_ref ( tokenc )); // string_view = ___b auto idx_assign = lnast -> add_child ( idx_tup , Lnast_node :: create_assign ( tokend )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( tokene )); //string_view = \"__bits\" auto idx_op4 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( tokenf )); //string_view = \"0d10\" auto idx_as = lnast -> add_child ( idx_stmts , Lnast_node :: create_as ( tokeng )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( tokenh )); //string_view = \"bar\" auto idx_op5 = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( tokeni )); //string_view = \"___b\" auto idx_assign = lnast -> add_child ( idx_stmts , Lnast_node :: create_assign ( tokenj )); auto idx_lhs = lnast -> add_child ( idx_assign , Lnast_node :: create_ref ( tokenk )); //string_view = \"bar\" auto idx_op6 = lnast -> add_child ( idx_assign , Lnast_node :: create_const ( tokenk )); //string_view = \"0d123\"","title":"Attribute statement"},{"location":"livehd/03-lnast/#string-management","text":"LNAST has to handle lots of strings. Each LNAST node has several strings, for example, the simple \"ref\" node has 2 strings: the variable name and the contents. The LNAST interface does not allocate strings when passed as arguments. The reason is that it accepts std::string_view as argument. The LNAST internals assume that someone else handles the string allocations. A code like this will result in incorrect behaviour: // WARNING: INCORRECT CODE std::string str{\"foo\"}; str += \"bar\"; auto Lnast_node::create_ref(str); The reason is that str is allocated at the stack, and after the function returns LNAST will have a pointer to incorrect memory region. The solution is that for newly created strings, the \"add_string\" API must be called. // CORRECT CODE to handle strings in LNAST std::string str{\"foo\"}; str += \"bar\"; auto Lnast_node::create_ref(lnast->add_string(str)); The add_string allocates a string inside lnast. When the lnast is de-allocated the string is garbage collected. LNAST is optimized to operate with scanner parsers. When LNAST is built, it is possible to pass a memory region mmaped with all the strings used by the scanner. In this case, the LNAST can get ownership of a large memory region with all the strings used by the scanner. // LNAST mmap support std::pair<std::string_view, int> own; // own.first points to the mmap region that lnast will munmap at the end // own.second points to the file descriptor associated to the mmap that must be closed lnast = std::make_unique<Lnast>(\"top_name\", own);","title":"String management"},{"location":"livehd/03c-mmapstr/","text":"mmap_lib::str mmap_lib::str is the LiveHD string class. There are several reasons to have a custom string class: LiveHD uses lots of strings, and they are mmap persistent for speed reasons. The strings are backup in a mmap, since the mmap locations change at reload and run-time there is no pointer stability. LiveHD string usage allows to optimize for common patters. E.g: append/remove beginning of the string is more frequent than the end. Also, the most common operator is the comparator for hash map search. Class Structure mmap_lib::str is a 16 byte string class with these main optimizations: SSO (Small String Optimization). When the string is less than 16 bytes, it fits in the mmap_lib::str, and no resource is allocated Unique pointer. When the string overflows, each string has a unique pointer. This requires a map search for each insert that overflows, but allows to just compare the pointer to know if two strings are equal. mmap_lib::str is a persistent data structure, calls like append, return a new str with the change. API Usage Building strings There are several constructors from std::string, std:string_view, int64_t. mmap_lib::str direct_call(\"foo\"); // == \"foo\" auto string_direct = \"string\"_str; // == \"string\" auto str_for_const = mmap_lib::str(33); // == \"33\" Append and prepend characters are also common: ** str append(char c) const : Append character c to string ** str prepend(char c) const : Prepend character c to string ** str concat(...) : Concatenate std::string/std::string_view/integer/mmap_lib::str str strip_leading(char c) const : Remove all the leading occurances of character c auto new_str = mmap_lib::str(\"hello\").append('!'); // == \"hello!\" auto prep = mmap_lib::str(\"123\").prepend('0'); // == \"0123\" auto full = mmap_lib::str::concat(\"hello\", \".\", 33); // == \"hello.33\" Auxiliary/Helper Functions ** void dump const {} : print string (useful in gdb) constexpr std::size_t size() const constexpr std::size_t max_size() const constexpr bool empty() const std::string to_s() const : convert to std::string bool is_i() const {} : Is integer? int64_t to_i() const : Convert to integer (fails if not integer) std::vector<str> split(const char chr) const : Split str in multiple strs Traversal/Search Functions ** bool starts_with(mmap_lib::str st) const : True if string starts with st bool ends_with(mmap_lib::str en) const : True if string ends with en std::size_t find(const str<m_id> &v, std::size_t pos=0) const {} : Similar to std::string::find std::size_t rfind(const str<m_id> &v, std::size_t pos=std::string::npos) const {} : Reverse find str substr(size_t start) const : Similar to std::string::substr str substr(size_t start, size_t end) const : Similar to std::string::substr str get_str_after_last(const char chr) const : str get_str_after_last_if_exists(const char chr) const : str get_str_after_first(const char chr) const : str get_str_after_first_if_exists(const char chr) const : str get_str_before_last(const char chr) const : str get_str_before_first(const char chr) const :","title":"mmap_lib::str"},{"location":"livehd/03c-mmapstr/#mmap_libstr","text":"mmap_lib::str is the LiveHD string class. There are several reasons to have a custom string class: LiveHD uses lots of strings, and they are mmap persistent for speed reasons. The strings are backup in a mmap, since the mmap locations change at reload and run-time there is no pointer stability. LiveHD string usage allows to optimize for common patters. E.g: append/remove beginning of the string is more frequent than the end. Also, the most common operator is the comparator for hash map search.","title":"mmap_lib::str"},{"location":"livehd/03c-mmapstr/#class-structure","text":"mmap_lib::str is a 16 byte string class with these main optimizations: SSO (Small String Optimization). When the string is less than 16 bytes, it fits in the mmap_lib::str, and no resource is allocated Unique pointer. When the string overflows, each string has a unique pointer. This requires a map search for each insert that overflows, but allows to just compare the pointer to know if two strings are equal. mmap_lib::str is a persistent data structure, calls like append, return a new str with the change.","title":"Class Structure"},{"location":"livehd/03c-mmapstr/#api-usage","text":"","title":"API Usage"},{"location":"livehd/03c-mmapstr/#building-strings","text":"There are several constructors from std::string, std:string_view, int64_t. mmap_lib::str direct_call(\"foo\"); // == \"foo\" auto string_direct = \"string\"_str; // == \"string\" auto str_for_const = mmap_lib::str(33); // == \"33\" Append and prepend characters are also common: ** str append(char c) const : Append character c to string ** str prepend(char c) const : Prepend character c to string ** str concat(...) : Concatenate std::string/std::string_view/integer/mmap_lib::str str strip_leading(char c) const : Remove all the leading occurances of character c auto new_str = mmap_lib::str(\"hello\").append('!'); // == \"hello!\" auto prep = mmap_lib::str(\"123\").prepend('0'); // == \"0123\" auto full = mmap_lib::str::concat(\"hello\", \".\", 33); // == \"hello.33\"","title":"Building strings"},{"location":"livehd/03c-mmapstr/#auxiliaryhelper-functions","text":"** void dump const {} : print string (useful in gdb) constexpr std::size_t size() const constexpr std::size_t max_size() const constexpr bool empty() const std::string to_s() const : convert to std::string bool is_i() const {} : Is integer? int64_t to_i() const : Convert to integer (fails if not integer) std::vector<str> split(const char chr) const : Split str in multiple strs","title":"Auxiliary/Helper Functions"},{"location":"livehd/03c-mmapstr/#traversalsearch-functions","text":"** bool starts_with(mmap_lib::str st) const : True if string starts with st bool ends_with(mmap_lib::str en) const : True if string ends with en std::size_t find(const str<m_id> &v, std::size_t pos=0) const {} : Similar to std::string::find std::size_t rfind(const str<m_id> &v, std::size_t pos=std::string::npos) const {} : Reverse find str substr(size_t start) const : Similar to std::string::substr str substr(size_t start, size_t end) const : Similar to std::string::substr str get_str_after_last(const char chr) const : str get_str_after_last_if_exists(const char chr) const : str get_str_after_first(const char chr) const : str get_str_after_first_if_exists(const char chr) const : str get_str_before_last(const char chr) const : str get_str_before_first(const char chr) const :","title":"Traversal/Search Functions"},{"location":"livehd/04a-bazel/","text":"Bazel build Bazel is a relatively new build system open sourced by google. The main difference with traditional Makefiles is that it checks to make sure that dependences are not lost and the builds are reproducible and hermetic. This document explains how to use Bazel in the LGraph project. Build targets are referred to using the syntax //<relative path to BUILD file>:<executable> , where // is the path of the root livehd directory. To build the LiveHD shell and supporting libraries, the target would be //main:all . To build every target in LiveHD (helpful for checking if changes cause compilation failures), the target would be //:... . For more details on target syntax, see this page. Release vs fastbuild (default) vs debug For debugging/development use -c dbg , for benchmarking and testing -c opt . Fast build: no optimization, minimal debugging information (no local variable information), assertions turned on (default) $ bazel build <target> Debug build: some optimization, full debugging information, assertions turned on $ bazel build -c dbg <target> or use address sanitizer to detect memory leaks $ bazel build -c dbg --config asan //... or use thread sanitizer to detect data races $ bazel build -c dbg --config tsan //... Release build: most optimization, no debug symbols, assertions turned off $ bazel build -c opt <target> Benchmarking build: aggressive optimization for the current architecture (binary may not be portable!) $ bazel build --config=bench <target> See the commands executed The bazel '-s' option prints the command executed. The sandbox may still be deleted. $ bazel build -s //main:all Keep all the files in bazel run for debugging Bazel runs process in a sandbox what it is deleted after each run. To preserve it for debugging a failing test. bazel test --sandbox_debug -c dbg //YOUR_TEST_HERE Check the failing log, it will show you the sandbox location. You can change directory to it, and debug as usual. To run FIXME tests Many times, we have new tests that make the regression fail. We use \"fixme\" if the test is a new one and LGraph is still not patched. We want the test in the system, but we do not want to make fail the regressions. Those tests are marked with tags \"fixme\" in the BUILD. E.g: sh_test( name = \"my_test.sh\", tags = [\"fixme\"], # This is a fixme test. It fails, but we should fix it srcs = [\"tests/pyrope_test.sh\"], To run all the fixme tests $ bazel test --test_tag_filters \"fixme\" <target> To list all the fixme tests (the goal is to have zero) $ bazel query 'attr(tags, fixme, tests(<target>))' List bazel targets starting from top directory $ bazel query <target> List bazel targets starting from any directory $ bazel query <target> List files needed for a given target $ bazel query \"deps(<target>)\" List all the passes that use core (those should be listed at main/BUILD deps) $ bazel query \"rdeps(//pass/..., //core:all)\" | grep pass_ Clear out cache (not needed in most cases) This command is useful for benchmarking build time, and when system parameters change (the compiler gets upgraded, for example) $ bazel clean --expunge To run LONG tests In addition to the short tests, there are sets of long tests that are run frequently but not before every push to main line. The reason is that those are multi-hour tests. $ bazel test --test_tag_filters \"long1\" <target> There are up to 8 long tests categories (long1, long2, long3...). Each of those tests groups should last less than 4 hours when running in a dual core machine (travis or azure). To list the tests under each tag. E.g., to list all the tests with long1 tag. $ bazel query 'attr(tags, long1, tests(<target>))' Debugging with bazel First run the tests to see the failing one. Then run with debug options the failing test. E.g: $ bazel run -c dbg //eprp:all Increase logging level if wanted $ LGRAPH_LOG=info bazel run -c dbg //eprp:all To run with gdb $ bazel build -c dbg //eprp:eprp_test $ gdb bazel-bin/eprp/eprp_test (gdb) b Eprp::run (gdb) r (lldb is also supported.) To create a fully static binary In the cc_binary of the relevant BUILD file, add linkopts = ['-static'] Notice that the lgshell still needs the directory inside bazel-bin/main/lgshell.runfiles when using inou.yosys.\\*","title":"Bazel build"},{"location":"livehd/04a-bazel/#bazel-build","text":"Bazel is a relatively new build system open sourced by google. The main difference with traditional Makefiles is that it checks to make sure that dependences are not lost and the builds are reproducible and hermetic. This document explains how to use Bazel in the LGraph project. Build targets are referred to using the syntax //<relative path to BUILD file>:<executable> , where // is the path of the root livehd directory. To build the LiveHD shell and supporting libraries, the target would be //main:all . To build every target in LiveHD (helpful for checking if changes cause compilation failures), the target would be //:... . For more details on target syntax, see this page.","title":"Bazel build"},{"location":"livehd/04a-bazel/#release-vs-fastbuild-default-vs-debug","text":"For debugging/development use -c dbg , for benchmarking and testing -c opt . Fast build: no optimization, minimal debugging information (no local variable information), assertions turned on (default) $ bazel build <target> Debug build: some optimization, full debugging information, assertions turned on $ bazel build -c dbg <target> or use address sanitizer to detect memory leaks $ bazel build -c dbg --config asan //... or use thread sanitizer to detect data races $ bazel build -c dbg --config tsan //... Release build: most optimization, no debug symbols, assertions turned off $ bazel build -c opt <target> Benchmarking build: aggressive optimization for the current architecture (binary may not be portable!) $ bazel build --config=bench <target>","title":"Release vs fastbuild (default) vs debug"},{"location":"livehd/04a-bazel/#see-the-commands-executed","text":"The bazel '-s' option prints the command executed. The sandbox may still be deleted. $ bazel build -s //main:all","title":"See the commands executed"},{"location":"livehd/04a-bazel/#keep-all-the-files-in-bazel-run-for-debugging","text":"Bazel runs process in a sandbox what it is deleted after each run. To preserve it for debugging a failing test. bazel test --sandbox_debug -c dbg //YOUR_TEST_HERE Check the failing log, it will show you the sandbox location. You can change directory to it, and debug as usual.","title":"Keep all the files in bazel run for debugging"},{"location":"livehd/04a-bazel/#to-run-fixme-tests","text":"Many times, we have new tests that make the regression fail. We use \"fixme\" if the test is a new one and LGraph is still not patched. We want the test in the system, but we do not want to make fail the regressions. Those tests are marked with tags \"fixme\" in the BUILD. E.g: sh_test( name = \"my_test.sh\", tags = [\"fixme\"], # This is a fixme test. It fails, but we should fix it srcs = [\"tests/pyrope_test.sh\"], To run all the fixme tests $ bazel test --test_tag_filters \"fixme\" <target> To list all the fixme tests (the goal is to have zero) $ bazel query 'attr(tags, fixme, tests(<target>))'","title":"To run FIXME tests"},{"location":"livehd/04a-bazel/#list-bazel-targets-starting-from-top-directory","text":"$ bazel query <target>","title":"List bazel targets starting from top directory"},{"location":"livehd/04a-bazel/#list-bazel-targets-starting-from-any-directory","text":"$ bazel query <target>","title":"List bazel targets starting from any directory"},{"location":"livehd/04a-bazel/#list-files-needed-for-a-given-target","text":"$ bazel query \"deps(<target>)\"","title":"List files needed for a given target"},{"location":"livehd/04a-bazel/#list-all-the-passes-that-use-core-those-should-be-listed-at-mainbuild-deps","text":"$ bazel query \"rdeps(//pass/..., //core:all)\" | grep pass_","title":"List all the passes that use core (those should be listed at main/BUILD deps)"},{"location":"livehd/04a-bazel/#clear-out-cache-not-needed-in-most-cases","text":"This command is useful for benchmarking build time, and when system parameters change (the compiler gets upgraded, for example) $ bazel clean --expunge","title":"Clear out cache (not needed in most cases)"},{"location":"livehd/04a-bazel/#to-run-long-tests","text":"In addition to the short tests, there are sets of long tests that are run frequently but not before every push to main line. The reason is that those are multi-hour tests. $ bazel test --test_tag_filters \"long1\" <target> There are up to 8 long tests categories (long1, long2, long3...). Each of those tests groups should last less than 4 hours when running in a dual core machine (travis or azure). To list the tests under each tag. E.g., to list all the tests with long1 tag. $ bazel query 'attr(tags, long1, tests(<target>))'","title":"To run LONG tests"},{"location":"livehd/04a-bazel/#debugging-with-bazel","text":"First run the tests to see the failing one. Then run with debug options the failing test. E.g: $ bazel run -c dbg //eprp:all Increase logging level if wanted $ LGRAPH_LOG=info bazel run -c dbg //eprp:all To run with gdb $ bazel build -c dbg //eprp:eprp_test $ gdb bazel-bin/eprp/eprp_test (gdb) b Eprp::run (gdb) r (lldb is also supported.)","title":"Debugging with bazel"},{"location":"livehd/04a-bazel/#to-create-a-fully-static-binary","text":"In the cc_binary of the relevant BUILD file, add linkopts = ['-static'] Notice that the lgshell still needs the directory inside bazel-bin/main/lgshell.runfiles when using inou.yosys.\\*","title":"To create a fully static binary"},{"location":"livehd/04b-pass/","text":"Creating a Pass This document provides some minimal suggestion on how to build a new LiveHD pass. Most LiveHD passes reside inside inou or pass . The only difference is that inou focuses on translation from some external tool to/from LiveHD while pass works on transformations from LiveHD to LiveHD. Create a pass Check the pass/sample directory for how to create a trivial pass. Create pass/XXX directory The typical is to have these files: pass/XXX/pass_XXX.[cpp|hpp]: C++ and Header file to interface with lgshell pass/XXX/XXX.[cpp|hpp]: C++ file to perform the pass over a Lgraph or LNAST API pass/XXX/BUILD: the Bazel build configuration file pass/XXX/tests/XXX_test.cpp: A google test checking the pass Finally, add the new pass to main/BUILD Pass Parameters and Common variables One of the main goals is to have a uniform set of passes in lgshell. lgshell should use this common variable names when possible name:foo lgraph name path:lgdb lgraph database path ( lgdb ) files:foo,var comma separated list of files used for INPUT odir:. output directory to generate files like verilog/pyrope... Some hints/comments useful for developers Using clang when building The regression system builds for both gcc and clang. To force a clang build, set the following environment variables before building: CXX = clang++ CC = clang bazel build -c dbg //... Perf in lgbench Use lgbench to gather statistics in your code block. It also allows to run perf record for the code section (from lgbench construction to destruction). To enable perf record set LGBENCH_PERF environment variable export LGBENCH_PERF = 1 GDB/LLDB usage For most tests, you can debug with gdb ./bazel-bin/main/lgshell or lldb ./bazel-bin/main/lgshell Note that breakpoint locations may not resolve until lgshell is started and the relevant LGraph libraries are loaded. Address Sanitizer LiveHD has the option to run it with address sanitizer to detect memory leaks. bazel build -c dbg --config asan //... Thread Sanitizer To debug with concurrent data race. bazel build -c dbg --config tsan //... Debugging a broken Docker image The travis/azure regressions run several docker images. To debug the issue, run the same as the failing docker image. c++ OPT with archlinux-masc image Create some directory to share data in/out the docker run (to avoid mistakes/issues, I would not share home directory unless you have done it several times before) mkdir $HOME /docker Run the docker image (in some masc docker images you can change the user to not being root) docker run --rm --cap-add SYS_ADMIN -it -e LOCAL_USER_ID = $( id -u $USER ) -v ${ HOME } /docker:/home/user mascucsc/archlinux-masc # Once inside docker image. Create local \"user\" at /home/user with your userid /usr/local/bin/entrypoint.sh If the docker image did not have the livehd repo, clone it git clone https://github.com/masc-ucsc/livehd.git Build with the failing options and debug CXX = g++ CC = gcc bazel build -c opt //... A docker distro that specially fails (address randomizing and muslc vs libc) is alpine. The command line to debug it: docker run --rm --cap-add SYS_ADMIN -it -e LOCAL_USER_ID = $( id -u $USER ) -v $HOME :/home/user -v/local/scrap:/local/scrap mascucsc/alpine-masc","title":"Creating a Pass"},{"location":"livehd/04b-pass/#creating-a-pass","text":"This document provides some minimal suggestion on how to build a new LiveHD pass. Most LiveHD passes reside inside inou or pass . The only difference is that inou focuses on translation from some external tool to/from LiveHD while pass works on transformations from LiveHD to LiveHD.","title":"Creating a Pass"},{"location":"livehd/04b-pass/#create-a-pass","text":"Check the pass/sample directory for how to create a trivial pass. Create pass/XXX directory The typical is to have these files: pass/XXX/pass_XXX.[cpp|hpp]: C++ and Header file to interface with lgshell pass/XXX/XXX.[cpp|hpp]: C++ file to perform the pass over a Lgraph or LNAST API pass/XXX/BUILD: the Bazel build configuration file pass/XXX/tests/XXX_test.cpp: A google test checking the pass Finally, add the new pass to main/BUILD","title":"Create a pass"},{"location":"livehd/04b-pass/#pass-parameters-and-common-variables","text":"One of the main goals is to have a uniform set of passes in lgshell. lgshell should use this common variable names when possible name:foo lgraph name path:lgdb lgraph database path ( lgdb ) files:foo,var comma separated list of files used for INPUT odir:. output directory to generate files like verilog/pyrope...","title":"Pass Parameters and Common variables"},{"location":"livehd/04b-pass/#some-hintscomments-useful-for-developers","text":"","title":"Some hints/comments useful for developers"},{"location":"livehd/04b-pass/#using-clang-when-building","text":"The regression system builds for both gcc and clang. To force a clang build, set the following environment variables before building: CXX = clang++ CC = clang bazel build -c dbg //...","title":"Using clang when building"},{"location":"livehd/04b-pass/#perf-in-lgbench","text":"Use lgbench to gather statistics in your code block. It also allows to run perf record for the code section (from lgbench construction to destruction). To enable perf record set LGBENCH_PERF environment variable export LGBENCH_PERF = 1","title":"Perf in lgbench"},{"location":"livehd/04b-pass/#gdblldb-usage","text":"For most tests, you can debug with gdb ./bazel-bin/main/lgshell or lldb ./bazel-bin/main/lgshell Note that breakpoint locations may not resolve until lgshell is started and the relevant LGraph libraries are loaded.","title":"GDB/LLDB usage"},{"location":"livehd/04b-pass/#address-sanitizer","text":"LiveHD has the option to run it with address sanitizer to detect memory leaks. bazel build -c dbg --config asan //...","title":"Address Sanitizer"},{"location":"livehd/04b-pass/#thread-sanitizer","text":"To debug with concurrent data race. bazel build -c dbg --config tsan //...","title":"Thread Sanitizer"},{"location":"livehd/04b-pass/#debugging-a-broken-docker-image","text":"The travis/azure regressions run several docker images. To debug the issue, run the same as the failing docker image. c++ OPT with archlinux-masc image Create some directory to share data in/out the docker run (to avoid mistakes/issues, I would not share home directory unless you have done it several times before) mkdir $HOME /docker Run the docker image (in some masc docker images you can change the user to not being root) docker run --rm --cap-add SYS_ADMIN -it -e LOCAL_USER_ID = $( id -u $USER ) -v ${ HOME } /docker:/home/user mascucsc/archlinux-masc # Once inside docker image. Create local \"user\" at /home/user with your userid /usr/local/bin/entrypoint.sh If the docker image did not have the livehd repo, clone it git clone https://github.com/masc-ucsc/livehd.git Build with the failing options and debug CXX = g++ CC = gcc bazel build -c opt //... A docker distro that specially fails (address randomizing and muslc vs libc) is alpine. The command line to debug it: docker run --rm --cap-add SYS_ADMIN -it -e LOCAL_USER_ID = $( id -u $USER ) -v $HOME :/home/user -v/local/scrap:/local/scrap mascucsc/alpine-masc","title":"Debugging a broken Docker image"},{"location":"livehd/04c-github/","text":"GitHub Guide LiveHD is the synthesis/emulation flow primarily maintained and developed by the MASC lab at UC Santa Cruz. Since LiveHD is used for computer architecture and VLSI research, the MASC lab has an internal private repo for some still in progress works. This is done using a private repo so that we can wait until the research is published before pushing changes to the public repo hosted on GitHub. This guide explains how we use git at the MASC group, and how you could setup a similar flow to contribute to the LiveHD project. Other groups may choose to adapt this technique for their own use. LiveHD uses bazel as a build system, as a result, we no longer use submodules. Instead we use the built-in bazel support to pull specific repositories. Github Configuration and Commands This section is for git first time users and to show the git configuration used by the MASC group. Configuration Suggested options for git first time users # Rebase no merge by default git config --global pull.rebase true # Set your name and email git config --global user.email \"perico@lospalotes.com\" git config --global user.name \"Perico LosPalotes\" git config --global pull.rebase true git config --global rebase.autoStash true Rebase vs No-Rebase Rebase creates cleaner logs, but sometimes it gets difficult to fix conflicts with rebase. For cases that you are struggling to merge a conflict, you could do this: # undo the failed rebase merge git rebase --abort # make sure that your code changes were committed git commit -a -m \"Your commit message\" git pull --no-rebase # Fix the conflict without rebase (easier) git commit -a -m \"your merge message\" git pull --no-rebase git push Typical git commands Clean the directory from any file not in git (it will remove all the files not committed) git clean -fdx Save and restore un-committed changes to allow a new git pull. stash is like a \"push\" and \"pop\" replays the changes in the current directory. This will happen automatically if you have the autoStash configuration option. git stash git pull git stash pop See the differences against the server (still not pushed). Everything may be committed, so git diff may be empty git diff @ { u } Git Hercules statistics hercules --languages C++ --burndown --burndown-people --pb https://github.com/masc-ucsc/livehd >hercules1.data labours -f pb -m overwrites-matrix -o hercules1a.pdf <hercules1.data labours -f pb -m ownership -o hercules1b.pdf <hercules1.data hercules --languages C++ --burndown --first-parent --pb https://github.com/masc-ucsc/livehd >hercules2.data labours -f pb -m burndown-project -o hercules2.pdf <hercules2.data hercules --languages C++ --devs --pb https://github.com/masc-ucsc/livehd >hercules3.data labours -f pb -m old-vs-new -o hercules3a.pdf <hercules3.data labours -f pb -m devs -o hercules3b.pdf <hercules3.data labours -f pb -m devs-efforts -o hercules3c.pdf <hercules3.data Test/Developer LiveHD case (no commits) If you do not plan to do many changes, and just wants to try LiveHD or be a LiveHD user, the easiest way is to just clone the repo: git clone https://github.com/masc-ucsc/livehd cd livehd From time to time, you should get the latest version to have the latest bug fixes/patches. Just a typical git pull should suffice: git pull Infrequent Contributor Flow (ADVANCED USERS) These are instructions for advanced users, more likely other university/company institutions with a team working on this project. The larger team may want to have some private repository with internal development and some pushes/pulls to the main LiveHD repo. For single external users, I would suggest to just fork the repository and do pull requests. If you work outside UCSC and/or you are an infrequent contributor, you have two main options: fork or private clone. The fork approach requires you to have your repository public, if you have publications or work-in-progress that you do not want to share the best option is to have a private repo (livehd-private). The simplest way to contribute to LiveHD is to create a public repo or a public fork, and a pull request. Most git guides use the origin/master (in fork or private repo) to synchronize with upstream/master (upstream main LiveHD repo). This means that your local changes should NOT go to your origin/master. Instead, you should create a branch for your local work. This works like a charm if you do pull requests, and it is reasonable if you have a long development branch without intention to push upstream. Although it is possible to create a different setup, we recommend that you keep the origin/master clean to synchronize with upstream/origin. You should create a new branch for each feature that you may want to upstream (origin/feature-x), and a local development branch (dev) for all your team members. Clone the repo: git clone https://github.com/masc-ucsc/livehd.git livehd cd livehd Create development branch (dev) git checkout -b dev Create a branch from origin/master to create a pull request to upstream/master git checkout -b pull_request_xxx Create a branch from dev for internal development if needed git checkout -b feature_xx_4dev dev Synchronize origin/master from main upstream/master Add remote upstream (if not added before) git remote -v If remote -v did not list upstream. Add them git remote add upstream https://github.com/masc-ucsc/livehd.git git fetch upstream Make sure that you are in origin/master git checkout master Bring the changes from the remote upstream/master to local master/origin git merge upstream/master Push to repo origin/master if everything was fine git push origin master To see the difference with upstream (it should be empty) git diff @ { upstream } Synchronize the dev branch with the latest master sync git checkout dev git merge origin/master git push # same as \"push origin dev\" because dev is checkout In case that you did not, push to the corresponding branch to the server git push origin dev git push origin pull_request_xxx git push origin feature_xx_4dev Create new pull request to upstream Make sure that origin/master is in sync (step 5) git diff @ { upstream } # should be empty Rebase/merge the feature request with latest origin master git checkout pull_request_xxx git rebase master git push upstream pull_request_xxx Now create a pull request through github, and the UCSC/MASC team will review it. Occasional Pull Request steps If you just want to do some small contributions to LiveHD doing a public fork is the easiest way to contribute. Just fork, commit to forked master, and click on the web link after you push. Frequent Contributor If you are working on LiveHD at UC Santa Cruz, contact Jose Renau to be added to the MASC organization on GitHub so that you have write access to the repo. The setup is similar to the infrequent contributor flow but you have access to directly commit to the public repository. Even the upstream/master.","title":"GitHub Guide"},{"location":"livehd/04c-github/#github-guide","text":"LiveHD is the synthesis/emulation flow primarily maintained and developed by the MASC lab at UC Santa Cruz. Since LiveHD is used for computer architecture and VLSI research, the MASC lab has an internal private repo for some still in progress works. This is done using a private repo so that we can wait until the research is published before pushing changes to the public repo hosted on GitHub. This guide explains how we use git at the MASC group, and how you could setup a similar flow to contribute to the LiveHD project. Other groups may choose to adapt this technique for their own use. LiveHD uses bazel as a build system, as a result, we no longer use submodules. Instead we use the built-in bazel support to pull specific repositories.","title":"GitHub Guide"},{"location":"livehd/04c-github/#github-configuration-and-commands","text":"This section is for git first time users and to show the git configuration used by the MASC group.","title":"Github Configuration and Commands"},{"location":"livehd/04c-github/#configuration","text":"Suggested options for git first time users # Rebase no merge by default git config --global pull.rebase true # Set your name and email git config --global user.email \"perico@lospalotes.com\" git config --global user.name \"Perico LosPalotes\" git config --global pull.rebase true git config --global rebase.autoStash true","title":"Configuration"},{"location":"livehd/04c-github/#rebase-vs-no-rebase","text":"Rebase creates cleaner logs, but sometimes it gets difficult to fix conflicts with rebase. For cases that you are struggling to merge a conflict, you could do this: # undo the failed rebase merge git rebase --abort # make sure that your code changes were committed git commit -a -m \"Your commit message\" git pull --no-rebase # Fix the conflict without rebase (easier) git commit -a -m \"your merge message\" git pull --no-rebase git push","title":"Rebase vs No-Rebase"},{"location":"livehd/04c-github/#typical-git-commands","text":"Clean the directory from any file not in git (it will remove all the files not committed) git clean -fdx Save and restore un-committed changes to allow a new git pull. stash is like a \"push\" and \"pop\" replays the changes in the current directory. This will happen automatically if you have the autoStash configuration option. git stash git pull git stash pop See the differences against the server (still not pushed). Everything may be committed, so git diff may be empty git diff @ { u }","title":"Typical git commands"},{"location":"livehd/04c-github/#git-hercules-statistics","text":"hercules --languages C++ --burndown --burndown-people --pb https://github.com/masc-ucsc/livehd >hercules1.data labours -f pb -m overwrites-matrix -o hercules1a.pdf <hercules1.data labours -f pb -m ownership -o hercules1b.pdf <hercules1.data hercules --languages C++ --burndown --first-parent --pb https://github.com/masc-ucsc/livehd >hercules2.data labours -f pb -m burndown-project -o hercules2.pdf <hercules2.data hercules --languages C++ --devs --pb https://github.com/masc-ucsc/livehd >hercules3.data labours -f pb -m old-vs-new -o hercules3a.pdf <hercules3.data labours -f pb -m devs -o hercules3b.pdf <hercules3.data labours -f pb -m devs-efforts -o hercules3c.pdf <hercules3.data","title":"Git Hercules statistics"},{"location":"livehd/04c-github/#testdeveloper-livehd-case-no-commits","text":"If you do not plan to do many changes, and just wants to try LiveHD or be a LiveHD user, the easiest way is to just clone the repo: git clone https://github.com/masc-ucsc/livehd cd livehd From time to time, you should get the latest version to have the latest bug fixes/patches. Just a typical git pull should suffice: git pull","title":"Test/Developer LiveHD case (no commits)"},{"location":"livehd/04c-github/#infrequent-contributor-flow-advanced-users","text":"These are instructions for advanced users, more likely other university/company institutions with a team working on this project. The larger team may want to have some private repository with internal development and some pushes/pulls to the main LiveHD repo. For single external users, I would suggest to just fork the repository and do pull requests. If you work outside UCSC and/or you are an infrequent contributor, you have two main options: fork or private clone. The fork approach requires you to have your repository public, if you have publications or work-in-progress that you do not want to share the best option is to have a private repo (livehd-private). The simplest way to contribute to LiveHD is to create a public repo or a public fork, and a pull request. Most git guides use the origin/master (in fork or private repo) to synchronize with upstream/master (upstream main LiveHD repo). This means that your local changes should NOT go to your origin/master. Instead, you should create a branch for your local work. This works like a charm if you do pull requests, and it is reasonable if you have a long development branch without intention to push upstream. Although it is possible to create a different setup, we recommend that you keep the origin/master clean to synchronize with upstream/origin. You should create a new branch for each feature that you may want to upstream (origin/feature-x), and a local development branch (dev) for all your team members. Clone the repo: git clone https://github.com/masc-ucsc/livehd.git livehd cd livehd Create development branch (dev) git checkout -b dev Create a branch from origin/master to create a pull request to upstream/master git checkout -b pull_request_xxx Create a branch from dev for internal development if needed git checkout -b feature_xx_4dev dev Synchronize origin/master from main upstream/master Add remote upstream (if not added before) git remote -v If remote -v did not list upstream. Add them git remote add upstream https://github.com/masc-ucsc/livehd.git git fetch upstream Make sure that you are in origin/master git checkout master Bring the changes from the remote upstream/master to local master/origin git merge upstream/master Push to repo origin/master if everything was fine git push origin master To see the difference with upstream (it should be empty) git diff @ { upstream } Synchronize the dev branch with the latest master sync git checkout dev git merge origin/master git push # same as \"push origin dev\" because dev is checkout In case that you did not, push to the corresponding branch to the server git push origin dev git push origin pull_request_xxx git push origin feature_xx_4dev Create new pull request to upstream Make sure that origin/master is in sync (step 5) git diff @ { upstream } # should be empty Rebase/merge the feature request with latest origin master git checkout pull_request_xxx git rebase master git push upstream pull_request_xxx Now create a pull request through github, and the UCSC/MASC team will review it.","title":"Infrequent Contributor Flow (ADVANCED USERS)"},{"location":"livehd/04c-github/#occasional-pull-request-steps","text":"If you just want to do some small contributions to LiveHD doing a public fork is the easiest way to contribute. Just fork, commit to forked master, and click on the web link after you push.","title":"Occasional Pull Request steps"},{"location":"livehd/04c-github/#frequent-contributor","text":"If you are working on LiveHD at UC Santa Cruz, contact Jose Renau to be added to the MASC organization on GitHub so that you have write access to the repo. The setup is similar to the infrequent contributor flow but you have access to directly commit to the public repository. Even the upstream/master.","title":"Frequent Contributor"},{"location":"livehd/04d-style/","text":"Coding Style These are the coding style rules for LiveHD C++. Each rule can be broken, but it should be VERY rare, and a small comment should be placed explaining why. Overall When possible keep the system simple. Complexity is the enemy of maintenance. Deprecate no longer used features. Try to reduce friction. This means to avoid hidden/complex steps. Every main API should have a unit test for testing but also to demonstrate usage. comments Code should be the comments, try to keep comments concise. They should explain the WHY not the HOW. The code is the HOW. Labels used in comments: // FIXME: Known bug/issue but no time to fix it at the moment // TODO: Code improvement that will improve perf/quality/??? but no time at the moment // WARNING: message for some \"strange\" \"weird\" code that if changes has effects // (bug). Usually, this is a \"not nice\" code that must be kept for some reason. // NOTE: Any comment that you want to remember something about (not critical) // STYLE: why you broke a style rule (pointers, iterator...) strings Avoid std::string and std::string_view. Use them only when interfacing external project. Use mmap_lib::str Avoid pointers, use std::unique_ptr with RAII Variable naming rules No camelCase. Use underscores to separate words: foo_bar = Foo_bar ( 3 ); Use plural for containers with multiple entries like vector, singular otherwise elem = entries [ index ]; Classes/types/enums start with uppercase. Lowercase otherwise val = My_enum :: Big ; class Sweet_potato { Error handling and exceptions Use the Pass::error or Pass:warn for error and likely error (warn). Internally, error generates and exception capture by the main lgshell to move to the next task. Pass :: error ( \"inou_yaml: can only have a yaml_input or a graph_name, not both\" ); Pass :: warn ( \"inou_yaml.to_lg: output:{} input:{} graph:{}\" , output , input , graph_name ); No tabs, indentation is 2 spaces Make sure to configure your editor to use 2 spaces You can configure your text editor to do this automatically Include order First do C includes (try to avoid when possible), then an empty line with C++ includes, then an empty line followed with lgraph related includes. E.g: #include <sys/types.h> #include <dirent.h> #include <iostream> #include <set> #include \"graph_library.hpp\" #include \"lgedgeiter.hpp\" Keep column widths short Less than 120 characters if at all possible (meaning not compromising readability) You can configure your text editor to do this automatically Avoid trailing spaces You can configure your text editor to highlight them. https://github.com/ntpeters/vim-better-whitespace Use C++14 iterators not ::iterator for ( auto idx : g -> unordered ()) { } Use structured returns when iterator is returned for cleaner code: for ( const auto & [ name , id ] : name2id ) { // ... Use \"auto\", or \"const auto\", when possible. for ( auto idx : g -> unordered ()) { for ( const auto & c : g -> out_edges ( idx )) { const and local variables It may be too verbose to write const all the time. The coding style request to use const (when possible) in iterators and pointers. The others are up to the programmer. Do not use std::unordered_set, std::map, use flat_hash_map or flat_hash_set from abseil #include \"absl/container/flat_hash_map.h\" #include \"absl/container/flat_hash_set.h\" absl :: flat_hash_map < Index_ID , RTLIL :: Wire *> my_example ; Some common idioms to handle map/sets Traverse the map/set, and as it traverses decide to erase some of the entries: for ( auto it = m . begin (), end = m . end (); it != end ;) { if ( condition_to_erase_it ) { m . erase ( it ++ ); } else { ++ it ; } } To check if a key is present: if ( set . contains ( key_value )) { } Use absl::Span instead of std::vector as return argument absl::Span is the equivalent of string_view for a string but for vectors. Like string_view, it does not have ownership, and the size in the span can decrease (not increase) without changing the original vector with \"subspan\". Faster and more functional, no reason to return \"const std::vector &\", instead return \"absl::Span \". #include \"absl/types/span.h\" absl :: Span < Sub_node > get_sub_nodes () const { I ( sub_nodes . size () >= 1 ); return absl :: MakeSpan ( sub_nodes ). subspan ( 1 ); // Skip first element from vector }; Pass by reference and use \"const\" when possible void print ( const Sub_node & g ); //or void edit ( Sub_node & g ); Note that older code still uses pointers, this is no longer allowed. Avoid dynamic allocation as much as possible The idea is to RARELY directly allocate pointer allocation Use: foo = Sweet_potato ( 3 , 7 ) instead of foo = new Sweet_potato ( 3 , 7 ) Do not use \"new\"/\"delete\" keywords. Use smart pointers if needed (VERY VERY rare) Use: foo = std :: make_unique < Sweet_potato > ( 3 , 7 ); instead of foo = new Sweet_potato ( 3 , 7 ) Use fmt::print to print messages for debugging fmt :: print ( \"This is a debug message, name = {}, id = {} \\n \" , g -> get_name (), idx ); Use accessors consistently get_XX(): gets \"const XX &\" from object without side effects (assert if it does not exist) operator(Y) is an alias for get_XX(Y) ref_XX(): gets \"XX * \" (nullptr if it does not exist) find_XX(): similar to get_XX but, if it does not exist return invalid object (is_invalid()) setup_XX(): gets XX from object, if it does not exists, it creates it create_XX(): clears previous XX from object, and creates a new and returns it set_XX(): sets XX to object, it creates if it does not exist. Similar to create, but does not return reference. If a variable is const, it can be exposed directly without get/set accessors foo = x.const_var; // No need to have x.get_const_var() Use bitarray class to have a compact bitvector marker bitarray visited ( g -> max_size ()); Use iassert extensively / be meaningful whenever possible in assertions This usually means use meaningful variable names and conditions that are easy to understand. If the meaning is not clear from the assertion, use a comment in the same line. This way, when the assertion is triggered it is easy to identify the problem. I ( n_edges > 0 ); //at least one edge needed to perform this function We use the https://github.com/masc-ucsc/iassert package. Go to the iassert for more details on the advantages and how to allow it to use GDB with assertions. Develop in debug mode and benchmark in release mode Extra checks should be only in debug. Debug and release must execute the same, only checks (not behavior change) allowed in debug mode. Benchmark in release. It is 2x-10x faster. Use compact if/else brackets Use clang-format as configured to catch style errors. LGraph clang-format is based on google format, but it adds several alignment directives and wider terminal. cd XXXX clang-format -i *pp std :: vector < LGraph *> Inou_yaml :: generate () { if ( opack . graph_name != \"\" ) { // ... } else { // .. } Decide how to use attributes Attributes are parameters or information that an be per Node, Node_pin or Edge. In LGraph, attributes are persistent. This means that they are kept across execution runs in the LGraph database (E.g: in lgdb). For persistent attributes, the structures to use are defined in core/annotate.hpp. Any new attribute must be added to \"annotate.hpp\" to preserve persistence and to make sure that they are cleared when needed. Many times it is important to have information per node, but that it is not persistent across runs. For example, when building a LGraph from Yosys, there is a need to remember pointers from yosys to LGraph. This by definition can not be persistent because pointers change across runs. For this case, there are several options. The Non-Persistent Annotations If the data structure needs to keep most of the node/pins in the Lgraph, use the compact_class notation: absl :: flat_hash_map < SomeData , Node_pin :: Compact_class > s2pin ; absl :: flat_hash_map < SomeData , Node :: Compact_class > s2node ; SomeData d1 ; Lgraph * lg ; // LGraph owning the node s2pin [ d1 ] = node . get_driver_pin (). get_compact_class (); // Example of use getting a pint s2node [ d1 ] = node . get_compact_class (); auto name = s2pin [ d1 ]. get_node ( lg ). get_name (); // Pick previously set driver name Another example: absl :: flat_hash_map < Node_pin :: Compact , RTLIL :: Wire *> input_map ; input_map [ pin . get_compact ()] = wire ; auto * wire = input_map [ pin . get_compact ()]; for ( const auto & [ key , value ] : input_map ) { Node_pin pin ( lg , key ); // Key is a ::Compact, not a Node_pin auto name = pin . get_name (); // ... Some use here } If the data structure just holds a small subset of the graph, you can keep the metadata, and use Node/Node_pin directly. E.g: absl :: flat_hash_map < SomeData , Node_pin > s2pin ; absl :: flat_hash_map < SomeData , Node > s2node ; SomeData d1 ; s2pin [ d1 ] = node . get_driver_pin (); // Example of use getting a pint s2node [ d1 ] = node ; auto name = s2pin [ d1 ]. get_name (); // Pick previously set driver name In this case, it is fine to use the full Node, Node_pin, or Edge. This has some pointers inside, but it is OK because it is not persistent. Avoid code duplication The rule is that if the same code appears in 3 places, it should be refactored Tool to detect duplication find . -name '*.?pp' | grep -v test >list.txt duplo -ml 12 -pt 90 list.txt report.txt","title":"Coding Style"},{"location":"livehd/04d-style/#coding-style","text":"These are the coding style rules for LiveHD C++. Each rule can be broken, but it should be VERY rare, and a small comment should be placed explaining why.","title":"Coding Style"},{"location":"livehd/04d-style/#overall","text":"When possible keep the system simple. Complexity is the enemy of maintenance. Deprecate no longer used features. Try to reduce friction. This means to avoid hidden/complex steps. Every main API should have a unit test for testing but also to demonstrate usage.","title":"Overall"},{"location":"livehd/04d-style/#comments","text":"Code should be the comments, try to keep comments concise. They should explain the WHY not the HOW. The code is the HOW. Labels used in comments: // FIXME: Known bug/issue but no time to fix it at the moment // TODO: Code improvement that will improve perf/quality/??? but no time at the moment // WARNING: message for some \"strange\" \"weird\" code that if changes has effects // (bug). Usually, this is a \"not nice\" code that must be kept for some reason. // NOTE: Any comment that you want to remember something about (not critical) // STYLE: why you broke a style rule (pointers, iterator...)","title":"comments"},{"location":"livehd/04d-style/#strings","text":"Avoid std::string and std::string_view. Use them only when interfacing external project. Use mmap_lib::str Avoid pointers, use std::unique_ptr with RAII","title":"strings"},{"location":"livehd/04d-style/#variable-naming-rules","text":"No camelCase. Use underscores to separate words: foo_bar = Foo_bar ( 3 ); Use plural for containers with multiple entries like vector, singular otherwise elem = entries [ index ]; Classes/types/enums start with uppercase. Lowercase otherwise val = My_enum :: Big ; class Sweet_potato {","title":"Variable naming rules"},{"location":"livehd/04d-style/#error-handling-and-exceptions","text":"Use the Pass::error or Pass:warn for error and likely error (warn). Internally, error generates and exception capture by the main lgshell to move to the next task. Pass :: error ( \"inou_yaml: can only have a yaml_input or a graph_name, not both\" ); Pass :: warn ( \"inou_yaml.to_lg: output:{} input:{} graph:{}\" , output , input , graph_name );","title":"Error handling and exceptions"},{"location":"livehd/04d-style/#no-tabs-indentation-is-2-spaces","text":"Make sure to configure your editor to use 2 spaces You can configure your text editor to do this automatically","title":"No tabs, indentation is 2 spaces"},{"location":"livehd/04d-style/#include-order","text":"First do C includes (try to avoid when possible), then an empty line with C++ includes, then an empty line followed with lgraph related includes. E.g: #include <sys/types.h> #include <dirent.h> #include <iostream> #include <set> #include \"graph_library.hpp\" #include \"lgedgeiter.hpp\"","title":"Include order"},{"location":"livehd/04d-style/#keep-column-widths-short","text":"Less than 120 characters if at all possible (meaning not compromising readability) You can configure your text editor to do this automatically","title":"Keep column widths short"},{"location":"livehd/04d-style/#avoid-trailing-spaces","text":"You can configure your text editor to highlight them. https://github.com/ntpeters/vim-better-whitespace","title":"Avoid trailing spaces"},{"location":"livehd/04d-style/#use-c14-iterators-not-iterator","text":"for ( auto idx : g -> unordered ()) { } Use structured returns when iterator is returned for cleaner code: for ( const auto & [ name , id ] : name2id ) { // ...","title":"Use C++14 iterators not ::iterator"},{"location":"livehd/04d-style/#use-auto-or-const-auto-when-possible","text":"for ( auto idx : g -> unordered ()) { for ( const auto & c : g -> out_edges ( idx )) {","title":"Use \"auto\", or \"const auto\", when possible."},{"location":"livehd/04d-style/#const-and-local-variables","text":"It may be too verbose to write const all the time. The coding style request to use const (when possible) in iterators and pointers. The others are up to the programmer.","title":"const and local variables"},{"location":"livehd/04d-style/#do-not-use-stdunordered_set-stdmap-use-flat_hash_map-or-flat_hash_set-from-abseil","text":"#include \"absl/container/flat_hash_map.h\" #include \"absl/container/flat_hash_set.h\" absl :: flat_hash_map < Index_ID , RTLIL :: Wire *> my_example ;","title":"Do not use std::unordered_set, std::map, use flat_hash_map or flat_hash_set from abseil"},{"location":"livehd/04d-style/#some-common-idioms-to-handle-mapsets","text":"Traverse the map/set, and as it traverses decide to erase some of the entries: for ( auto it = m . begin (), end = m . end (); it != end ;) { if ( condition_to_erase_it ) { m . erase ( it ++ ); } else { ++ it ; } } To check if a key is present: if ( set . contains ( key_value )) { }","title":"Some common idioms to handle map/sets"},{"location":"livehd/04d-style/#use-abslspan-instead-of-stdvector-as-return-argument","text":"absl::Span is the equivalent of string_view for a string but for vectors. Like string_view, it does not have ownership, and the size in the span can decrease (not increase) without changing the original vector with \"subspan\". Faster and more functional, no reason to return \"const std::vector &\", instead return \"absl::Span \". #include \"absl/types/span.h\" absl :: Span < Sub_node > get_sub_nodes () const { I ( sub_nodes . size () >= 1 ); return absl :: MakeSpan ( sub_nodes ). subspan ( 1 ); // Skip first element from vector };","title":"Use absl::Span instead of std::vector as return argument"},{"location":"livehd/04d-style/#pass-by-reference-and-use-const-when-possible","text":"void print ( const Sub_node & g ); //or void edit ( Sub_node & g ); Note that older code still uses pointers, this is no longer allowed.","title":"Pass by reference and use \"const\" when possible"},{"location":"livehd/04d-style/#avoid-dynamic-allocation-as-much-as-possible","text":"The idea is to RARELY directly allocate pointer allocation Use: foo = Sweet_potato ( 3 , 7 ) instead of foo = new Sweet_potato ( 3 , 7 )","title":"Avoid dynamic allocation as much as possible"},{"location":"livehd/04d-style/#do-not-use-newdelete-keywords-use-smart-pointers-if-needed-very-very-rare","text":"Use: foo = std :: make_unique < Sweet_potato > ( 3 , 7 ); instead of foo = new Sweet_potato ( 3 , 7 )","title":"Do not use \"new\"/\"delete\" keywords. Use smart pointers if needed (VERY VERY rare)"},{"location":"livehd/04d-style/#use-fmtprint-to-print-messages-for-debugging","text":"fmt :: print ( \"This is a debug message, name = {}, id = {} \\n \" , g -> get_name (), idx );","title":"Use fmt::print to print messages for debugging"},{"location":"livehd/04d-style/#use-accessors-consistently","text":"get_XX(): gets \"const XX &\" from object without side effects (assert if it does not exist) operator(Y) is an alias for get_XX(Y) ref_XX(): gets \"XX * \" (nullptr if it does not exist) find_XX(): similar to get_XX but, if it does not exist return invalid object (is_invalid()) setup_XX(): gets XX from object, if it does not exists, it creates it create_XX(): clears previous XX from object, and creates a new and returns it set_XX(): sets XX to object, it creates if it does not exist. Similar to create, but does not return reference. If a variable is const, it can be exposed directly without get/set accessors foo = x.const_var; // No need to have x.get_const_var()","title":"Use accessors consistently"},{"location":"livehd/04d-style/#use-bitarray-class-to-have-a-compact-bitvector-marker","text":"bitarray visited ( g -> max_size ());","title":"Use bitarray class to have a compact bitvector marker"},{"location":"livehd/04d-style/#use-iassert-extensively-be-meaningful-whenever-possible-in-assertions","text":"This usually means use meaningful variable names and conditions that are easy to understand. If the meaning is not clear from the assertion, use a comment in the same line. This way, when the assertion is triggered it is easy to identify the problem. I ( n_edges > 0 ); //at least one edge needed to perform this function We use the https://github.com/masc-ucsc/iassert package. Go to the iassert for more details on the advantages and how to allow it to use GDB with assertions.","title":"Use iassert extensively / be meaningful whenever possible in assertions"},{"location":"livehd/04d-style/#develop-in-debug-mode-and-benchmark-in-release-mode","text":"Extra checks should be only in debug. Debug and release must execute the same, only checks (not behavior change) allowed in debug mode. Benchmark in release. It is 2x-10x faster.","title":"Develop in debug mode and benchmark in release mode"},{"location":"livehd/04d-style/#use-compact-ifelse-brackets","text":"Use clang-format as configured to catch style errors. LGraph clang-format is based on google format, but it adds several alignment directives and wider terminal. cd XXXX clang-format -i *pp std :: vector < LGraph *> Inou_yaml :: generate () { if ( opack . graph_name != \"\" ) { // ... } else { // .. }","title":"Use compact if/else brackets"},{"location":"livehd/04d-style/#decide-how-to-use-attributes","text":"Attributes are parameters or information that an be per Node, Node_pin or Edge. In LGraph, attributes are persistent. This means that they are kept across execution runs in the LGraph database (E.g: in lgdb). For persistent attributes, the structures to use are defined in core/annotate.hpp. Any new attribute must be added to \"annotate.hpp\" to preserve persistence and to make sure that they are cleared when needed. Many times it is important to have information per node, but that it is not persistent across runs. For example, when building a LGraph from Yosys, there is a need to remember pointers from yosys to LGraph. This by definition can not be persistent because pointers change across runs. For this case, there are several options.","title":"Decide how to use attributes"},{"location":"livehd/04d-style/#the-non-persistent-annotations","text":"If the data structure needs to keep most of the node/pins in the Lgraph, use the compact_class notation: absl :: flat_hash_map < SomeData , Node_pin :: Compact_class > s2pin ; absl :: flat_hash_map < SomeData , Node :: Compact_class > s2node ; SomeData d1 ; Lgraph * lg ; // LGraph owning the node s2pin [ d1 ] = node . get_driver_pin (). get_compact_class (); // Example of use getting a pint s2node [ d1 ] = node . get_compact_class (); auto name = s2pin [ d1 ]. get_node ( lg ). get_name (); // Pick previously set driver name Another example: absl :: flat_hash_map < Node_pin :: Compact , RTLIL :: Wire *> input_map ; input_map [ pin . get_compact ()] = wire ; auto * wire = input_map [ pin . get_compact ()]; for ( const auto & [ key , value ] : input_map ) { Node_pin pin ( lg , key ); // Key is a ::Compact, not a Node_pin auto name = pin . get_name (); // ... Some use here } If the data structure just holds a small subset of the graph, you can keep the metadata, and use Node/Node_pin directly. E.g: absl :: flat_hash_map < SomeData , Node_pin > s2pin ; absl :: flat_hash_map < SomeData , Node > s2node ; SomeData d1 ; s2pin [ d1 ] = node . get_driver_pin (); // Example of use getting a pint s2node [ d1 ] = node ; auto name = s2pin [ d1 ]. get_name (); // Pick previously set driver name In this case, it is fine to use the full Node, Node_pin, or Edge. This has some pointers inside, but it is OK because it is not persistent.","title":"The Non-Persistent Annotations"},{"location":"livehd/04d-style/#avoid-code-duplication","text":"The rule is that if the same code appears in 3 places, it should be refactored Tool to detect duplication find . -name '*.?pp' | grep -v test >list.txt duplo -ml 12 -pt 90 list.txt report.txt","title":"Avoid code duplication"},{"location":"pyrope/","text":"Introduction Warning This document explains the future Pyrope, some features are still not implemented. They are documented to guide the designers. Pyrope is a modern hardware description language, with these focus points: Fast parallel and incremental elaboration. Help hardware verification: Powerful synthesizable type system Hot-Reload support, powerful assertions Allows Pyrope 2 Verilog, edit Verilog, Verilog 2 Pyrope, edit Pyrope... Static checks as long as they not produce false positives Modern and concise language Avoiding hardware specific artifacts Synthesis and simulation must be equal and deterministic Zero cost abstraction Hello World Create a directory for the project: $ mkdir hello $ cd hello $ mkdir src Populate the Pyrope code src/hello.prp test \"quite empty\" { puts \"hello world\" } Run $prp test All the pyrope files reside in src directory. The prp builder calls LiveHD to elaborate the pyrope files and run all the tests. Trivial GCD Populate the Pyrope code Pyrope 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 // src/gcd.prp if $load_values { #x = $value1 #y = $value2 }else{ #x = if #x > #y { #x - #y } else { #y - #x } %z = #x %v = #y == 0 } test \"16bits gcd\" { for i in 1..=100 { for j in 1..=100 { $value1 = i $value2 = j $load_values = true puts \"trying gcd({},{})\", $value1, $value2 step 1 // advance 1 clock $load_values = false // deactivate load waitfor %z == true puts \"result is {}\", %v assert %v == __my_cpp_gcd(v1=$value1, v2=$value2) } } } // src/my_cpp_gcd.cpp void my_gcd_cpp(const Lbundle &inp, Lbundle &out) { auto [x,ok1] = inp.get_const(\"v1\"); auto [y,ok2] = inp.get_const(\"v2\"); assert(ok1 && ok2); // both must be defined while (y > 0) { if (x > y) { x -= y } else { y -= x } } out.add_const(x); } CHISEL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 import Chisel . _ import firrtl_interpreter . InterpretiveTester import org . scalatest .{ Matchers , FlatSpec } object GCDCalculator { def computeGcd ( a : Int , b : Int ): ( Int , Int ) = { var x = a var y = b while ( y > 0 ) { if ( x > y ) { x -= y } else { y -= x } } x } } class GCD extends Module { val io = new Bundle { val a = UInt ( INPUT , 16 ) val b = UInt ( INPUT , 16 ) val e = Bool ( INPUT ) val z = UInt ( OUTPUT , 16 ) val v = Bool ( OUTPUT ) } val x = Reg ( UInt ()) val y = Reg ( UInt ()) when ( x > y ) { x := x - y } unless ( x > y ) { y := y - x } when ( io . e ) { x := io . a ; y := io . b } io . z := x io . v := y === UInt ( 0 ) } class InterpreterUsageSpec extends FlatSpec with Matchers { \"GCD\" should \"return correct values for a range of inputs\" in { val s = Driver . emit (() => new GCD ) val tester = new InterpretiveTester ( s ) for { i <- 1 to 100 j <- 1 to 100 } { tester . poke ( \"io_a\" , i ) tester . poke ( \"io_b\" , j ) tester . poke ( \"io_e\" , 1 ) tester . step () tester . poke ( \"io_e\" , 0 ) while ( tester . peek ( \"io_v\" ) != BigInt ( 1 )) { tester . step () } tester . expect ( \"io_z\" , BigInt ( GCDCalculator . computeGcd ( i , j ). _1 )) } tester . report () } } Run $prp test gcd The gcd.prp includes the top level module ( gcd ) and the unit test. To understand the differences with alternative HDLs, the same GCD with CHISEL: Some of the visible differences: Pyrope has global type inference. The gcd.prp file doe not specify any size. The size is inferred from instantiation, in this case the test. Pyrope has special variable markers: $ is for inputs, % for outputs, and # for registers. CHISEL is a DSL. E.g: the = are SCALA, the === is generated HDL. The GCDCalculator is a SCALA program, and the GCD is a generated CHISEL module. Some not so visible differences: Pyrope is not a DSL. There are several DSL Hardware Description Languages (HDL) like CHISEL, pyMTL, pyRTL, C\u03bbaSH. In all the DSL cases, there is a host language (SCALA, or Python, or Haskell) that must be executed. The result of the execution is the hardware description which can be Verilog or some internal IR like FIRRTL in CHISEL. The advantage of the DSL is that it can leverage the existing language to have a nice hardware generator. The disadvantage is that there are 2 languages at once, the DSL and the host language, and that it is difficult to do incremental because the generated executable from host language must be executed to generate the design.","title":"Introduction"},{"location":"pyrope/#introduction","text":"Warning This document explains the future Pyrope, some features are still not implemented. They are documented to guide the designers. Pyrope is a modern hardware description language, with these focus points: Fast parallel and incremental elaboration. Help hardware verification: Powerful synthesizable type system Hot-Reload support, powerful assertions Allows Pyrope 2 Verilog, edit Verilog, Verilog 2 Pyrope, edit Pyrope... Static checks as long as they not produce false positives Modern and concise language Avoiding hardware specific artifacts Synthesis and simulation must be equal and deterministic Zero cost abstraction","title":"Introduction"},{"location":"pyrope/#hello-world","text":"Create a directory for the project: $ mkdir hello $ cd hello $ mkdir src Populate the Pyrope code src/hello.prp test \"quite empty\" { puts \"hello world\" } Run $prp test All the pyrope files reside in src directory. The prp builder calls LiveHD to elaborate the pyrope files and run all the tests.","title":"Hello World"},{"location":"pyrope/#trivial-gcd","text":"Populate the Pyrope code Pyrope 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 // src/gcd.prp if $load_values { #x = $value1 #y = $value2 }else{ #x = if #x > #y { #x - #y } else { #y - #x } %z = #x %v = #y == 0 } test \"16bits gcd\" { for i in 1..=100 { for j in 1..=100 { $value1 = i $value2 = j $load_values = true puts \"trying gcd({},{})\", $value1, $value2 step 1 // advance 1 clock $load_values = false // deactivate load waitfor %z == true puts \"result is {}\", %v assert %v == __my_cpp_gcd(v1=$value1, v2=$value2) } } } // src/my_cpp_gcd.cpp void my_gcd_cpp(const Lbundle &inp, Lbundle &out) { auto [x,ok1] = inp.get_const(\"v1\"); auto [y,ok2] = inp.get_const(\"v2\"); assert(ok1 && ok2); // both must be defined while (y > 0) { if (x > y) { x -= y } else { y -= x } } out.add_const(x); } CHISEL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 import Chisel . _ import firrtl_interpreter . InterpretiveTester import org . scalatest .{ Matchers , FlatSpec } object GCDCalculator { def computeGcd ( a : Int , b : Int ): ( Int , Int ) = { var x = a var y = b while ( y > 0 ) { if ( x > y ) { x -= y } else { y -= x } } x } } class GCD extends Module { val io = new Bundle { val a = UInt ( INPUT , 16 ) val b = UInt ( INPUT , 16 ) val e = Bool ( INPUT ) val z = UInt ( OUTPUT , 16 ) val v = Bool ( OUTPUT ) } val x = Reg ( UInt ()) val y = Reg ( UInt ()) when ( x > y ) { x := x - y } unless ( x > y ) { y := y - x } when ( io . e ) { x := io . a ; y := io . b } io . z := x io . v := y === UInt ( 0 ) } class InterpreterUsageSpec extends FlatSpec with Matchers { \"GCD\" should \"return correct values for a range of inputs\" in { val s = Driver . emit (() => new GCD ) val tester = new InterpretiveTester ( s ) for { i <- 1 to 100 j <- 1 to 100 } { tester . poke ( \"io_a\" , i ) tester . poke ( \"io_b\" , j ) tester . poke ( \"io_e\" , 1 ) tester . step () tester . poke ( \"io_e\" , 0 ) while ( tester . peek ( \"io_v\" ) != BigInt ( 1 )) { tester . step () } tester . expect ( \"io_z\" , BigInt ( GCDCalculator . computeGcd ( i , j ). _1 )) } tester . report () } } Run $prp test gcd The gcd.prp includes the top level module ( gcd ) and the unit test. To understand the differences with alternative HDLs, the same GCD with CHISEL: Some of the visible differences: Pyrope has global type inference. The gcd.prp file doe not specify any size. The size is inferred from instantiation, in this case the test. Pyrope has special variable markers: $ is for inputs, % for outputs, and # for registers. CHISEL is a DSL. E.g: the = are SCALA, the === is generated HDL. The GCDCalculator is a SCALA program, and the GCD is a generated CHISEL module. Some not so visible differences: Pyrope is not a DSL. There are several DSL Hardware Description Languages (HDL) like CHISEL, pyMTL, pyRTL, C\u03bbaSH. In all the DSL cases, there is a host language (SCALA, or Python, or Haskell) that must be executed. The result of the execution is the hardware description which can be Verilog or some internal IR like FIRRTL in CHISEL. The advantage of the DSL is that it can leverage the existing language to have a nice hardware generator. The disadvantage is that there are 2 languages at once, the DSL and the host language, and that it is difficult to do incremental because the generated executable from host language must be executed to generate the design.","title":"Trivial GCD"},{"location":"pyrope/02-basics/","text":"Basics Comments Comments begin with // , there are no multi-line comments // comment a = 3 // another comment Constants Pyrope has 3 basic constants: number : which is signed integer of unlimited precision string : which is a sequence of characters boolean : either true or false Numbers or integers Pyrope has unlimited precision signed integers. 0xF_a_0 // 4000 in hexa. Underscores have no meaning 0b1100 // 12 in binary 0sb1110 // -2 in binary (sb signed binary) 33 // 33 in decimal 0o111 // 73 in octal 0111 // 111 in decimal (some languages use octal here) Since powers of two are very common, Pyrope decimal numbers have the k , m , g modifiers. assert 1k == 1K == 1024 assert 1m == 1M == 1024*1024 assert 1g == 1G == 1024*1024*1024 Several hardware languages support unknown bits ( ? ) or high-impedance ( z ). Pyrope aims at being compatible with synthesizable Verilog, as such such values are also supported in the binary encoding. 0b? // 0 or 1 in decimal 0sb? // 0 or -1 in decimal 0b?0 // 0 or 2 in decimal 0sb0?0 // 0 or 2 in decimal 0b0?_1??0z_??z0 // valid value Like in many HDLs, Pyrope has unknowns ? . The x-propagation is a source of complexity in most hardware models. Pyrope has x or ? to be compatible with Verilog existing designs. The advise is not to use x besides match statement pattern matching. It is much better to use the default value (zero or empty string), but sometimes it is easier to use nil when converting Verilog code to Pyrope code. The nil means that the numeric value is invalid. If any operation is performed with nil, the result is an assertion failure. The only thing allowed to do with nil is to copy it. While the nil behaves like an invalid value, the 0sb? behaves like an unknown value that still can be used in arithmetic operations. Notice that nil is a state in the Number basic type, it is not a new type by itself, it does not represent invalid pointer, but rather invalid number. a = 0sb? & 0 // OK, result is 0 b = nil & 0 // Error Strings Pyrope accepts single line strings with single quote ( ' ) or double quote ( \" ). Single quote only has \\' as escape character. double quote supports extra escape sequences. a = \"hello \\n newline\" b = 'simpler here' \\n : newline \\\\ : backslash \\\" : double quote \\' : single quote (only one allowed in single quote) \\xNN : hexadecimal 8 bit character (2 digits) \\uNNNN : hexadecimal 16-bit Unicode character UTF-8 encoded (4 digits) Numbers and strings can be converted back and forth: a = \"127\" b = a.__to_i() c = a.__to_s() assert a == c assert b == 0x7F A Pyrope std library could provide a better interface in the future like a.to_i() , but fields that start with double underscore are reserved to interact with the LiveHD compiler or call the C++ provided library. Unique identifiers When an identifier uses an all upper case (E.g: ALL_CAPS ). Pyrope assigns a unique identifer for each upper case constant. The value is unique and not visible, but it can be used to index tuples or to compare equality. The identifier scope is the whole Pyrope file. a = ONE b = TWO assert a!=b val[ONE] = true newlines and spaces Spaces do not have meaning but new lines do. Several programming languages like Python use indentation level (spaces) to know the parsing meaning of expressions. In Pyrope, spaces do not have meaning, but new lines affect the operator precedence and multi line statements. By looking at the first character after a new line, it is possible to know if the rest of the line belongs to the previous statement or it is a new statement. If the line starts with a alphanumeric ( [a-z0-9] ) value or an open parenthesis ( ( ), the rest of the line belongs to a new statement. a = 1 + 3 // 1st stmt (b,c) = (1,3) // 2nd stmt d = 1 + 3 // compile error This functionality allows to parallelize the parsing and elaboration in Pyrope. Also, makes the code more readable. Avoiding multi-line comments is always a good idea. Pyrope has a very restricted/shallow operator precedence that forces to use parenthesis more frequently than other languages. The new line is a visual break that behaves like adding a open/close parenthesis after the first operator and the end of the line. a = 1 - 4 // same as: a = (1 - 4) * 1 + 4 // same as: * (1 + 4) * 2 * 3 // same as: * (2 * 3) Identifiers An identifier is any non reserved keyword that starts with an underscore or an alphabetic character. Since Pyrope is designer to support any synthesizable Verilog automatic translation, the any sequence of characters between ` can form a valid identifier. This is needed because Verilog has the \\ that builds identifiers with special characters. `foo is . strange!` = 4 Semicolons Semicolons are not needed to separate statements. In Pyrope, a semicolon ( ; ) has exactly the same meaning as a newline. Sometimes it is possible to add semicolons to separate statements. Since newlines affect the meaning of the program, a semicolon can do too. a = 1 ; b = 2 Printing Printing messages is useful for debugging. puts prints a message and the string is formatted using the c++20 fmt format. There is an implicit new line printed. The same without a newline can be achieved with print. a = 1 puts \"Hello a is {}\", a Since many modules can print at the same cycle, it is possible to put a relative order between puts ( order ). This example will print \"hello world\" even though there are 2 puts/prints in different files. // src/file1.prp puts order=2, \" world\" // src/file2.prp print order=1, \"hello\" The available puts/print arguments: * order : relative order to print in a given cycle * file : file to send the message. E.g: stdout , my_large.log ,...","title":"Basics"},{"location":"pyrope/02-basics/#basics","text":"","title":"Basics"},{"location":"pyrope/02-basics/#comments","text":"Comments begin with // , there are no multi-line comments // comment a = 3 // another comment","title":"Comments"},{"location":"pyrope/02-basics/#constants","text":"Pyrope has 3 basic constants: number : which is signed integer of unlimited precision string : which is a sequence of characters boolean : either true or false","title":"Constants"},{"location":"pyrope/02-basics/#numbers-or-integers","text":"Pyrope has unlimited precision signed integers. 0xF_a_0 // 4000 in hexa. Underscores have no meaning 0b1100 // 12 in binary 0sb1110 // -2 in binary (sb signed binary) 33 // 33 in decimal 0o111 // 73 in octal 0111 // 111 in decimal (some languages use octal here) Since powers of two are very common, Pyrope decimal numbers have the k , m , g modifiers. assert 1k == 1K == 1024 assert 1m == 1M == 1024*1024 assert 1g == 1G == 1024*1024*1024 Several hardware languages support unknown bits ( ? ) or high-impedance ( z ). Pyrope aims at being compatible with synthesizable Verilog, as such such values are also supported in the binary encoding. 0b? // 0 or 1 in decimal 0sb? // 0 or -1 in decimal 0b?0 // 0 or 2 in decimal 0sb0?0 // 0 or 2 in decimal 0b0?_1??0z_??z0 // valid value Like in many HDLs, Pyrope has unknowns ? . The x-propagation is a source of complexity in most hardware models. Pyrope has x or ? to be compatible with Verilog existing designs. The advise is not to use x besides match statement pattern matching. It is much better to use the default value (zero or empty string), but sometimes it is easier to use nil when converting Verilog code to Pyrope code. The nil means that the numeric value is invalid. If any operation is performed with nil, the result is an assertion failure. The only thing allowed to do with nil is to copy it. While the nil behaves like an invalid value, the 0sb? behaves like an unknown value that still can be used in arithmetic operations. Notice that nil is a state in the Number basic type, it is not a new type by itself, it does not represent invalid pointer, but rather invalid number. a = 0sb? & 0 // OK, result is 0 b = nil & 0 // Error","title":"Numbers or integers"},{"location":"pyrope/02-basics/#strings","text":"Pyrope accepts single line strings with single quote ( ' ) or double quote ( \" ). Single quote only has \\' as escape character. double quote supports extra escape sequences. a = \"hello \\n newline\" b = 'simpler here' \\n : newline \\\\ : backslash \\\" : double quote \\' : single quote (only one allowed in single quote) \\xNN : hexadecimal 8 bit character (2 digits) \\uNNNN : hexadecimal 16-bit Unicode character UTF-8 encoded (4 digits) Numbers and strings can be converted back and forth: a = \"127\" b = a.__to_i() c = a.__to_s() assert a == c assert b == 0x7F A Pyrope std library could provide a better interface in the future like a.to_i() , but fields that start with double underscore are reserved to interact with the LiveHD compiler or call the C++ provided library.","title":"Strings"},{"location":"pyrope/02-basics/#unique-identifiers","text":"When an identifier uses an all upper case (E.g: ALL_CAPS ). Pyrope assigns a unique identifer for each upper case constant. The value is unique and not visible, but it can be used to index tuples or to compare equality. The identifier scope is the whole Pyrope file. a = ONE b = TWO assert a!=b val[ONE] = true","title":"Unique identifiers"},{"location":"pyrope/02-basics/#newlines-and-spaces","text":"Spaces do not have meaning but new lines do. Several programming languages like Python use indentation level (spaces) to know the parsing meaning of expressions. In Pyrope, spaces do not have meaning, but new lines affect the operator precedence and multi line statements. By looking at the first character after a new line, it is possible to know if the rest of the line belongs to the previous statement or it is a new statement. If the line starts with a alphanumeric ( [a-z0-9] ) value or an open parenthesis ( ( ), the rest of the line belongs to a new statement. a = 1 + 3 // 1st stmt (b,c) = (1,3) // 2nd stmt d = 1 + 3 // compile error This functionality allows to parallelize the parsing and elaboration in Pyrope. Also, makes the code more readable. Avoiding multi-line comments is always a good idea. Pyrope has a very restricted/shallow operator precedence that forces to use parenthesis more frequently than other languages. The new line is a visual break that behaves like adding a open/close parenthesis after the first operator and the end of the line. a = 1 - 4 // same as: a = (1 - 4) * 1 + 4 // same as: * (1 + 4) * 2 * 3 // same as: * (2 * 3)","title":"newlines and spaces"},{"location":"pyrope/02-basics/#identifiers","text":"An identifier is any non reserved keyword that starts with an underscore or an alphabetic character. Since Pyrope is designer to support any synthesizable Verilog automatic translation, the any sequence of characters between ` can form a valid identifier. This is needed because Verilog has the \\ that builds identifiers with special characters. `foo is . strange!` = 4","title":"Identifiers"},{"location":"pyrope/02-basics/#semicolons","text":"Semicolons are not needed to separate statements. In Pyrope, a semicolon ( ; ) has exactly the same meaning as a newline. Sometimes it is possible to add semicolons to separate statements. Since newlines affect the meaning of the program, a semicolon can do too. a = 1 ; b = 2","title":"Semicolons"},{"location":"pyrope/02-basics/#printing","text":"Printing messages is useful for debugging. puts prints a message and the string is formatted using the c++20 fmt format. There is an implicit new line printed. The same without a newline can be achieved with print. a = 1 puts \"Hello a is {}\", a Since many modules can print at the same cycle, it is possible to put a relative order between puts ( order ). This example will print \"hello world\" even though there are 2 puts/prints in different files. // src/file1.prp puts order=2, \" world\" // src/file2.prp print order=1, \"hello\" The available puts/print arguments: * order : relative order to print in a given cycle * file : file to send the message. E.g: stdout , my_large.log ,...","title":"Printing"},{"location":"pyrope/03-bundle/","text":"Bundles Bundles are a basic construct in Pyrope. They provide a mix of tuples and structs. Tuples are usually defined as \"ordered\" sequence of elements, while structs or records are named but un-ordered data structures. Bundles can be \"ordered and named\", \"ordered\", or just \"named\". A bundle can not be unnamed and unordered. a.field1 = 1 a.field2 = 2 // a is named unordered b = (f1=3,f2=4) // b is named and ordered c = (1,d=4) // c is ordered and unnamed (some entries are not named) To access fields in a bundle we use the dot . or [] a = ( ,r1 = (b=1,c=2) ,r2 = (3,4) ) // different ways to access the same field assert a.r1.c == 2 assert a['r1'].c == 2 assert a.r1.1 == 2 assert a.r1[1] == 2 assert a[0][1] == 2 assert a[0]['c'] == 2 assert a['r1.c'] == 2 assert a['r1.1'] == 2 assert a['0.c'] == 2 assert a['0.1'] == 2 assert a.0.c == 2 assert a.0.1 == 2 assert a[':0:r1'].1 == 2 // indicate position with :num: assert a[':0:r1.1'] == 2 assert a[':0:r1.:1:c'] == 2 Ordered and named fields also can use :position:key to indicate the position and key. If either mismatches a compilation error is triggered. There is introspection to check for an existing field with the has operator. a.foo = 3 assert a has 'foo' assert !(a has 'bar') assert !(a has 0) // unordered v = (33,44,55) assert v has 2 assert !(v has 3)","title":"Bundles"},{"location":"pyrope/03-bundle/#bundles","text":"Bundles are a basic construct in Pyrope. They provide a mix of tuples and structs. Tuples are usually defined as \"ordered\" sequence of elements, while structs or records are named but un-ordered data structures. Bundles can be \"ordered and named\", \"ordered\", or just \"named\". A bundle can not be unnamed and unordered. a.field1 = 1 a.field2 = 2 // a is named unordered b = (f1=3,f2=4) // b is named and ordered c = (1,d=4) // c is ordered and unnamed (some entries are not named) To access fields in a bundle we use the dot . or [] a = ( ,r1 = (b=1,c=2) ,r2 = (3,4) ) // different ways to access the same field assert a.r1.c == 2 assert a['r1'].c == 2 assert a.r1.1 == 2 assert a.r1[1] == 2 assert a[0][1] == 2 assert a[0]['c'] == 2 assert a['r1.c'] == 2 assert a['r1.1'] == 2 assert a['0.c'] == 2 assert a['0.1'] == 2 assert a.0.c == 2 assert a.0.1 == 2 assert a[':0:r1'].1 == 2 // indicate position with :num: assert a[':0:r1.1'] == 2 assert a[':0:r1.:1:c'] == 2 Ordered and named fields also can use :position:key to indicate the position and key. If either mismatches a compilation error is triggered. There is introspection to check for an existing field with the has operator. a.foo = 3 assert a has 'foo' assert !(a has 'bar') assert !(a has 0) // unordered v = (33,44,55) assert v has 2 assert !(v has 3)","title":"Bundles"},{"location":"pyrope/04-variables/","text":"Variables and types A variable is an instance of a given type. The type may be inferred from use. The basic types are Number, String, Boolean, Functions, and Bundles. All the types are build around these basic types. Mutable/Immutable Variables are immutable by default and bundle fields are mutable by default. There are 3 keywords to handle mutability: var is used to declare mutable variables. let is used to declare immutable variables. mut is used to modify mutable variables. The mut keyword is not needed when there is a op= assignment. set is used to potentially add new fields to a mutable bundle. a = 3 a = 4 // compile error, 'a' is immutable a += 1 // compile error, 'a' is immutable var b = 3 mut b = 5 // OK b = 5 // compile error, 'b' is already declared as mutable b += 1 // OK, OP= assumes mutable mut b += 1 // OK, mut is not needed in this case var c=(x=1,let b=2, mut d=3) // mut d is redundant mut c.x = 3 // OK mut x.foo = 2 // compile error, bundle 'x' does not have field 'foo' set x.foo = 3 // OK mut c.b = 10 // compile error, 'c.b' is immutable let d=(x=1, let y=2) mut d.x = 2 // OK set d.foo = 3 // compile error, bundle 'd' is immutable mut d.y = 4 // compile error, 'd.y' is immutable Bundles can be mutable. This means that fields and subfields can be added with successive statements. var a.foo = (a=1,b=2) mut a.bar = 3 set a.foo ++= (c=4) assert a.foo.c == 4 Variable modifiers The first character[s] in the variable modify/indicate the behavior: $ : for inputs, all the inputs are immutable. E.g: $inp % : for outputs, all the outputs are mutable. E.g: %out # : for registers, all the registers are mutable. E.g: #reg _ : for private variables. It is a recommendation, not enforced by the compiler. %out = #counter if $enable { #counter = (#counter + 1) & 0xFF } comptime Pyrope borrows the comptime keyword and functionality from Zig. Variables, or expressions, can be declared compile time constants or comptime . This means that the value must be constant at compile time or an error is generated. let comptime a = 1 // obviously comptime var comptime b = a + 2 // OK too let comptime c = $rand // compile error, 'c' can not be computed at compile time The comptime directive considers values propagated across modules. debug In software and more commonly in hardware, it is common to have extra statements to debug the code. These statements can be more than plain assertions, they can also include code. The debug attribute marks a mutable or immutable variable. At synthesis, all the statements that use a debug can be removed. debug variables can read from non debug variables, but non-debug variables can not read from debug . This guarantees that debug variables, or statements, do not have any side-effect beyond debug statements. var a = (debug b=2, c = 3) // a.b is a debug variable let debug c = 3 Basic type annotations Global type inference and unlimited precision allows to avoid most of the types. Pyrope allows to declare types. The types have two main uses, they behave like assertions, and they allow function polymorphism. var a:u120 // a is an unsigned value with up to 120bits, initialized to zero var x:s3 = 0 // x is a signed value with 3 bits (-4 to 3) mut x = 3 // OK mut x = 4 // compile error, '4' overflows the maximum allowed value of 'x' var person = ( ,name:string // empty string by default ,age:u8 // zero by default ) var b b ++= (1,2) b ++= (3,4) assert b == (1,2,3,4) The basic type keywords provided by Pyrope: boolean : true or false boolean. It can not be undefined ( 0sb? ). string : a string. {||} : is a function without any statement which can be used as function type. unsigned : an unlimited precision natural number. u<num> : a natural number with a maximum value of \\(2^{\\texttt{num}}\\) . E.g: u10 can go from zero to 1024. int : an unlimited precision integer number. i<num> : an integer 2s complement number with a maximum value of \\(2^{\\texttt{num}-1}-1\\) and a minimum of \\(-2^{\\texttt{num}}\\) . Each bundle is has a type, either implicit or explicit, and as such it can be used to declared a new type. The type keywords guarantees that a variable is just a type and not an instance. var bund1 = (color:string, value:s33) var x:bund1 // OK bund1.color = \"red\" // OK x.color = \"blue\" // OK type typ = (color:string, value:s20) var y:typ // OK typ.color = \"red\" // compile errro y.color = \"red\" // OK Operators There are the typical basic operators found in most common languages with the exception exponent operations. The reason is that those are very hardware intensive and a library code should be used instead. All the operators work over signed integers. Unary operators ! or not logical negation ~ bitwise negation - arithmetic negation Binary operators + addition - substraction * multiplication / division and logical and or logical or implies logical implication & bitwise and | bitwise or ^ bitwise or >> shift right << shift left Most operations behave as expected when applied to signed unlimited precision integers. Logical and arithmetic operations can not be mixed. x = a and b y = x + 1 // compile error: 'x' is a boolean, '1' is not Reduce and bit selection operators The reduce operators and bit selection share a common syntax @op[selection] where there can be different operators (op) and/or bit selection. The valid operators: * | : or-reduce. * & : and-reduce. * ^ : xor-reduce or parity check. * + : pop-count. * sext : Sign extend select bits. * zext : Zero sign extend select bits. If no operator is provided, a zext is used. The bit selection without operator can also be used on the left hand side to update a set of bits. The bit selector. The or/and/xor reduce have a single bit signed output (not boolean). This means that the result can be 0 ( 0sb0 ) or -1 ( 0sb1 ). x = 0b10110 y = 0s10110 assert x@[0,2] == 0b10 assert y@[100,200] == 0b11 and x@[100,200] == 0 assert y@sext[100,200] == -1 and x@sext[100,200] == 0 assert x@|[] == -1 assert x@&[0,1] == 0 assert x@+[] == 3 and y@+[] == 3 var z = 0b0110 mut z@[0] = 1 // same as mut z@[0] = -1 assert z == 0b0111 mut z@[0] = 0b11 // compile error, '0b11` overflows the maximum allowed value of `z@[0]` Operator with bundles There are some operators that can also have bundles as input and/or outputs. ++ concatenate two bundles << shift left. The bundle can be in the right hand side has checks if a bundle has a field. The << allows to have multiple values provided by a bundle on the right hand side or amount. This is useful to create one-hot encodings. y = (a=1,b=2) ++ (c=3) assert y == (a=1,b=2,c=3) assert y has 'a' and y has 'c' x = 1<<(1,4,3) assert x == 0b01_1010 Precedence Pyrope has a very shallow precedence, unlike most other languages the programmer should explicitly indicate the precedence. The exception is for widely expected precedence. Unary operators (not,!,~,?) bind stronger than binary operators (+,++,-,*...) Always left-to-right evaluation. Comparators can be chained (a==c<=d) same as (a==c and c<=d) mult/div precedence is only against +,- operators. Parenthesis can be avoided when a expression only has variables (no function calls) and the left-to-right has the same result as right-to-left. Priority Category Main operators in category 1 unary not ! ~ ? 2 mult/div *, / 3 other binary ..,^, &, -,+, ++, --, <<, >> 4 comparators <, <=, ==, !=, >=, > 5 logical and, or, implies To reduce the number of parenthesis and increase the visual/structural organization, the newlines behave like inserting a parenthesis after the statement and the end of the line. assert (x or !y) == (x or (!y) == (x or not y) assert (3*5+5) == ((3*5) + 5) == 3*5 + 5 a = x1 or x2==x3 // same as b = x1 or (x2==x3) b = 3 & 4 * 4 // compile error: use explicit precendence between '&' and '*' c = 3 & 4 * 4 & 5 + 3 // OK, same as b = 3 & (4*4) & (5+3) d = 3 + 3 - 5 // OK, same result right-left // e = 1 | (5) & (6) // precendence problem even with newlines e = 1 | 5 & 6 // compile error: use explicit precendence between '&' and '|' f = 1 & 4 | 1 + 5 | 1 // OK, same as (1&4) | (1+5) | (1) g = 1 + 3 * 1 + 2 + 5 // OK, same as (1+3) * (1+2) + (5) h = x or y and z// compile error: use explicit precedence between 'or' and 'and' i = a == 3 <= b == d assert i == (a==3 and 3<=b and b == d)","title":"Variables and types"},{"location":"pyrope/04-variables/#variables-and-types","text":"A variable is an instance of a given type. The type may be inferred from use. The basic types are Number, String, Boolean, Functions, and Bundles. All the types are build around these basic types.","title":"Variables and types"},{"location":"pyrope/04-variables/#mutableimmutable","text":"Variables are immutable by default and bundle fields are mutable by default. There are 3 keywords to handle mutability: var is used to declare mutable variables. let is used to declare immutable variables. mut is used to modify mutable variables. The mut keyword is not needed when there is a op= assignment. set is used to potentially add new fields to a mutable bundle. a = 3 a = 4 // compile error, 'a' is immutable a += 1 // compile error, 'a' is immutable var b = 3 mut b = 5 // OK b = 5 // compile error, 'b' is already declared as mutable b += 1 // OK, OP= assumes mutable mut b += 1 // OK, mut is not needed in this case var c=(x=1,let b=2, mut d=3) // mut d is redundant mut c.x = 3 // OK mut x.foo = 2 // compile error, bundle 'x' does not have field 'foo' set x.foo = 3 // OK mut c.b = 10 // compile error, 'c.b' is immutable let d=(x=1, let y=2) mut d.x = 2 // OK set d.foo = 3 // compile error, bundle 'd' is immutable mut d.y = 4 // compile error, 'd.y' is immutable Bundles can be mutable. This means that fields and subfields can be added with successive statements. var a.foo = (a=1,b=2) mut a.bar = 3 set a.foo ++= (c=4) assert a.foo.c == 4","title":"Mutable/Immutable"},{"location":"pyrope/04-variables/#variable-modifiers","text":"The first character[s] in the variable modify/indicate the behavior: $ : for inputs, all the inputs are immutable. E.g: $inp % : for outputs, all the outputs are mutable. E.g: %out # : for registers, all the registers are mutable. E.g: #reg _ : for private variables. It is a recommendation, not enforced by the compiler. %out = #counter if $enable { #counter = (#counter + 1) & 0xFF }","title":"Variable modifiers"},{"location":"pyrope/04-variables/#comptime","text":"Pyrope borrows the comptime keyword and functionality from Zig. Variables, or expressions, can be declared compile time constants or comptime . This means that the value must be constant at compile time or an error is generated. let comptime a = 1 // obviously comptime var comptime b = a + 2 // OK too let comptime c = $rand // compile error, 'c' can not be computed at compile time The comptime directive considers values propagated across modules.","title":"comptime"},{"location":"pyrope/04-variables/#debug","text":"In software and more commonly in hardware, it is common to have extra statements to debug the code. These statements can be more than plain assertions, they can also include code. The debug attribute marks a mutable or immutable variable. At synthesis, all the statements that use a debug can be removed. debug variables can read from non debug variables, but non-debug variables can not read from debug . This guarantees that debug variables, or statements, do not have any side-effect beyond debug statements. var a = (debug b=2, c = 3) // a.b is a debug variable let debug c = 3","title":"debug"},{"location":"pyrope/04-variables/#basic-type-annotations","text":"Global type inference and unlimited precision allows to avoid most of the types. Pyrope allows to declare types. The types have two main uses, they behave like assertions, and they allow function polymorphism. var a:u120 // a is an unsigned value with up to 120bits, initialized to zero var x:s3 = 0 // x is a signed value with 3 bits (-4 to 3) mut x = 3 // OK mut x = 4 // compile error, '4' overflows the maximum allowed value of 'x' var person = ( ,name:string // empty string by default ,age:u8 // zero by default ) var b b ++= (1,2) b ++= (3,4) assert b == (1,2,3,4) The basic type keywords provided by Pyrope: boolean : true or false boolean. It can not be undefined ( 0sb? ). string : a string. {||} : is a function without any statement which can be used as function type. unsigned : an unlimited precision natural number. u<num> : a natural number with a maximum value of \\(2^{\\texttt{num}}\\) . E.g: u10 can go from zero to 1024. int : an unlimited precision integer number. i<num> : an integer 2s complement number with a maximum value of \\(2^{\\texttt{num}-1}-1\\) and a minimum of \\(-2^{\\texttt{num}}\\) . Each bundle is has a type, either implicit or explicit, and as such it can be used to declared a new type. The type keywords guarantees that a variable is just a type and not an instance. var bund1 = (color:string, value:s33) var x:bund1 // OK bund1.color = \"red\" // OK x.color = \"blue\" // OK type typ = (color:string, value:s20) var y:typ // OK typ.color = \"red\" // compile errro y.color = \"red\" // OK","title":"Basic type annotations"},{"location":"pyrope/04-variables/#operators","text":"There are the typical basic operators found in most common languages with the exception exponent operations. The reason is that those are very hardware intensive and a library code should be used instead. All the operators work over signed integers.","title":"Operators"},{"location":"pyrope/04-variables/#unary-operators","text":"! or not logical negation ~ bitwise negation - arithmetic negation","title":"Unary operators"},{"location":"pyrope/04-variables/#binary-operators","text":"+ addition - substraction * multiplication / division and logical and or logical or implies logical implication & bitwise and | bitwise or ^ bitwise or >> shift right << shift left Most operations behave as expected when applied to signed unlimited precision integers. Logical and arithmetic operations can not be mixed. x = a and b y = x + 1 // compile error: 'x' is a boolean, '1' is not","title":"Binary operators"},{"location":"pyrope/04-variables/#reduce-and-bit-selection-operators","text":"The reduce operators and bit selection share a common syntax @op[selection] where there can be different operators (op) and/or bit selection. The valid operators: * | : or-reduce. * & : and-reduce. * ^ : xor-reduce or parity check. * + : pop-count. * sext : Sign extend select bits. * zext : Zero sign extend select bits. If no operator is provided, a zext is used. The bit selection without operator can also be used on the left hand side to update a set of bits. The bit selector. The or/and/xor reduce have a single bit signed output (not boolean). This means that the result can be 0 ( 0sb0 ) or -1 ( 0sb1 ). x = 0b10110 y = 0s10110 assert x@[0,2] == 0b10 assert y@[100,200] == 0b11 and x@[100,200] == 0 assert y@sext[100,200] == -1 and x@sext[100,200] == 0 assert x@|[] == -1 assert x@&[0,1] == 0 assert x@+[] == 3 and y@+[] == 3 var z = 0b0110 mut z@[0] = 1 // same as mut z@[0] = -1 assert z == 0b0111 mut z@[0] = 0b11 // compile error, '0b11` overflows the maximum allowed value of `z@[0]`","title":"Reduce and bit selection operators"},{"location":"pyrope/04-variables/#operator-with-bundles","text":"There are some operators that can also have bundles as input and/or outputs. ++ concatenate two bundles << shift left. The bundle can be in the right hand side has checks if a bundle has a field. The << allows to have multiple values provided by a bundle on the right hand side or amount. This is useful to create one-hot encodings. y = (a=1,b=2) ++ (c=3) assert y == (a=1,b=2,c=3) assert y has 'a' and y has 'c' x = 1<<(1,4,3) assert x == 0b01_1010","title":"Operator with bundles"},{"location":"pyrope/04-variables/#precedence","text":"Pyrope has a very shallow precedence, unlike most other languages the programmer should explicitly indicate the precedence. The exception is for widely expected precedence. Unary operators (not,!,~,?) bind stronger than binary operators (+,++,-,*...) Always left-to-right evaluation. Comparators can be chained (a==c<=d) same as (a==c and c<=d) mult/div precedence is only against +,- operators. Parenthesis can be avoided when a expression only has variables (no function calls) and the left-to-right has the same result as right-to-left. Priority Category Main operators in category 1 unary not ! ~ ? 2 mult/div *, / 3 other binary ..,^, &, -,+, ++, --, <<, >> 4 comparators <, <=, ==, !=, >=, > 5 logical and, or, implies To reduce the number of parenthesis and increase the visual/structural organization, the newlines behave like inserting a parenthesis after the statement and the end of the line. assert (x or !y) == (x or (!y) == (x or not y) assert (3*5+5) == ((3*5) + 5) == 3*5 + 5 a = x1 or x2==x3 // same as b = x1 or (x2==x3) b = 3 & 4 * 4 // compile error: use explicit precendence between '&' and '*' c = 3 & 4 * 4 & 5 + 3 // OK, same as b = 3 & (4*4) & (5+3) d = 3 + 3 - 5 // OK, same result right-left // e = 1 | (5) & (6) // precendence problem even with newlines e = 1 | 5 & 6 // compile error: use explicit precendence between '&' and '|' f = 1 & 4 | 1 + 5 | 1 // OK, same as (1&4) | (1+5) | (1) g = 1 + 3 * 1 + 2 + 5 // OK, same as (1+3) * (1+2) + (5) h = x or y and z// compile error: use explicit precedence between 'or' and 'and' i = a == 3 <= b == d assert i == (a==3 and 3<=b and b == d)","title":"Precedence"},{"location":"pyrope/05-assert/","text":"Assertions Assertions are consider debug statements. This means that they can not have side effects on non-debug statements. Pyrope supports a syntax close to Verilog for assertions. The language is designed to have 3 levels of assertion checking: simulation runtime, compilation time, and formal verification time. There are 4 main methods: assert : The condition should be true at runtime. If comptime assert , the condition must be true at compile time. assume : Similar to assert, but allows the tool to simplify code based on it (it has optimization side-effects). verify : Similar to assert, but it is potentially slow to check, so checked at runtime or verification step. restrict : Constraints or restricts beyond to check a subset of the valid space. It only affects the verify command. The restrict command accepts a list of conditions to restrict a = 3 assert a == 3 // checked at runtime (or compile time) comptime assert a == 3 // checked at compile time verify a < 4 // checked at runtime and verification assume b > 3 // may optimize and perform a runtime check restrict foo < 1, foo >3 { verify bar == 4 // only checked at verification, restricting conditions } To guard an assertion for being checked unless some condition happens, you can use the when/unless statement modifier or the implies logic. All the verification statements ( assert , assume , verify ) can have an error message. a = 0 if cond { a = 3 } assert cond implies a == 3, \"the branch was taken, so it must be 3??\" assert a == 3, \"the same error\" when cond verify a == 0, \"the same error\" unless cond The recommendation is to write as many assert and assume as possible. If something can not happen, writing the assume has the advantage of allowing the synthesis tool to generate more efficient code. In a way, most type checks have equivalent comptime assert checks.","title":"Assertions"},{"location":"pyrope/05-assert/#assertions","text":"Assertions are consider debug statements. This means that they can not have side effects on non-debug statements. Pyrope supports a syntax close to Verilog for assertions. The language is designed to have 3 levels of assertion checking: simulation runtime, compilation time, and formal verification time. There are 4 main methods: assert : The condition should be true at runtime. If comptime assert , the condition must be true at compile time. assume : Similar to assert, but allows the tool to simplify code based on it (it has optimization side-effects). verify : Similar to assert, but it is potentially slow to check, so checked at runtime or verification step. restrict : Constraints or restricts beyond to check a subset of the valid space. It only affects the verify command. The restrict command accepts a list of conditions to restrict a = 3 assert a == 3 // checked at runtime (or compile time) comptime assert a == 3 // checked at compile time verify a < 4 // checked at runtime and verification assume b > 3 // may optimize and perform a runtime check restrict foo < 1, foo >3 { verify bar == 4 // only checked at verification, restricting conditions } To guard an assertion for being checked unless some condition happens, you can use the when/unless statement modifier or the implies logic. All the verification statements ( assert , assume , verify ) can have an error message. a = 0 if cond { a = 3 } assert cond implies a == 3, \"the branch was taken, so it must be 3??\" assert a == 3, \"the same error\" when cond verify a == 0, \"the same error\" unless cond The recommendation is to write as many assert and assume as possible. If something can not happen, writing the assume has the advantage of allowing the synthesis tool to generate more efficient code. In a way, most type checks have equivalent comptime assert checks.","title":"Assertions"},{"location":"pyrope/06-functions/","text":"Functions and methods Hardware description languages specify a tree-like structure of modules or functions. Usually, there is a top module that instantiates several sub-modules. The difference between module and function is mostly what is visible/left after synthesis. We call module any a function call is left visible in the generated netlist as a separate entity. If a function is inlined in the caller module, we do not call it module. By this definition, a function is a super-set of modules. Note Pyrope only supports a restricted amount of recursion. Recursion is only allowed when it can be unrolled at compile time. Function definition All the functions are lambdas that must passed as arguments or assigned to a given variable. There is no global scope for variables or functions. just_3 = { 3 } // just scope, not even a lambda is generated just_4 = {|| 4 } // function that returns 4 The simplest function resembles a scope with at { followed by a sequence of statements where the last statement can be an expression before the closing } . The difference between a function and a normal scope is the lambda definition enclosed between pipes ( | ). [ATTRIBUTES] | [META] [CAPTURE] [INPUT] [-> OUTPUT] [where COND] | ATTRIBUTES are optional method modifiers like: comptime : function should be computed at compile time debug : function is for debugging, not side effects in non-debug statements mut : function is a method that can modify variables using self . META are a list of type identifiers or type definitions. CAPTURE has the list of capture variables for the function. If no capture is provided, no variable can be captured. INPUT has a list of inputs allowed with optional types. If no input is provided, the $ bundle is used as input. OUTPUT has a list of outputs allowed with optional types. If no output is provided, the % bundle is used as output. COND is the condition under which this statement is valid. add = {|| $a+$b+$c } // no IO specified add = {|a,b,c| a+b+c } // constrain inputs to a,b,c add = {|(a,b,c)| a+b+c } // same add = {|a:u32,b:s3,c| a+b+c } // constrain some input types add = {|(a,b,c) -> :u32| a+b+c } // constrain result to u32 add = {|(a,b,c) -> res| a+b+c } // constrain result to be named res add = {|<T>(a:T,b:T,c:T)| a+b+c } // constrain inputs to have same type x = 2 add2 = {|[x](a)| x + a } // capture x add2 = {|[foo=x](a)| foo + a } // capture x but rename to something else y = ( ,val:u32 = 1 ,inc1 = {mut|| self.val := self.val + 1 } // mut allows to change bundle ) my_log = {debug|| print \"loging:\" for i in $ { print \" {}\", i } puts } my_log a, false, x+1 Implicit function per file Every Pyrope file creates an implicit function with the same name as the file and visible to the other files/functions in the same directory/project. Like any function, the input/outputs can be constrained or left to be inferred. // file: src/mycall_with_def.prp |(a,b) -> (d:u12)| %d = a + $a + $b // a or $a the same due to function definition // file: src/mycall_without_def.prp %d = $a + $a + $b // a or $a the same due to function definition assume %d < 4K Arguments Function calls have a bundle as input and another bundle as output. As such, bundles can be named, ordered or both. $ is the input bundle, and % is the output bundle. This implies: Arguments can be named. E.g: fcall(a=2,b=3) There can be many return values. E.g: return (a=3,b=5) Inputs can be accessed with the bundle. E.g: return $1 + 2 There are several rules on how to handle function arguments. Calls uses the Uniform Function Call Syntax (UFCS). (a,b).f(x,y) == f((a,b),x,y) Pipe |> concatenated inputs: (a,b) |> f(x,y) == f(x,y,a,b) No parenthesis after newline or a variable assignment: a = f(x,y) is the same as a = f x,y Pyrope uses a uniform function call syntax (UFCS) like other languages like Nim or D but it can be different from the order in other languages. Notice the different order in UFCS vs pipe, and also that in pipe the argument tuple is concatenated, but in UFCS the it is added as first argument. div = {|a,b| a / $b } // named input bundle div2 = {|| $0 / $1 } // unnamed input bundle a=div(3 , 4 , 3) // compile error, div has 2 inputs b=div(a=8, b=4) // OK, 2 c=div a=8, b=4 // OK, 2 d=(a=8).div(b=2) // OK, 4 e=(a=8).div b=2 // compile error, parenthesis is needed for function calls h=div2(8, 4, 3) // OK, 2 (3rd arg is not used) i=8.div2(4,3) // OK, 2 (3rd arg is not used) j=(8,4) |> div2 // OK, 2 k=(4) |> div2 8 // OK, 2 l=(4,33) |> div2(8) // OK, 2 m=4 |> div2 8 // OK, 2 n=div2((8,4), 3) // compile error: (8,4)/3 is undefined o=(8,4).div2(1) // compile error: (8,4)/1 is undefined Methods A method is a function associated to a bundle. The method names behave like capturing the bundle in the first argument and adding an extra return for the self object. var a_1 = ( ,x:u10 ,fun = {mut |x| assert $.__size == 2 // self and x self.a = x } ) a_1.fun(3) assert a_1.x == 3 fun2 = {|(x,self)| self.a = x ; return self } a_2 = a_1.fun2(4) assert a_1.x == 3 assert a_2.x == 4 To access the bundle contents, there are two keywords: self provides access to the upper level in the bundle. super provides the method before it was redefined. type base1 = ( ,fun = {|| a = super() // nothing after when called assert a == nil 1 } ) type base2 = ( ,fun = {|| a = super() assert a == 1 2 } ) type top = ( ,top_fun = {|| 4 } ,fun = {|| a = super() assert a == 2 return 33 } ) ++ base2 ++ base1 var a3:top assert a3.top_fun does {||} assert a3.top_fun.size == 1 assert a3.top_fun does {||} assert a3.top_fun.size == 1 assert a3.fun does {||} assert a3.fun.size == 3 // explicit overload assert a3.fun[0]() == 33 assert a3.fun[1]() == 2 assert a3.fun[2]() == 1 assert a3.fun() == 33 assert a3.fun() == 33 var a1:base1 var a2:base2 assert a1.fun() == 1 assert a2.fun() == 2","title":"Functions and methods"},{"location":"pyrope/06-functions/#functions-and-methods","text":"Hardware description languages specify a tree-like structure of modules or functions. Usually, there is a top module that instantiates several sub-modules. The difference between module and function is mostly what is visible/left after synthesis. We call module any a function call is left visible in the generated netlist as a separate entity. If a function is inlined in the caller module, we do not call it module. By this definition, a function is a super-set of modules. Note Pyrope only supports a restricted amount of recursion. Recursion is only allowed when it can be unrolled at compile time.","title":"Functions and methods"},{"location":"pyrope/06-functions/#function-definition","text":"All the functions are lambdas that must passed as arguments or assigned to a given variable. There is no global scope for variables or functions. just_3 = { 3 } // just scope, not even a lambda is generated just_4 = {|| 4 } // function that returns 4 The simplest function resembles a scope with at { followed by a sequence of statements where the last statement can be an expression before the closing } . The difference between a function and a normal scope is the lambda definition enclosed between pipes ( | ). [ATTRIBUTES] | [META] [CAPTURE] [INPUT] [-> OUTPUT] [where COND] | ATTRIBUTES are optional method modifiers like: comptime : function should be computed at compile time debug : function is for debugging, not side effects in non-debug statements mut : function is a method that can modify variables using self . META are a list of type identifiers or type definitions. CAPTURE has the list of capture variables for the function. If no capture is provided, no variable can be captured. INPUT has a list of inputs allowed with optional types. If no input is provided, the $ bundle is used as input. OUTPUT has a list of outputs allowed with optional types. If no output is provided, the % bundle is used as output. COND is the condition under which this statement is valid. add = {|| $a+$b+$c } // no IO specified add = {|a,b,c| a+b+c } // constrain inputs to a,b,c add = {|(a,b,c)| a+b+c } // same add = {|a:u32,b:s3,c| a+b+c } // constrain some input types add = {|(a,b,c) -> :u32| a+b+c } // constrain result to u32 add = {|(a,b,c) -> res| a+b+c } // constrain result to be named res add = {|<T>(a:T,b:T,c:T)| a+b+c } // constrain inputs to have same type x = 2 add2 = {|[x](a)| x + a } // capture x add2 = {|[foo=x](a)| foo + a } // capture x but rename to something else y = ( ,val:u32 = 1 ,inc1 = {mut|| self.val := self.val + 1 } // mut allows to change bundle ) my_log = {debug|| print \"loging:\" for i in $ { print \" {}\", i } puts } my_log a, false, x+1","title":"Function definition"},{"location":"pyrope/06-functions/#implicit-function-per-file","text":"Every Pyrope file creates an implicit function with the same name as the file and visible to the other files/functions in the same directory/project. Like any function, the input/outputs can be constrained or left to be inferred. // file: src/mycall_with_def.prp |(a,b) -> (d:u12)| %d = a + $a + $b // a or $a the same due to function definition // file: src/mycall_without_def.prp %d = $a + $a + $b // a or $a the same due to function definition assume %d < 4K","title":"Implicit function per file"},{"location":"pyrope/06-functions/#arguments","text":"Function calls have a bundle as input and another bundle as output. As such, bundles can be named, ordered or both. $ is the input bundle, and % is the output bundle. This implies: Arguments can be named. E.g: fcall(a=2,b=3) There can be many return values. E.g: return (a=3,b=5) Inputs can be accessed with the bundle. E.g: return $1 + 2 There are several rules on how to handle function arguments. Calls uses the Uniform Function Call Syntax (UFCS). (a,b).f(x,y) == f((a,b),x,y) Pipe |> concatenated inputs: (a,b) |> f(x,y) == f(x,y,a,b) No parenthesis after newline or a variable assignment: a = f(x,y) is the same as a = f x,y Pyrope uses a uniform function call syntax (UFCS) like other languages like Nim or D but it can be different from the order in other languages. Notice the different order in UFCS vs pipe, and also that in pipe the argument tuple is concatenated, but in UFCS the it is added as first argument. div = {|a,b| a / $b } // named input bundle div2 = {|| $0 / $1 } // unnamed input bundle a=div(3 , 4 , 3) // compile error, div has 2 inputs b=div(a=8, b=4) // OK, 2 c=div a=8, b=4 // OK, 2 d=(a=8).div(b=2) // OK, 4 e=(a=8).div b=2 // compile error, parenthesis is needed for function calls h=div2(8, 4, 3) // OK, 2 (3rd arg is not used) i=8.div2(4,3) // OK, 2 (3rd arg is not used) j=(8,4) |> div2 // OK, 2 k=(4) |> div2 8 // OK, 2 l=(4,33) |> div2(8) // OK, 2 m=4 |> div2 8 // OK, 2 n=div2((8,4), 3) // compile error: (8,4)/3 is undefined o=(8,4).div2(1) // compile error: (8,4)/1 is undefined","title":"Arguments"},{"location":"pyrope/06-functions/#methods","text":"A method is a function associated to a bundle. The method names behave like capturing the bundle in the first argument and adding an extra return for the self object. var a_1 = ( ,x:u10 ,fun = {mut |x| assert $.__size == 2 // self and x self.a = x } ) a_1.fun(3) assert a_1.x == 3 fun2 = {|(x,self)| self.a = x ; return self } a_2 = a_1.fun2(4) assert a_1.x == 3 assert a_2.x == 4 To access the bundle contents, there are two keywords: self provides access to the upper level in the bundle. super provides the method before it was redefined. type base1 = ( ,fun = {|| a = super() // nothing after when called assert a == nil 1 } ) type base2 = ( ,fun = {|| a = super() assert a == 1 2 } ) type top = ( ,top_fun = {|| 4 } ,fun = {|| a = super() assert a == 2 return 33 } ) ++ base2 ++ base1 var a3:top assert a3.top_fun does {||} assert a3.top_fun.size == 1 assert a3.top_fun does {||} assert a3.top_fun.size == 1 assert a3.fun does {||} assert a3.fun.size == 3 // explicit overload assert a3.fun[0]() == 33 assert a3.fun[1]() == 2 assert a3.fun[2]() == 1 assert a3.fun() == 33 assert a3.fun() == 33 var a1:base1 var a2:base2 assert a1.fun() == 1 assert a2.fun() == 2","title":"Methods"},{"location":"pyrope/06b-pipelining/","text":"Pipelining One of the fundamental differences between most programming languages and hardware description languages is that pipelining is a fundamental feature that must be used in hardware but not in software designs. To illustrate the confusion/complication the following example illustrates a multiplier that takes 3 cycles and an adder that takes 1 cycle to complete, and the conceptual problems of integrating them: |(in1,in2) -> (out)| add1 = {|a,b| // 1 cycle add #reg = a+b return #reg } mul3 = {|a,b| // 3 cycle multiply #reg1 = $a * $b #reg2 = #reg1 #reg3 = #reg2 return #reg3 } x =# mul3(in1, in2) %out =# add1(x,in3) The first observation is the new assignment =# instead of = . This is to explicitly indicate to Pyrope that the function called ( mul3 , add1 ) can have pipeline outputs. This helps the tool but more importantly the programmer because it helps to check assumptions about the function connections. The typical assignment = only connects combinational logic. The previous code connects two inputs (in1/in2) to a multiplier, and then connects the result of the multiplier to an adder. The in1 inputs is also passed to the adder. This results in the following functionality: graph LR in1[in1] --a--> m0(mul3 cycle 0) in2[in2] --b--> m0 m0 --> m1(mul3 cycle 1) m1 --> m2(mul3 cycle 2) in1--a--> a0[add1 cycle 1] m2 --b--> a0 a0 --> out[out] The issue in most HDLs is that the connection is unaware of the pipelining, and it is left up to the programmer to understand and check the potential pipeline stages inside add1 and mul3 . This lack of pipelining awareness in the language syntax is common in most HDLs. In Pyrope, the =# must be used when there is any path that starting from the inputs of the function passes through a pipeline stage to generate the assignment. If all the paths have exactly 1 flop in between, it is a 1 stage pipeline, if some paths have 2 flops and others 3, it is a 2 or 3 pipeline stages. Sometimes, there are loops, and the tool has 1 to infinite pipeline stages. The default pipeline assignment =# just checks that it is possible to have pipeline stages between the module/function inputs and the assignment value. To restrict the check, it accepts a range. E.g: =#[3] means that there are exactly 3 flops or cycles between inputs and the assignment. =#[0..<4] means that there are between 0 and 3 cycles, and open range could be used when there are loops (E.g: =#[2..] ). let x = mul3(in1, in2) // compile error: 'mul3' is pipelined let x =# mul3(in1, in2) // OK %out =# add1(x,in3) // OK (in3 has 0 cycles, x has 3 cycles) %out =#[1] add1(x,in3) // compile error: 'x' is pipelined with '3' cycles %out =#[3] add1(x,in3) // compile error: 'in3' is pipelined with '1' cycle %out =#[1..<4] add1(x,in3) // OK The previous code will check the assumptions in pipelining. It is likely that the designer wanted to implement a multiply-add. As such, the input to the adder should be from the same cycle as the multiplied started to operate. Otherwise, values across cycles are mixed. graph LR in1[in1] --a--> m0(mul3 cycle 0) in2[in2] --b--> m0 m0 --> m1(mul3 cycle 1) m1 --> m2(mul3 cycle 2) in1 --> in1_0(flop cycle 0) in1_0--> in1_1(flop cycle 1) in1_1--> in1_2(flop cycle 2) in1_2--a--> a0[add1 cycle 0] m2 --b--> a0 a0 --> out[out] It is possible to balance the pipeline stages explicitly, the issue is that it is error prone because it requires to know exactly the number of cycles for mul3 . This is were the repipe command becomes handy, it guarantees that all the paths from the inputs to every tuple entry has exactly the same pipeline depth. It does it by adding pipeline stages as needed. If it can not be done automatically like when there are loops, an error is generated and an explicit solution should be used. Explicitly added pipeline stages x =# mul3(in1, in2) y = in1#[-3] %out =# add1(a=x,b=y) // connect in1 from -3 cycles repipe statement x =# mul3(in1, in2) z = repipe (a=x,b=in1) // add flops to match x and in1 %out =# add1(z)) assert z.a == x // x is not repipelined assert z.b == in1#[-3] The |> keyword ( |> ) connects functions, but guarantees that all the outputs have the same delay from the inputs. Effectively, it adds a repipe command. With |> (a=mul3(in1, in2), b=in1) |> add |> %out // pipelined add.b input (a=mul3(in1, in2)) |> add(b=in1) // non-pipelined add.b input With repipe let x =# repipe (a=mul3(in1, in2), b=in1) // pipelined add.b input %out =# add(x) let x =# mul3(in1, in2) %out =# add(a=x, b=in1) // non-pipelined add.b input With explicit let x =# mul3(in1, in2) // pipelined add.b input %out =# add(a=x,b=in#[-3]) let x =# mul3(in1, in2) %out =# add(a=x, b=in1) // non-pipelined add.b input The repipe command arguments can add and remove pipeline stages. The default setting is to add pipeline stages to match, but those are future options: z = repipe (a=x,b=in1) to x // same as a=x,b=in#[-3] z = repipe (a=x,b=in1) to 5 // same as a=x#[-2],b=in#[-5] z = repipe (a=x,b=in1) to 0 // try to create a combinational path z = repipe (x ) to 2 // repipeline mul3 to have 2 stages","title":"Pipelining"},{"location":"pyrope/06b-pipelining/#pipelining","text":"One of the fundamental differences between most programming languages and hardware description languages is that pipelining is a fundamental feature that must be used in hardware but not in software designs. To illustrate the confusion/complication the following example illustrates a multiplier that takes 3 cycles and an adder that takes 1 cycle to complete, and the conceptual problems of integrating them: |(in1,in2) -> (out)| add1 = {|a,b| // 1 cycle add #reg = a+b return #reg } mul3 = {|a,b| // 3 cycle multiply #reg1 = $a * $b #reg2 = #reg1 #reg3 = #reg2 return #reg3 } x =# mul3(in1, in2) %out =# add1(x,in3) The first observation is the new assignment =# instead of = . This is to explicitly indicate to Pyrope that the function called ( mul3 , add1 ) can have pipeline outputs. This helps the tool but more importantly the programmer because it helps to check assumptions about the function connections. The typical assignment = only connects combinational logic. The previous code connects two inputs (in1/in2) to a multiplier, and then connects the result of the multiplier to an adder. The in1 inputs is also passed to the adder. This results in the following functionality: graph LR in1[in1] --a--> m0(mul3 cycle 0) in2[in2] --b--> m0 m0 --> m1(mul3 cycle 1) m1 --> m2(mul3 cycle 2) in1--a--> a0[add1 cycle 1] m2 --b--> a0 a0 --> out[out] The issue in most HDLs is that the connection is unaware of the pipelining, and it is left up to the programmer to understand and check the potential pipeline stages inside add1 and mul3 . This lack of pipelining awareness in the language syntax is common in most HDLs. In Pyrope, the =# must be used when there is any path that starting from the inputs of the function passes through a pipeline stage to generate the assignment. If all the paths have exactly 1 flop in between, it is a 1 stage pipeline, if some paths have 2 flops and others 3, it is a 2 or 3 pipeline stages. Sometimes, there are loops, and the tool has 1 to infinite pipeline stages. The default pipeline assignment =# just checks that it is possible to have pipeline stages between the module/function inputs and the assignment value. To restrict the check, it accepts a range. E.g: =#[3] means that there are exactly 3 flops or cycles between inputs and the assignment. =#[0..<4] means that there are between 0 and 3 cycles, and open range could be used when there are loops (E.g: =#[2..] ). let x = mul3(in1, in2) // compile error: 'mul3' is pipelined let x =# mul3(in1, in2) // OK %out =# add1(x,in3) // OK (in3 has 0 cycles, x has 3 cycles) %out =#[1] add1(x,in3) // compile error: 'x' is pipelined with '3' cycles %out =#[3] add1(x,in3) // compile error: 'in3' is pipelined with '1' cycle %out =#[1..<4] add1(x,in3) // OK The previous code will check the assumptions in pipelining. It is likely that the designer wanted to implement a multiply-add. As such, the input to the adder should be from the same cycle as the multiplied started to operate. Otherwise, values across cycles are mixed. graph LR in1[in1] --a--> m0(mul3 cycle 0) in2[in2] --b--> m0 m0 --> m1(mul3 cycle 1) m1 --> m2(mul3 cycle 2) in1 --> in1_0(flop cycle 0) in1_0--> in1_1(flop cycle 1) in1_1--> in1_2(flop cycle 2) in1_2--a--> a0[add1 cycle 0] m2 --b--> a0 a0 --> out[out] It is possible to balance the pipeline stages explicitly, the issue is that it is error prone because it requires to know exactly the number of cycles for mul3 . This is were the repipe command becomes handy, it guarantees that all the paths from the inputs to every tuple entry has exactly the same pipeline depth. It does it by adding pipeline stages as needed. If it can not be done automatically like when there are loops, an error is generated and an explicit solution should be used. Explicitly added pipeline stages x =# mul3(in1, in2) y = in1#[-3] %out =# add1(a=x,b=y) // connect in1 from -3 cycles repipe statement x =# mul3(in1, in2) z = repipe (a=x,b=in1) // add flops to match x and in1 %out =# add1(z)) assert z.a == x // x is not repipelined assert z.b == in1#[-3] The |> keyword ( |> ) connects functions, but guarantees that all the outputs have the same delay from the inputs. Effectively, it adds a repipe command. With |> (a=mul3(in1, in2), b=in1) |> add |> %out // pipelined add.b input (a=mul3(in1, in2)) |> add(b=in1) // non-pipelined add.b input With repipe let x =# repipe (a=mul3(in1, in2), b=in1) // pipelined add.b input %out =# add(x) let x =# mul3(in1, in2) %out =# add(a=x, b=in1) // non-pipelined add.b input With explicit let x =# mul3(in1, in2) // pipelined add.b input %out =# add(a=x,b=in#[-3]) let x =# mul3(in1, in2) %out =# add(a=x, b=in1) // non-pipelined add.b input The repipe command arguments can add and remove pipeline stages. The default setting is to add pipeline stages to match, but those are future options: z = repipe (a=x,b=in1) to x // same as a=x,b=in#[-3] z = repipe (a=x,b=in1) to 5 // same as a=x#[-2],b=in#[-5] z = repipe (a=x,b=in1) to 0 // try to create a combinational path z = repipe (x ) to 2 // repipeline mul3 to have 2 stages","title":"Pipelining"},{"location":"pyrope/07-typesystem/","text":"Type system Type systems are quite similar to sets. A main difference is that type systems may not be as accurate as a set system, and it may not allow the same expressiveness because some type of set properties may not be allowed to be specified. Most HDLs do not have modern type systems, but they could benefit like in other software domains. Additionally, in hardware it makes sense to have different implementations that adjust for performance/constrains like size, area, FPGA/ASIC. Type systems could help on these areas. Types vs comptime assert Pyrope has support for different types of assertions ( assert , comptime assert , assume , comptime assume , verify ). The type system checks, not the function overloading, can be translated to a set of comptime assert statements. Pyrope type checks can be translated to compile time assertion checks, but the type related language syntax makes it more readable/familiar with programmers. To understand the type check, it is useful to see an equivalent comptime assert translation. Each variable can have a type attached once. Each time that the variable is modified a comptime assert statement could check that the variable is compatible with the assigned type. From a practical perspective, the Pyrope type system works this way when variables are modified. Snippet with types var b = \"hello\" var a:u32 mut a += 1 mut a = b // fails type check Snippet with comptime assert var b = \"hello\" mut a += 1 comptime assert a does u32 mut a = b comptime assert a does u32 // fails type check The compiler handles automatically, but control flow instructions affect the equivalent assert statement. var a:type1 if $runtime { var b:type2 a = yyy // comptime assert $runtime implies yyy does :type1 b = xxx // comptime assert $runtime implies xxx does :type2 } a = zzz // comptime assert zzz does :type1 Building types Each variable can be a basic type like String, Boolean, Number, or a bundle. In addition, each variable can have a set of constrains from the type system. Although it is possible to declare just the comptime assert for type checks, the recommendation is to use the explicit Pyrope type syntax because it is more readable and easier to optimize. Pyrope type constructs: type keyword allows to declare types. a does b : Checks 'a' is a superset or equal to 'b'. In the future, the unicode character \"\\u02287\" could be used as an alternative to does ( a \u2287 b ); a:b is equivalent to a does b or comptime assert a does b check. :b returns the \"type of\" b when used in an expression. a equals b : Checks that a does b and b does a . Effectively checking that they have the same type. While var statement declares a new variable instance which can also have an associated type, the type statement declares a type without any instance. The type keyword also allows for expressions to build more complex types. All the elements in the type expression are treated as \"type of\". E.g: type x = a or 1..=3 is equivalent to write type x = :a or :(1..=3) type a1 = u32 // type a1 = :u32 is also valid syntax type a2 = int(max=33,min=-5) type a3 = ( ,name:string ,age:u8 ) type b1 = a1 or a2 // same as type b1 = -5..<4G type b2 = a1 and a2 // same as type b2 = 0..=33 type b3 = a1 or a3 // compile error: unclear how to combine type 'a1' and 'a2' The puts command understands types. type at=33.. // number bigger than 32 type bt=( ,c:string ,d=100 ,initial = {|| self.c = $ } ) var a:at=40 var v:bt=\"hello\" puts \"a:{} type:{} or {}\", a, :a, at // a:40 type:Number(33..) or Number(33..) puts \"b:{} type:{}\", b, :b // b:(c=\"hello\",d=100) type:(c:string,d=100)\" Some languages use an is keyword but Pyrope uses does or equals because in English \"a is b\" is not clear (\"a is same as b\" vs \"a is subtype of b\"). type x = (a:string, b:int) type y = (a:string) type z = (a:string, b:u32, c:i8) assert x does y assert y does y assert z does y assert !(x does z) assert !(y does z) assert !(y does x) assert !(z does x) type big = x or y or z or :(d:u33) assert big does x assert big does y assert big does z assert big does :(d:u20) assert !(big does :(d:u40)) Enums with types The union of types is the way to implement enums in Pyrope: type color = RED or BLUE or GREEN // enum just a unique ID type Rgb = ( ,color:u24 ,initial = {|x| self.color = x } ) type Red = Rgb(0x0xff0000) type Green = Rgb(0x0x00ff00) type Blue = Rgb(0x0x0000ff) type color2 = Red or Green or Blue var x:color = RED // only in local module if x does RED { // in this case \"x does RED\" is the same as \"x equals RED\" puts \"color:{}\\n\", :x // prints \"color:RED\" } var y:color2 = Red if y does Red { // in this case \"y does RED\" is the same as \"y equals RED\" // prints \"color:Red c1:Red(color=0xff0000) c2:0xff0000\" puts \"color:{} c1:{} c2:{}\\n\", :y, y, y.color } Bitwidth for numbers Number basic type can be constrained based on the maximum and minimum value (not by number of bits). Pyrope automatically infers the maximum and minimum value for each numeric variable. If a variable width can not be inferred, the compiler generates a compilation error. A compilation error is generated if the destination variable has an assigned size smaller than the operand results. The programmer can specify the maximum number of bits, or the maximum value range. The programmer can not specify the exact number of bits because the compiler has the option to optimize the design. Pyrope code can set or access the bitwidth pass results for each variable. __max : the maximum number __min : the minimum number __sbits : the number of bits to represent the value __ubits : the number of bits. The variable must be always positive or a compile error. var val:u8 // designer constraints a to be between 0 and 255 val = 3 // val has 3 bits (0sb011 all the numbers are signed) val = 300 // compile error, '300' overflows the maximum allowed value of 'val' val = 0x1F0@[0..<val.__ubits] // explicitly select bits to not overflow assert val == 240 val := 0x1F0 // Drop bits from 0x1F0 to fit in maximum 'val' allowed bits assert val == 240 val = u8(0x1F0) // Adjust val to the maximum value if overflow assert val == 255 val = :val(0x1F0) // Adjust val to the maximum value if overflow assert val == 255 Pyrope leverages LiveHD bitwidth pass [stephenson_bitwidth] to compute the maximum and minimum value of each variable. For each operation, the maximum and minimum is computed. For control flow divergences, the worst possible path is considered. a = 3 // max:3, min:3 if b { c = a+1 // max:4, min:4 }else{ c = a // max:3, min:3 } e.__sbits = 4 // max:3, min:-4 e = 3 // max:3, min:3 d = c // max:4, min:3 if d==4 { d = e + 1 // max:4, min:4 } g = d // max:4, min:3 h = c@[0,1] // max:3, min:0 Typecasting Typecasting is the process of changing from one type to other. The Number/int type allows to specify the maximum/minimum value per bit, this is not considered a new type. Since bitwidth pass adjust/computes the maximum/minimum range for each Number type, as long as precision is not lost, type casting between Numbers is done automatically. When the precision can not be preserved in a Number, a := or a typecast could be used. The lhs := rhs statement drops the bits in the rhs to fit on the lhs . An alternative method to typecase is to call the constructor, for the Number class, this does not drop bits, but keeps the maximum/minimum allowed value. var a:u32=100 var b:u10 var c:u5 var d:u5 b = a // OK done automatically. No precision lost c = a // compile error, '100' overflows the maximum allowed value of 'c' c:= a // OK, same as c = a@[0..<5] (Since 100 is 0b1100100, c==4) c = u5(a) // OK, c == 31 c = 31 d = c + 1 // compile error, '32' overflows the maximum allowed value of 'd' d:= c + 1 // OK d == 0 d = u5(c+1) // OK, d==31 d = :d(c+1) // OK, d==31 To convert between bundles, a explicit typecast is needed unless all the bundle fields match and field can be automatically typecasted without loss of precision. type at=(c:string,d:u32) type bt=(c:string:d:u100) type ct=( ,d:u32 ,c:string ) // different order type dt=( ,d:u32 ,c:string ,initial = {|x:at| self.d = x.d ; self.c = x.c } ) // different order var b:bt=(c=\"hello\", d=10000) var a:at a = b // OK c is string, and 10000 fits in u32 var c:ct c = a // compile error, different order var d:dt d = a // OK, call intitial to type cast Traits and mixins There is no object inheritance in Pyrope, but bundles allow to build mixins and composition with traits. A mixin is when an object or class can add methods and the parent object can access them. In several languages there are different constructs to build them (E.g: an include inside a class in Ruby). Since Pyrope bundles are not immutable, new methods can be added like in mixins. type Say_mixin = ( ,say = {|s| puts s } ) type Say_hi_mixin = ( ,say_hi = {|| self.say(\"hi {}\", self.name) ,say_bye = {|| self.say(\"bye {}\", self.name) ) type User = ( ,name:string ,initial = {mut |n| self.name = n } ) type Mixing_all = Say_mixin ++ Say_hi_mixin ++ User var a:Mixing_all(\"Julius Caesar\") a.say_hi() Mixins are very expressive but allow to redefine methods. If two bundles have the same field a bundle with the concatenated values will be created. This is likely an error with basic types but useful to handle explicit method overload. This could be error prone and in many cases it may be fine just to use the trait construction. The implements keyword checks that the new type implements the functionality undefined and allows to use methods defined. This is effectively a mixin with checks that some methods should be implemented. type Shape = ( ,name:string ,area = { |( ) -> :i32 |} ,increase_size = {mut|(_:i12) -> () |} ) type Circle implements Shape = ( ,rad:i32 ,initial = {mut || self.name = \"circle\" } ,area = {|() -> :i32 | let pi = import \"math.pi\" return pi * self.rad * self.rad } ,increase_size = {mut|(_:i12) -> ()| self.rad *= $1 } ) Like most typechecks, the implement can be translated for a comptime assert . An equivalent \"Circle\" functionality: type Circle = ( ,rad:i32 ,name = \"Circle\" ,area = {|() -> :i32| let pi = import \"math.pi\" return pi * self.rad * self.rad } ,increase_size = {mut|(_:i12) -> ()| self.rad *= $1 } ) comptime assert Circle does Shape Explicit function overloading Pyrope has types and functions. There is also function overloading, but unlike most languages it has explicit function overloading. With explicit, the programmer sets an ordered list of methods, and the first that satisfies the type check is called. bool_to_string = {|(b:boolean) -> :string| if b { \"true\" } else { \"false\" } } int_to_string = {|(b:int) -> :string| } to_string = bool_to_string ++ int_to_string let s = to_string(3) Liquid types or logically qualified types further constraint some types. In a way, the maximum/minimum constrain on numbers is already a logically qualified constrain, but Pyrope allows a where keyword when building function types. Types must be decided at compile time. Some times like in the maximum/minimum range, the estimation can be conservative. The where keyword can use compile time conditions, but it can also use run-time decisions like values on the inputs. When combined with liquid types, it is possible to specialize the functionality based on targets and/or functionality. Like in the adder example: add_plus_one = {|(a,b) where b == 1 or a == 1|} fast_csa = {|(a,b) where min(a.__sbits, b.__sbits)>40|} default_adder= {|(a,b)|} my_add = add_plus_one ++ fast_csa ++ default_adder assert $foo.__sbits < 10 // foo has less than 10 bits assert $bar.__sbits > 40 // bar has more than 40 bits result = my_add($foo,$foo) // calls default_adder result = my_add($bar,$bar) // calls fast_csa result = my_add($foo,1) // calls add_plus_one Global variables There are no global variables or functions in Pyrope. Variable scope is restricted by code block { ... } and/or the file. Each Pyrope file is a function, but they are only visible to the same directory/project Pyrope files. The punch statement allows to access variables from other files/functions. The import statement allows to reference functions from other files. import Each file can have several functions in addition to itself. All the functions are visible to the import statement, but it is a good etiquette not to import functions that start with underscore, but sometimes it is useful for debugging, and hence allowed. // file: src/my_fun.prp fun1 = {|a,b| ... } fun2 = {|a| ... } another = {|a| ... } _fun3 = {|a| ... } // file: src/user.prp a = import \"my_fun.*fun*\" a.fun1(a=1,b=2) // OK a.another(a=1=2) // compile error, 'anoter' is not an imported function a._fun3(a=1=2) // OK but not nice The import statement uses a shell like file globbing with an optional \"project\". If the project is not provided, the current project is used. Globbing is not allowed on the project name. * matches zero or more characters ? matches exactly one character a = import \"prj1/file?/*something*\" b = import \"file1/xxx_fun\" // import xxx_fun from file1 in the local project c = import \"file2\" // import the functions from local file2 d = import \"prj2/file3\" // import the functions from project prj2 and file3 Many languages have a \"using\" or \"import\" or \"include\" command that includes all the imported functions/variables to the current scope. Pyrope does not allow that, but it is possible to use mixins to add the imported functionality to a bundle. b = import \"prp/Number\" a = import \"fancy/Number_mixin\" type Number = b ++ a // patch the default Number class var x:Number = 3 punch The punch statement allows to access variables from other modules. It can be seen as an import but only applicable to read/write variables instead of functions. There is another significant difference with import , while import goes through projects and files, punch goes through the instantiation hierarchy to find a matching variable. The punch statement has a regex syntax, not file globbing like in import . There can be many matches for a given regex, it will return all the matches in an ordered bundle. Given a tree hierarchy, the traversal starts by visiting all the children, then the parents. The traversal is similar to a post-order tree traversal, but not the same. The post-order traversal visits a tree node once all the children are visited. The punch traversal visits a tree node once all the children AND niblings (niece of nephews from siblings) are visited. For example, given this tree hierarchy. If the punch is called from 1.2.1 node, it will visit nodes in this order: +\u2500\u2500 1.2.1.3.1 // 5th |\u2500\u2500 1.2.1.3.2 // 4th +\u2500\u2500 1.2.1.1 // 3th \u251c\u2500\u2500 1.2.1.2 // 2nd |\u2500\u2500 1.2.1.3 // 1st +\u2500\u2500 1.2.1 // START <-- | +\u2500\u2500 1.3.1.1 // 7th | |\u2500\u2500 1.3.1.2 // 8th \u251c\u2500\u2500 1.3.1 // 9th \u251c\u2500\u2500 1.3.2 // 10th \u251c\u2500\u2500 1.3.3 // 11th \u2502 -\u2500\u2500 1.4.2.1 // 12th | |\u2500\u2500 1.4.3.1 // 13th \u251c\u2500\u2500 1.4.1 // 14th \u251c\u2500\u2500 1.4.2 // 15th \u251c\u2500\u2500 1.4.3 // 16th +\u2500\u2500 1.1 // 17th \u251c\u2500\u2500 1.2 // 20th \u251c\u2500\u2500 1.3 // 21st \u251c\u2500\u2500 1.4 // 22nd | 1 // LAST punch connects to inputs ( $ ), outputs ( % ), and registers ( # ). The modifier does not need to be included in the search. The regex can include tree hierarchy. E.g: %a = punch \"module1/mod2/foo\" %b = punch \"uart_addr\" // any module that has an input $uart_addr %b[0] = 0x100 %b[1] = 0x200 %b = punch \"foo.*/uart_addr\" // modules named foo.* that have uart_addr as input $c = punch \"bar/some_output\" $d = punch \"bar/some_register\" The result of the punch has either a $ or % . The reason is that the punch creates new inputs $ or outputs % in the current module. These do not need to be in the function declaration list.","title":"Type system"},{"location":"pyrope/07-typesystem/#type-system","text":"Type systems are quite similar to sets. A main difference is that type systems may not be as accurate as a set system, and it may not allow the same expressiveness because some type of set properties may not be allowed to be specified. Most HDLs do not have modern type systems, but they could benefit like in other software domains. Additionally, in hardware it makes sense to have different implementations that adjust for performance/constrains like size, area, FPGA/ASIC. Type systems could help on these areas.","title":"Type system"},{"location":"pyrope/07-typesystem/#types-vs-comptime-assert","text":"Pyrope has support for different types of assertions ( assert , comptime assert , assume , comptime assume , verify ). The type system checks, not the function overloading, can be translated to a set of comptime assert statements. Pyrope type checks can be translated to compile time assertion checks, but the type related language syntax makes it more readable/familiar with programmers. To understand the type check, it is useful to see an equivalent comptime assert translation. Each variable can have a type attached once. Each time that the variable is modified a comptime assert statement could check that the variable is compatible with the assigned type. From a practical perspective, the Pyrope type system works this way when variables are modified. Snippet with types var b = \"hello\" var a:u32 mut a += 1 mut a = b // fails type check Snippet with comptime assert var b = \"hello\" mut a += 1 comptime assert a does u32 mut a = b comptime assert a does u32 // fails type check The compiler handles automatically, but control flow instructions affect the equivalent assert statement. var a:type1 if $runtime { var b:type2 a = yyy // comptime assert $runtime implies yyy does :type1 b = xxx // comptime assert $runtime implies xxx does :type2 } a = zzz // comptime assert zzz does :type1","title":"Types vs comptime assert"},{"location":"pyrope/07-typesystem/#building-types","text":"Each variable can be a basic type like String, Boolean, Number, or a bundle. In addition, each variable can have a set of constrains from the type system. Although it is possible to declare just the comptime assert for type checks, the recommendation is to use the explicit Pyrope type syntax because it is more readable and easier to optimize. Pyrope type constructs: type keyword allows to declare types. a does b : Checks 'a' is a superset or equal to 'b'. In the future, the unicode character \"\\u02287\" could be used as an alternative to does ( a \u2287 b ); a:b is equivalent to a does b or comptime assert a does b check. :b returns the \"type of\" b when used in an expression. a equals b : Checks that a does b and b does a . Effectively checking that they have the same type. While var statement declares a new variable instance which can also have an associated type, the type statement declares a type without any instance. The type keyword also allows for expressions to build more complex types. All the elements in the type expression are treated as \"type of\". E.g: type x = a or 1..=3 is equivalent to write type x = :a or :(1..=3) type a1 = u32 // type a1 = :u32 is also valid syntax type a2 = int(max=33,min=-5) type a3 = ( ,name:string ,age:u8 ) type b1 = a1 or a2 // same as type b1 = -5..<4G type b2 = a1 and a2 // same as type b2 = 0..=33 type b3 = a1 or a3 // compile error: unclear how to combine type 'a1' and 'a2' The puts command understands types. type at=33.. // number bigger than 32 type bt=( ,c:string ,d=100 ,initial = {|| self.c = $ } ) var a:at=40 var v:bt=\"hello\" puts \"a:{} type:{} or {}\", a, :a, at // a:40 type:Number(33..) or Number(33..) puts \"b:{} type:{}\", b, :b // b:(c=\"hello\",d=100) type:(c:string,d=100)\" Some languages use an is keyword but Pyrope uses does or equals because in English \"a is b\" is not clear (\"a is same as b\" vs \"a is subtype of b\"). type x = (a:string, b:int) type y = (a:string) type z = (a:string, b:u32, c:i8) assert x does y assert y does y assert z does y assert !(x does z) assert !(y does z) assert !(y does x) assert !(z does x) type big = x or y or z or :(d:u33) assert big does x assert big does y assert big does z assert big does :(d:u20) assert !(big does :(d:u40))","title":"Building types"},{"location":"pyrope/07-typesystem/#enums-with-types","text":"The union of types is the way to implement enums in Pyrope: type color = RED or BLUE or GREEN // enum just a unique ID type Rgb = ( ,color:u24 ,initial = {|x| self.color = x } ) type Red = Rgb(0x0xff0000) type Green = Rgb(0x0x00ff00) type Blue = Rgb(0x0x0000ff) type color2 = Red or Green or Blue var x:color = RED // only in local module if x does RED { // in this case \"x does RED\" is the same as \"x equals RED\" puts \"color:{}\\n\", :x // prints \"color:RED\" } var y:color2 = Red if y does Red { // in this case \"y does RED\" is the same as \"y equals RED\" // prints \"color:Red c1:Red(color=0xff0000) c2:0xff0000\" puts \"color:{} c1:{} c2:{}\\n\", :y, y, y.color }","title":"Enums with types"},{"location":"pyrope/07-typesystem/#bitwidth-for-numbers","text":"Number basic type can be constrained based on the maximum and minimum value (not by number of bits). Pyrope automatically infers the maximum and minimum value for each numeric variable. If a variable width can not be inferred, the compiler generates a compilation error. A compilation error is generated if the destination variable has an assigned size smaller than the operand results. The programmer can specify the maximum number of bits, or the maximum value range. The programmer can not specify the exact number of bits because the compiler has the option to optimize the design. Pyrope code can set or access the bitwidth pass results for each variable. __max : the maximum number __min : the minimum number __sbits : the number of bits to represent the value __ubits : the number of bits. The variable must be always positive or a compile error. var val:u8 // designer constraints a to be between 0 and 255 val = 3 // val has 3 bits (0sb011 all the numbers are signed) val = 300 // compile error, '300' overflows the maximum allowed value of 'val' val = 0x1F0@[0..<val.__ubits] // explicitly select bits to not overflow assert val == 240 val := 0x1F0 // Drop bits from 0x1F0 to fit in maximum 'val' allowed bits assert val == 240 val = u8(0x1F0) // Adjust val to the maximum value if overflow assert val == 255 val = :val(0x1F0) // Adjust val to the maximum value if overflow assert val == 255 Pyrope leverages LiveHD bitwidth pass [stephenson_bitwidth] to compute the maximum and minimum value of each variable. For each operation, the maximum and minimum is computed. For control flow divergences, the worst possible path is considered. a = 3 // max:3, min:3 if b { c = a+1 // max:4, min:4 }else{ c = a // max:3, min:3 } e.__sbits = 4 // max:3, min:-4 e = 3 // max:3, min:3 d = c // max:4, min:3 if d==4 { d = e + 1 // max:4, min:4 } g = d // max:4, min:3 h = c@[0,1] // max:3, min:0","title":"Bitwidth for numbers"},{"location":"pyrope/07-typesystem/#typecasting","text":"Typecasting is the process of changing from one type to other. The Number/int type allows to specify the maximum/minimum value per bit, this is not considered a new type. Since bitwidth pass adjust/computes the maximum/minimum range for each Number type, as long as precision is not lost, type casting between Numbers is done automatically. When the precision can not be preserved in a Number, a := or a typecast could be used. The lhs := rhs statement drops the bits in the rhs to fit on the lhs . An alternative method to typecase is to call the constructor, for the Number class, this does not drop bits, but keeps the maximum/minimum allowed value. var a:u32=100 var b:u10 var c:u5 var d:u5 b = a // OK done automatically. No precision lost c = a // compile error, '100' overflows the maximum allowed value of 'c' c:= a // OK, same as c = a@[0..<5] (Since 100 is 0b1100100, c==4) c = u5(a) // OK, c == 31 c = 31 d = c + 1 // compile error, '32' overflows the maximum allowed value of 'd' d:= c + 1 // OK d == 0 d = u5(c+1) // OK, d==31 d = :d(c+1) // OK, d==31 To convert between bundles, a explicit typecast is needed unless all the bundle fields match and field can be automatically typecasted without loss of precision. type at=(c:string,d:u32) type bt=(c:string:d:u100) type ct=( ,d:u32 ,c:string ) // different order type dt=( ,d:u32 ,c:string ,initial = {|x:at| self.d = x.d ; self.c = x.c } ) // different order var b:bt=(c=\"hello\", d=10000) var a:at a = b // OK c is string, and 10000 fits in u32 var c:ct c = a // compile error, different order var d:dt d = a // OK, call intitial to type cast","title":"Typecasting"},{"location":"pyrope/07-typesystem/#traits-and-mixins","text":"There is no object inheritance in Pyrope, but bundles allow to build mixins and composition with traits. A mixin is when an object or class can add methods and the parent object can access them. In several languages there are different constructs to build them (E.g: an include inside a class in Ruby). Since Pyrope bundles are not immutable, new methods can be added like in mixins. type Say_mixin = ( ,say = {|s| puts s } ) type Say_hi_mixin = ( ,say_hi = {|| self.say(\"hi {}\", self.name) ,say_bye = {|| self.say(\"bye {}\", self.name) ) type User = ( ,name:string ,initial = {mut |n| self.name = n } ) type Mixing_all = Say_mixin ++ Say_hi_mixin ++ User var a:Mixing_all(\"Julius Caesar\") a.say_hi() Mixins are very expressive but allow to redefine methods. If two bundles have the same field a bundle with the concatenated values will be created. This is likely an error with basic types but useful to handle explicit method overload. This could be error prone and in many cases it may be fine just to use the trait construction. The implements keyword checks that the new type implements the functionality undefined and allows to use methods defined. This is effectively a mixin with checks that some methods should be implemented. type Shape = ( ,name:string ,area = { |( ) -> :i32 |} ,increase_size = {mut|(_:i12) -> () |} ) type Circle implements Shape = ( ,rad:i32 ,initial = {mut || self.name = \"circle\" } ,area = {|() -> :i32 | let pi = import \"math.pi\" return pi * self.rad * self.rad } ,increase_size = {mut|(_:i12) -> ()| self.rad *= $1 } ) Like most typechecks, the implement can be translated for a comptime assert . An equivalent \"Circle\" functionality: type Circle = ( ,rad:i32 ,name = \"Circle\" ,area = {|() -> :i32| let pi = import \"math.pi\" return pi * self.rad * self.rad } ,increase_size = {mut|(_:i12) -> ()| self.rad *= $1 } ) comptime assert Circle does Shape","title":"Traits and mixins"},{"location":"pyrope/07-typesystem/#explicit-function-overloading","text":"Pyrope has types and functions. There is also function overloading, but unlike most languages it has explicit function overloading. With explicit, the programmer sets an ordered list of methods, and the first that satisfies the type check is called. bool_to_string = {|(b:boolean) -> :string| if b { \"true\" } else { \"false\" } } int_to_string = {|(b:int) -> :string| } to_string = bool_to_string ++ int_to_string let s = to_string(3) Liquid types or logically qualified types further constraint some types. In a way, the maximum/minimum constrain on numbers is already a logically qualified constrain, but Pyrope allows a where keyword when building function types. Types must be decided at compile time. Some times like in the maximum/minimum range, the estimation can be conservative. The where keyword can use compile time conditions, but it can also use run-time decisions like values on the inputs. When combined with liquid types, it is possible to specialize the functionality based on targets and/or functionality. Like in the adder example: add_plus_one = {|(a,b) where b == 1 or a == 1|} fast_csa = {|(a,b) where min(a.__sbits, b.__sbits)>40|} default_adder= {|(a,b)|} my_add = add_plus_one ++ fast_csa ++ default_adder assert $foo.__sbits < 10 // foo has less than 10 bits assert $bar.__sbits > 40 // bar has more than 40 bits result = my_add($foo,$foo) // calls default_adder result = my_add($bar,$bar) // calls fast_csa result = my_add($foo,1) // calls add_plus_one","title":"Explicit function overloading"},{"location":"pyrope/07-typesystem/#global-variables","text":"There are no global variables or functions in Pyrope. Variable scope is restricted by code block { ... } and/or the file. Each Pyrope file is a function, but they are only visible to the same directory/project Pyrope files. The punch statement allows to access variables from other files/functions. The import statement allows to reference functions from other files.","title":"Global variables"},{"location":"pyrope/07-typesystem/#import","text":"Each file can have several functions in addition to itself. All the functions are visible to the import statement, but it is a good etiquette not to import functions that start with underscore, but sometimes it is useful for debugging, and hence allowed. // file: src/my_fun.prp fun1 = {|a,b| ... } fun2 = {|a| ... } another = {|a| ... } _fun3 = {|a| ... } // file: src/user.prp a = import \"my_fun.*fun*\" a.fun1(a=1,b=2) // OK a.another(a=1=2) // compile error, 'anoter' is not an imported function a._fun3(a=1=2) // OK but not nice The import statement uses a shell like file globbing with an optional \"project\". If the project is not provided, the current project is used. Globbing is not allowed on the project name. * matches zero or more characters ? matches exactly one character a = import \"prj1/file?/*something*\" b = import \"file1/xxx_fun\" // import xxx_fun from file1 in the local project c = import \"file2\" // import the functions from local file2 d = import \"prj2/file3\" // import the functions from project prj2 and file3 Many languages have a \"using\" or \"import\" or \"include\" command that includes all the imported functions/variables to the current scope. Pyrope does not allow that, but it is possible to use mixins to add the imported functionality to a bundle. b = import \"prp/Number\" a = import \"fancy/Number_mixin\" type Number = b ++ a // patch the default Number class var x:Number = 3","title":"import"},{"location":"pyrope/07-typesystem/#punch","text":"The punch statement allows to access variables from other modules. It can be seen as an import but only applicable to read/write variables instead of functions. There is another significant difference with import , while import goes through projects and files, punch goes through the instantiation hierarchy to find a matching variable. The punch statement has a regex syntax, not file globbing like in import . There can be many matches for a given regex, it will return all the matches in an ordered bundle. Given a tree hierarchy, the traversal starts by visiting all the children, then the parents. The traversal is similar to a post-order tree traversal, but not the same. The post-order traversal visits a tree node once all the children are visited. The punch traversal visits a tree node once all the children AND niblings (niece of nephews from siblings) are visited. For example, given this tree hierarchy. If the punch is called from 1.2.1 node, it will visit nodes in this order: +\u2500\u2500 1.2.1.3.1 // 5th |\u2500\u2500 1.2.1.3.2 // 4th +\u2500\u2500 1.2.1.1 // 3th \u251c\u2500\u2500 1.2.1.2 // 2nd |\u2500\u2500 1.2.1.3 // 1st +\u2500\u2500 1.2.1 // START <-- | +\u2500\u2500 1.3.1.1 // 7th | |\u2500\u2500 1.3.1.2 // 8th \u251c\u2500\u2500 1.3.1 // 9th \u251c\u2500\u2500 1.3.2 // 10th \u251c\u2500\u2500 1.3.3 // 11th \u2502 -\u2500\u2500 1.4.2.1 // 12th | |\u2500\u2500 1.4.3.1 // 13th \u251c\u2500\u2500 1.4.1 // 14th \u251c\u2500\u2500 1.4.2 // 15th \u251c\u2500\u2500 1.4.3 // 16th +\u2500\u2500 1.1 // 17th \u251c\u2500\u2500 1.2 // 20th \u251c\u2500\u2500 1.3 // 21st \u251c\u2500\u2500 1.4 // 22nd | 1 // LAST punch connects to inputs ( $ ), outputs ( % ), and registers ( # ). The modifier does not need to be included in the search. The regex can include tree hierarchy. E.g: %a = punch \"module1/mod2/foo\" %b = punch \"uart_addr\" // any module that has an input $uart_addr %b[0] = 0x100 %b[1] = 0x200 %b = punch \"foo.*/uart_addr\" // modules named foo.* that have uart_addr as input $c = punch \"bar/some_output\" $d = punch \"bar/some_register\" The result of the punch has either a $ or % . The reason is that the punch creates new inputs $ or outputs % in the current module. These do not need to be in the function declaration list.","title":"punch"},{"location":"pyrope/09-stdlib/","text":"Pyrope std lib Like most languages, a standard library provides some common functionality around. The standard library provides methods for the basic types (Number, String, Boolean) and utility code like fifos. The utils must be imported but the basic types are imported by default.","title":"Pyrope std lib"},{"location":"pyrope/09-stdlib/#pyrope-std-lib","text":"Like most languages, a standard library provides some common functionality around. The standard library provides methods for the basic types (Number, String, Boolean) and utility code like fifos. The utils must be imported but the basic types are imported by default.","title":"Pyrope std lib"}]}